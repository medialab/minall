{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This site contains documentation for the <code>minall</code> data enrichment workflow. The project's aim is to collect and update metadata about web content, targeted via Unique Resource Identifiers (URIs / URLs).</p> <p><code>minall</code> is built atop the data-mining tool <code>minet</code>, which was designed to collect data about media content online.</p>"},{"location":"#table-of-contents","title":"Table Of Contents","text":"<ul> <li>Tutorials : Articles demonstrating how to use the project for various use cases.</li> <li>How-To Guides : Straight-to-the-point, step-by-step guides.</li> <li>Reference : Documentation of the project's code base.</li> <li>Explanation : Article explaining the project's motivation and implementation.</li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This project was developed as a response to research needs in the European project De Facto and with the help of members of the m\u00e9dialab at Sciences Po. In particular, the project depends on the excellent work of Guillaume Plique and other contributors to the m\u00e9dialab's tool <code>minet</code>.</p>"},{"location":"explanation/","title":"Explanation","text":"<p>This part of the project documentation focuses on an understanding-oriented approach. You'll get a chance to read about the background of the project, as well as reasoning about how it was implemented.</p> <p>Note: Expand this section by considering the following points:</p> <ul> <li>Give context and background on your library</li> <li>Explain why you created it</li> <li>Provide multiple examples and approaches of how   to work with it</li> <li>Help the reader make connections</li> <li>Avoid writing instructions or technical descriptions   here</li> </ul> <pre><code>graph\nA(\"What is the nature of the URL?\")\nB(\"Is the URL of a video?\")\nC[\"Call YouTube API for video metadata, including channel ID.\"]\nD(\"Is the URL of a channel?\")\nE[\"Call YouTube API for channel metadata\"]\n\nF(\"Is the URL of a Facebook post?\")\nG[\"Call CrowdTangle API for post metadata\"]\n\nH(\"Is the URL from a media platform other than YouTube or Facebook?\")\nI[\"Assign '@type' = 'SocialMediaPosting'.\"]\n\nJ(\"Is the URL not from a social media platform?\")\nK[\"Scrape text and metadata.\"]\n\nL[\"Call Buzzsumo API for metadata.\"]\n\nA==YouTube==&gt;B\nB==Y==&gt;C\nB==N==&gt;D\nC---E\nD---E\nA==Facebook==&gt;F\nF---G\nA==Other Social Media==&gt;H\nH---I\nA==Article==&gt;J\nJ---K\nE---L\nG---L\nI---L\nK---L</code></pre>"},{"location":"explanation/#data-fields","title":"Data fields","text":"<ul> <li><code>url</code> : the URL that will be used for the metadata collection</li> <li><code>domain</code> : the URL's domain name</li> <li><code>work_type</code> : a Schema.org classification for the URL as a CreativeWork</li> <li><code>duration</code> : if the URL is of a video, the video's duration</li> <li><code>identifier</code> : the identifier given to the URL via a platform (i.e. YouTube ID, Twitter user ID)</li> <li><code>date_published</code> : date (YYYY-MM-DD) when the URL's content was originally published</li> <li><code>date_modified</code> : date (YYYY-MM-DD) when the URL's content was last updated</li> <li><code>country_of_origin</code> : if the URL is of a YouTube channel, the channel's registered country</li> <li><code>abstract</code> : abbreviated description of the URL's content</li> <li><code>keywords</code> : keywords associated with the URL</li> <li><code>title</code> : title given to the URL's content</li> <li><code>text</code> : the URL's main textual content</li> <li><code>hashtags</code> : hashtags associated with the URL</li> <li><code>creator_type</code> : a Schema.org or De Facto classification for the creator of the URL's content</li> <li><code>creator_date_created</code> : if the URL's content was created by a social media account, the date of the account's creation on the site</li> <li><code>creator_location_created</code> : if the URL's content was created by a social media account, the country in which the account is registered</li> <li><code>creator_identifier</code> if the URL's content was created by a social media account, the social media platform's identifier for the account</li> <li><code>creator_facebook_follow</code> : if the URL is a Facebook post, the number of Facebook followers the creator's account has</li> <li><code>creator_facebook_subscribe</code> : if the URL is a Facebook post, the number of Facebook subscribers the creator's account has</li> <li><code>creator_twitter_follow</code> : if the URL is a Tweet, the number of Twitter / X followers the creator's account has</li> <li><code>creator_youtube_subscribe</code> : if the URL is a YouTube video, the number of YouTube channel subscribers the channel has</li> <li><code>creator_create_video</code> : if the URL is a YouTube video, the number of videos the YouTube channel has created</li> <li><code>creator_name</code> : the name of the creator of the URL's content</li> <li><code>creator_url</code> : if the URL is a social media post, a link to the creator's account page on the platform</li> <li><code>facebook_comment</code> : number of comments the URL has received on Facebook</li> <li><code>facebook_like</code> : number of likes the URL has received on Facebook</li> <li><code>facebook_share</code> : number of shares the URL has received on Facebook</li> <li><code>pinterest_share</code> : number of shares the URL has received on Pinterest</li> <li><code>twitter_share</code> : number of shares the URL has received on Twitter / X</li> <li><code>tiktok_share</code> : number of shares the URL has received on TikTok</li> <li><code>tiktok_comment</code> : number of comments the URL has received on TikTok</li> <li><code>reddit_engagement</code> : metric engagement the URL has received on Reddit</li> <li><code>youtube_watch</code> : number of views the URL has received on YouTube</li> <li><code>youtube_comment</code> : number of comments the URL has received on YouTube</li> <li><code>youtube_like</code> : number of likes the URL has received on YouTube</li> <li><code>youtube_favorite</code> : number of favorite reactions the URL has received on YouTube</li> <li><code>youtube_subscribe</code> : if the URL is of a YouTube channel, the channel's number of subscribers</li> <li><code>create_video</code>: if the URL is of a YouTube channel, the number of videos the channel has created</li> </ul> <p>Example from https://realpython.com/python-project-documentation-with-mkdocs/</p>"},{"location":"how-to-guides/","title":"How-To Guides","text":""},{"location":"how-to-guides/#using-minall-from-the-command-line","title":"Using <code>minall</code> from the command line","text":""},{"location":"how-to-guides/#context","title":"Context","text":"<p>Let's say we have a set of 2 URLs, one is a web page and the other is a YouTube video.</p> <p><code>data.csv</code></p> target_url https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ https://www.youtube.com/watch?v=BTvfWbAjh1w <p>And we've stored the data file in our current working directory under the name <code>data.csv</code>.</p> <pre><code>.\n\u2502\n\u2514\u2500\u2500 data.csv\n</code></pre>"},{"location":"how-to-guides/#set-up-files","title":"Set up files","text":"<p>For the purposes of this demonstration, we'll need to create an additional file, <code>config.yml</code>.</p> <pre><code>.\n\u2502\n\u251c\u2500\u2500 config.yml\n\u2502\n\u2514\u2500\u2500 data.csv\n</code></pre> <p>This YAML file is a configuration file in the same format as that used in <code>minet</code>, and it contains API keys.</p> <p><code>config.yml</code> <pre><code>---\nbuzzsumo:\n  token: \"XXXX\" # Used as --token for `minet bz` commands\ncrowdtangle:\n  token: \"XXXX\" # Used as --token for `minet ct` commands\n  rate_limit: 50 # Used as --rate-limit for `minet ct` commands\nyoutube:\n  key: \"XXXX\" # Used as --key for `minet yt` commands\n</code></pre></p>"},{"location":"how-to-guides/#set-up-minall","title":"Set up <code>minall</code>","text":"<p>Now we'll install <code>minall</code>. Create and activate a virtual Python environment, using version 3.11. Then install the tool with pip.</p> <pre><code>$ pip install git+https://github.com/medialab/minall.git\n</code></pre>"},{"location":"how-to-guides/#run","title":"Run","text":"<p>Finally, let's run the workflow on our dataset. We'll set the parameters as follows:</p> <ul> <li><code>--config</code> : Path to the YAML configuration file, <code>./config.yml</code></li> <li><code>--links</code> : Path to the dataset of target URLs, <code>./data.csv</code></li> <li><code>--url-col</code>: Name of the column in the dataset file with the target URLs. <code>target_url</code></li> <li><code>--output-dir</code>: Path to where <code>minall</code> will export its results. <code>./output/</code></li> </ul> <pre><code>$ minall --config config.yml --output-dir output/ --links data.csv --url-col target_url\n</code></pre> <p>While <code>minall</code> is running, we'll see the following commands proceed:</p> <pre><code>Querying YouTube videos   1/1 0:00:00\nQuerying YouTube channels   1/1 0:00:00\nScraping webpage   1/1 0:00:00\nCalling Buzzsumo API   2/2 0:00:05\n</code></pre>"},{"location":"how-to-guides/#results","title":"Results","text":"<p>The results will be written to files in the directory whose path was given to the parameter <code>--output-dir</code>.</p> <pre><code>.\n\u2502\n\u251c\u2500\u2500 config.yml\n\u2502\n\u251c\u2500\u2500 data.csv\n\u2502\n\u2514\u2500\u2500 output/\n    \u251c\u2500\u2500 links.csv\n    \u2514\u2500\u2500 shared_content.csv\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>This tutorial will walk you through a real-life example of why and how to use <code>minall</code>.</p>"},{"location":"tutorials/#example-dataset","title":"Example dataset","text":"<p>Let's say we have a list of URLs whose basic metadata and propagation online we want to study. We've stored those URLs in a CSV file under the column <code>target_url</code>. Both are about Guillaume Plique's presentation of <code>minet</code> at the FOSDEM conference in 2020. One of the URLs is of a web page from the conference's site and the other is a YouTube video, published by the conference organization.</p> target_url https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ https://www.youtube.com/watch?v=BTvfWbAjh1w <p>If using <code>minet</code>, we'd need to run 2 different commands based on the type of URL, <code>minet yt</code> for the YouTube video and <code>minet fetch</code> / <code>minet extract</code> for the web page. When working with just 2 URLs, that's not such a problem. However, let's imagine our list of URLs is much bigger than these 2 rows and that we don't aleady know what type of content is in it. Plus, we want to be able to work with the collected data as a set, comparing identical attributes of both the web page and the YouTube video. <code>minet</code>'s commands write their results in data fields that are unique to each sub-command. This idiosyncracy complicates comparative analysis. What <code>minall</code> does, in one single command, is output fewer but harmonized data fields, which apply to all types of web content.</p>"},{"location":"tutorials/#set-up-required-files","title":"Set up required files","text":"<p>For the purposes of this tutorial, let's create two files in our current working directory. One is the dataset described above (<code>data.csv</code>) and the second is a YAML configuation file, which is the same as that used in <code>minet</code> (<code>config.yml</code>).</p> <pre><code>.\n\u2502\n\u251c\u2500\u2500 config.yml\n\u2502\n\u2514\u2500\u2500 data.csv\n</code></pre> <p>Because API keys are not always available, <code>minall</code> does not require them to function. However, the majority of its enrichments depend on various APIs and, if not using any, we might as well just use <code>minet</code>'s scraping commands directly.</p> <p>Let's assume we only have a YouTube API key, which is free and can be obtained from Google with a Gmail account. We'll set up the configuration file like so:</p> <p><code>config.yml</code> <pre><code>---\nyoutube:\n  key: \"XXXX\"\n</code></pre></p>"},{"location":"tutorials/#api-keys","title":"API keys","text":"<p>Technically, <code>minall</code> does not require a configuration file to function because it can skip over any enrichment methods that require API keys the user did not provide. Only the dataset file, which contains target URLs, is absolutley necessary. However, the purpose of using <code>minall</code> is to take advantage of <code>minet</code>'s many API clients in one single command. Thus, though not important for this tutorial, it's best if you can fill out the entire configuration file below:</p> <pre><code>---\nbuzzsumo:\n  token: \"XXXX\" # Used as --token for `minet bz` commands\ncrowdtangle:\n  token: \"XXXX\" # Used as --token for `minet ct` commands\n  rate_limit: 50 # Used as --rate-limit for `minet ct` commands\nyoutube:\n  key: \"XXXX\" # Used as --key for `minet yt` commands\n</code></pre> <ul> <li>YouTube's API key can be requested from Google.</li> <li>CrowdTangle's API key can be requested from Meta</li> <li>Buzzsumo's API key can be purchased from Buzzsumo.</li> </ul>"},{"location":"tutorials/#install-minall","title":"Install <code>minall</code>","text":"<p>Because <code>minall</code> is written entirely in Python, we need to have Python installed, specifically version 3.11-something. We also need to create a \"virtual\" Python environment.</p> <p>In a shell with the virtual Python environment activated, install <code>minall</code> from GitHub.</p> <pre><code>$ pip install git+https://github.com/medialab/minall.git\n</code></pre> <p>Let's check that we installed it correctly by entering the command <code>minall --help</code>. The following should show up in the console:</p> <pre><code>usage: Minall [-h] [--database DATABASE] [--config CONFIG] --output-dir\n              OUTPUT_DIR --links LINKS_FILE --url-col URL_COL\n              [--shared-content SHARED_CONTENT_FILE] [--buzzsumo-only]\n\noptions:\n  -h, --help            show this help message and exit\n  --database DATABASE   [Optional] Path to SQLite database. If not given,\n                        database written to memory.\n  --config CONFIG       [Optional] Path to configuration file. If not\n                        given, environment variables are expected.\n  --output-dir OUTPUT_DIR\n                        [Required] Path to directory in which a links and\n                        shared_content file will be written.\n  --links LINKS_FILE    [Required] Path to links file.\n  --url-col URL_COL     [Required] Name of URL column in links file.\n  --shared-content SHARED_CONTENT_FILE\n                        [Optional] Path to shared_content file.\n  --buzzsumo-only       [Optional] Flag indicating only Buzzsumo API will\n                        be called on links file.\n</code></pre>"},{"location":"tutorials/#run","title":"Run","text":"<p>Now we're ready to run <code>minall</code> on our dataset of URLs about Guillaume Plique's FOSDEM presentation. The <code>minall</code> command will produce 2 new CSV files, one has all of the dataset's URLs and their newly collected metadata (<code>links.csv</code>), the other has URLs pointing to media content that was embedded inside the target URL's web content (<code>shared_content.csv</code>).</p> <p>Note: Currently, <code>minall</code> only records the URLS of embedded media content when it's shared inside a Facebook post. This feature, however, should be expanded to include media (images, videos) shared inside articles.</p> <p>We'll ask <code>minall</code> to write the 2 new files to a directory named <code>output</code>, which will eventually (at the end of the workflow) change our current working directory like so:</p> <pre><code>.\n\u2502\n\u251c\u2500\u2500 config.yml\n\u2502\n\u251c\u2500\u2500 data.csv\n\u2502\n\u2514\u2500\u2500 output/\n    \u251c\u2500\u2500 links.csv\n    \u2514\u2500\u2500 shared_content.csv\n</code></pre> <p>To run <code>minall</code>, we'll call the command with the following options:</p> <ul> <li><code>--config</code> : Path to the YAML configuration file, <code>./config.yml</code></li> <li><code>--links</code> : Path to the dataset of target URLs, <code>./data.csv</code></li> <li><code>--url-col</code>: Name of the column in the dataset file with the target URLs. <code>target_url</code></li> <li><code>--output-dir</code>: Path to where <code>minall</code> will export its results. <code>./output/</code></li> </ul> <pre><code>$ minall --config config.yml --output-dir output/ --links data.csv --url-col target_url\n</code></pre> <p>While <code>minall</code> is running, we'll see the following commands proceed:</p> <pre><code>Querying YouTube videos   1/1 0:00:00\nQuerying YouTube channels   1/1 0:00:00\nScraping webpage   1/1 0:00:00\n</code></pre> <p>Had our dataset included URLs from Facebook and had we provided a CrowdTangle API key, <code>minall</code> would have also called the CrowdTangle API. But because our dataset only included the URL of a web page and of a YouTube video, it ran through only its YouTube API and scraping utilities. Had we provided a Buzzsumo API key, it would have also called the Buzzsumo API twice, searching for both the web page's URL and the YouTube video's URL in Buzzsumo's database.</p>"},{"location":"tutorials/#understanding-the-results","title":"Understanding the results","text":"<p>A portion of the <code>output/links.csv</code> file that <code>minall</code> created is shown below.</p> target_url url domain work_type duration identifier date_published ... title https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ fosdem.org WebPage 2020-02-01 ... FOSDEM 2020 - Empowering social scientists with web mining tools https://www.youtube.com/watch?v=BTvfWbAjh1w https://www.youtube.com/watch?v=BTvfWbAjh1w youtube.com VideoObject 1431 BTvfWbAjh1w 2021-07-12T06:53:30 ... Empowering social scientists with web mining tools Why and how to enable researchers to perform com\u2026 <p>We see that <code>minall</code> read the columns in our data file, specifically <code>target_url</code>, conserved the original column, and appended the enrichment's additional columns to the right.</p> <p>We also see that FOSDEM published the announcement of Guillaume Plique's presentation about <code>minet</code> on their website just before the conference, on 1 February 2020. However, FOSDEM uploaded a video of the presentation to YouTube over a year later, on 12 July 2021. Though we have no way of knowing how many people viewed the web page, YouTube's API allows us know how many people viewed, commented on, and liked the video.</p> target_url ... reddit_engagement youtube_watch youtube_comment youtube_like https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ https://www.youtube.com/watch?v=BTvfWbAjh1w 69 0 3"},{"location":"tutorials/#buzzsumo","title":"Buzzsumo","text":"<p>Because we didn't provide <code>minall</code> with a Buzzsumo API key, it was unable to ask Buzzsumo if the database had cached metadata about either of our dataset's URLs. Had we included Buzzsumo in our configuration file, <code>minall</code> would have told us that Buzzsumo does have information about the FOSDEM video on YouTube; however, it does not have any information about the web page on FOSDEM's site.</p> <p>We know when Buzzsumo has stored information about one of our target URLs because certain data fields in the <code>links.csv</code> file will have a value. For example, if we were to run <code>minall</code> again with a Buzzsumo API key in the configuration file, we would know Buzzsumo cached our dataset's YouTube video because we see values in data fields that are beyond the scope of YouTube's API, specifically <code>facebook_comment</code>, <code>pinterest_share</code>, and <code>twitter_share</code>. It is normal that some of Buzzsumo's data fields, such as <code>tiktok_share</code>, are empty even though Buzzsumo found an exact match of our target URL in its database. The fact that none of the data fields for our dataset's web page have any value means that Buzzsumo did not find the FOSDEM URL.</p> target_url ... facebook_comment facebook_like pinterest_share twitter_share tiktok_share https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ https://www.youtube.com/watch?v=BTvfWbAjh1w 0 0 0"},{"location":"reference/cli/","title":"CLI tools","text":""},{"location":"reference/cli/#minall.cli.run","title":"<code>minall.cli.run</code>","text":"<p>CLI action for minall workflow.</p> <p>This module contains the function <code>cli()</code>, which runs the minall workflow as a CLI tool.</p> <p>The function <code>cli()</code> requests and parses the command-line arguments that are necessary to create an instance of the <code>Minall</code> class. Then, it deploys the <code>Minall</code> class's workflow.</p>"},{"location":"reference/cli/#minall.cli.run.cli","title":"<code>cli()</code>","text":"<p>Run minall workflow from the command line.</p> Source code in <code>minall/cli/run.py</code> <pre><code>def cli():\n    \"\"\"Run minall workflow from the command line.\"\"\"\n\n    args = cli_args()\n\n    app = Minall(**args)\n\n    app.collect_and_coalesce()\n\n    app.export()\n</code></pre>"},{"location":"reference/cli/#minall.cli.parse_args","title":"<code>minall.cli.parse_args</code>","text":"<p>Helper functions for CLI action.</p> <p>This module contains the following helper functions for parsing command-line arguments:</p> <ul> <li><code>cli_args()</code> - Parse CLI arguments.</li> <li><code>dir_path(path_name)</code> - Create directory and necessary parent directories.</li> <li><code>file_path(path_name)</code> - Verify existence of given file.</li> <li><code>has_parent(path_name)</code> - Create necessary parent directories for file path.</li> </ul>"},{"location":"reference/cli/#minall.cli.parse_args.cli_args","title":"<code>cli_args()</code>","text":"<p>Function to call and parse command-line arguments.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary of parsed command-line arguments.</p> Source code in <code>minall/cli/parse_args.py</code> <pre><code>def cli_args() -&gt; dict:\n    \"\"\"Function to call and parse command-line arguments.\n\n    Returns:\n        dict: Dictionary of parsed command-line arguments.\n    \"\"\"\n    parser = ArgumentParser(\n        add_help=True, prog=\"Minall\", formatter_class=RawDescriptionHelpFormatter\n    )\n    parser.add_argument(\n        \"--database\",\n        dest=\"database\",\n        required=False,\n        type=has_parent,\n        help=\"[Optional] Path to SQLite database. If not given, database written to memory.\",\n    )\n    parser.add_argument(\n        \"--config\",\n        dest=\"config\",\n        type=file_path,\n        required=False,\n        help=\"[Optional] Path to configuration file. If not given, environment variables are expected.\",\n    )\n    parser.add_argument(\n        \"--output-dir\",\n        dest=\"output_dir\",\n        type=dir_path,\n        required=True,\n        help=\"[Required] Path to directory in which a links and shared_content file will be written.\",\n    )\n    parser.add_argument(\n        \"--links\",\n        dest=\"links_file\",\n        type=file_path,\n        required=True,\n        help=\"[Required] Path to links file.\",\n    )\n    parser.add_argument(\n        \"--url-col\",\n        dest=\"url_col\",\n        type=str,\n        required=True,\n        help=\"[Required] Name of URL column in links file.\",\n    )\n    parser.add_argument(\n        \"--shared-content\",\n        dest=\"shared_content_file\",\n        type=file_path,\n        required=False,\n        help=\"[Optional] Path to shared_content file.\",\n    )\n    parser.add_argument(\n        \"--buzzsumo-only\",\n        dest=\"buzzsumo_only\",\n        default=False,\n        required=False,\n        action=\"store_true\",\n        help=\"[Optional] Flag indicating only Buzzsumo API will be called on links file.\",\n    )\n    args = parser.parse_args()\n    return args.__dict__\n</code></pre>"},{"location":"reference/cli/#minall.cli.parse_args.dir_path","title":"<code>dir_path(path_name)</code>","text":"<p>Function to convert CLI argument to created directory.</p> <p>Parameters:</p> Name Type Description Default <code>path_name</code> <code>str</code> <p>Path to target directory.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to prepared directory.</p> Source code in <code>minall/cli/parse_args.py</code> <pre><code>def dir_path(path_name: str) -&gt; str:\n    \"\"\"Function to convert CLI argument to created directory.\n\n    Args:\n        path_name (str): Path to target directory.\n\n    Returns:\n        str: Path to prepared directory.\n    \"\"\"\n    if Path(path_name).is_dir():\n        return path_name\n    else:\n        Path(path_name).mkdir(exist_ok=True)\n        [p.mkdir(exist_ok=True) for p in Path(path_name).parents]\n        return path_name\n</code></pre>"},{"location":"reference/cli/#minall.cli.parse_args.file_path","title":"<code>file_path(path_name)</code>","text":"<p>Function to convert CLI argument to verified, found file path.</p> <p>Parameters:</p> Name Type Description Default <code>path_name</code> <code>str</code> <p>Path to data file.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>Data file not found at given path.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Verified path to data file.</p> Source code in <code>minall/cli/parse_args.py</code> <pre><code>def file_path(path_name: str) -&gt; str:\n    \"\"\"Function to convert CLI argument to verified, found file path.\n\n    Args:\n        path_name (str): Path to data file.\n\n    Raises:\n        FileNotFoundError: Data file not found at given path.\n\n    Returns:\n        str: Verified path to data file.\n    \"\"\"\n    if Path(path_name).is_file():\n        return path_name\n    else:\n        raise FileNotFoundError(path_name)\n</code></pre>"},{"location":"reference/cli/#minall.cli.parse_args.has_parent","title":"<code>has_parent(path_name)</code>","text":"<p>Function to convert CLI argument to file path with created parent directories.</p> <p>Parameters:</p> Name Type Description Default <code>path_name</code> <code>str</code> <p>Path to out-file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to out-file with created parent directories.</p> Source code in <code>minall/cli/parse_args.py</code> <pre><code>def has_parent(path_name: str) -&gt; str:\n    \"\"\"Function to convert CLI argument to file path with created parent directories.\n\n    Args:\n        path_name (str): Path to out-file.\n\n    Returns:\n        str: Path to out-file with created parent directories.\n    \"\"\"\n    [p.mkdir(exist_ok=True) for p in Path(path_name).parents]\n    return path_name\n</code></pre>"},{"location":"reference/enrichment/","title":"Enrichment tools","text":"<pre><code>graph\nA(\"What is the nature of the URL?\")\nB(\"Is the URL of a video?\")\nC[\"Call YouTube API for video metadata, including channel ID.\"]\nD(\"Is the URL of a channel?\")\nE[\"Call YouTube API for channel metadata\"]\n\nF(\"Is the URL of a Facebook post?\")\nG[\"Call CrowdTangle API for post metadata\"]\n\nH(\"Is the URL from a media platform other than YouTube or Facebook?\")\nI[\"Assign '@type' = 'SocialMediaPosting'.\"]\n\nJ(\"Is the URL not from a social media platform?\")\nK[\"Scrape text and metadata.\"]\n\nL[\"Call Buzzsumo API for metadata.\"]\n\nA==YouTube==&gt;B\nB==Y==&gt;C\nB==N==&gt;D\nC---E\nD---E\nA==Facebook==&gt;F\nF---G\nA==Other Social Media==&gt;H\nH---I\nA==Article==&gt;J\nJ---K\nE---L\nG---L\nI---L\nK---L</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment","title":"<code>minall.enrichment.enrichment</code>","text":"<p>Class for data collection and coalescing.</p> <p>With the class <code>Enrichment</code>, this module manages the data collection process.</p> <p>The class contains the following methods:</p> <ul> <li><code>__init__(links_table, shared_content_table, keys)</code> -</li> </ul>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment","title":"<code>Enrichment</code>","text":"Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>class Enrichment:\n    def __init__(\n        self,\n        links_table: LinksTable,\n        shared_content_table: SharedContentTable,\n        keys: APIKeys,\n    ) -&gt; None:\n        \"\"\"From given API keys and URL data set, filter URLs by domain and initialize data enrichment class.\n\n        Args:\n            links_table (BaseTable): BaseTable class instance of SQL table for URL dataset.\n            shared_content_table (BaseTable): BaseTable class instance of SQL table for shared content related to URLs in dataset.\n            keys (APIKeys): APIKeys class instance of minet API client configurations.\n        \"\"\"\n\n        self.links_table = links_table\n        self.shared_content_table = shared_content_table\n        self.keys = keys\n        self.filtered_links = FilteredLinks(self.links_table)\n\n    def buzzsumo(self):\n        \"\"\"For all URLs, collect data from Buzzsumo and coalesce in the database's 'links' table.\"\"\"\n\n        if self.keys.buzzsumo_token:\n            get_buzzsumo_data(\n                data=self.filtered_links.all_links,\n                token=self.keys.buzzsumo_token,\n                outfile=self.links_table.outfile,\n            )\n            self.links_table.update_from_csv(datafile=self.links_table.outfile)\n\n    def scraper(self):\n        \"\"\"For select URLs, collect data via scraping and coalesce in the database's 'links' table.\"\"\"\n\n        # In multiple threads, scrape HTML data and write to a CSV file\n        get_article_text(\n            data=self.filtered_links.to_scrape, outfile=self.links_table.outfile\n        )\n        # Coalesce the results in the CSV File to the links table\n        self.links_table.update_from_csv(datafile=self.links_table.outfile)\n\n    def other_social_media(self):\n        \"\"\"For select URLs, update the 'work_type' column in the database's 'links' table with the value 'SocialMediaPosting'.\"\"\"\n        # Assign default type to social media post\n        add_type_data(\n            data=self.filtered_links.other_social, outfile=self.links_table.outfile\n        )\n        # Coalesce the results in the CSV File to the links table\n        self.links_table.update_from_csv(datafile=self.links_table.outfile)\n\n    def facebook(self):\n        \"\"\"For Facebook URLs, collect data from CrowdTangle and coalesce in the database's 'links' and 'shared_content' tables.\"\"\"\n        if self.keys.crowdtangle_token:\n            get_facebook_post_data(\n                data=self.filtered_links.facebook,\n                token=self.keys.crowdtangle_token,\n                rate_limit=self.keys.crowdtangle_rate_limit,\n                links_outfile=self.links_table.outfile,\n                shared_content_outfile=self.shared_content_table.outfile,\n            )\n            # Coalesce the results in the CSV File to the links table\n            self.links_table.update_from_csv(datafile=self.links_table.outfile)\n            self.shared_content_table.update_from_csv(\n                datafile=self.shared_content_table.outfile\n            )\n\n    def youtube(self):\n        \"\"\"For YouTube URLs, collect data from YouTube API and coalesce in the database's 'links' table.\"\"\"\n        if self.keys.youtube_key:\n            # In single thread, collect YouTube API data and write to a CSV file\n            get_youtube_data(\n                data=self.filtered_links.youtube,\n                keys=self.keys.youtube_key,\n                outfile=self.links_table.outfile,\n            )\n            # Coalesce the results in the CSV File to the links table\n            self.links_table.update_from_csv(datafile=self.links_table.outfile)\n\n    def __call__(self, buzzsumo_only: bool):\n        executor = SQLiteWrapper(connection=self.links_table.conn)\n        # apply domain to all urls\n        for link in self.filtered_links.all_links:\n            query, domain = apply_domain(link)\n            if query and domain:\n                self.links_table.conn\n                executor(query=query)\n\n        if not buzzsumo_only:\n            if len(self.filtered_links.youtube) &gt; 0:\n                self.youtube()\n            if len(self.filtered_links.facebook) &gt; 0:\n                self.facebook()\n            if len(self.filtered_links.other_social) &gt; 0:\n                self.other_social_media()\n            if len(self.filtered_links.to_scrape) &gt; 0:\n                self.scraper()\n        self.buzzsumo()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.__init__","title":"<code>__init__(links_table, shared_content_table, keys)</code>","text":"<p>From given API keys and URL data set, filter URLs by domain and initialize data enrichment class.</p> <p>Parameters:</p> Name Type Description Default <code>links_table</code> <code>BaseTable</code> <p>BaseTable class instance of SQL table for URL dataset.</p> required <code>shared_content_table</code> <code>BaseTable</code> <p>BaseTable class instance of SQL table for shared content related to URLs in dataset.</p> required <code>keys</code> <code>APIKeys</code> <p>APIKeys class instance of minet API client configurations.</p> required Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def __init__(\n    self,\n    links_table: LinksTable,\n    shared_content_table: SharedContentTable,\n    keys: APIKeys,\n) -&gt; None:\n    \"\"\"From given API keys and URL data set, filter URLs by domain and initialize data enrichment class.\n\n    Args:\n        links_table (BaseTable): BaseTable class instance of SQL table for URL dataset.\n        shared_content_table (BaseTable): BaseTable class instance of SQL table for shared content related to URLs in dataset.\n        keys (APIKeys): APIKeys class instance of minet API client configurations.\n    \"\"\"\n\n    self.links_table = links_table\n    self.shared_content_table = shared_content_table\n    self.keys = keys\n    self.filtered_links = FilteredLinks(self.links_table)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.buzzsumo","title":"<code>buzzsumo()</code>","text":"<p>For all URLs, collect data from Buzzsumo and coalesce in the database's 'links' table.</p> Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def buzzsumo(self):\n    \"\"\"For all URLs, collect data from Buzzsumo and coalesce in the database's 'links' table.\"\"\"\n\n    if self.keys.buzzsumo_token:\n        get_buzzsumo_data(\n            data=self.filtered_links.all_links,\n            token=self.keys.buzzsumo_token,\n            outfile=self.links_table.outfile,\n        )\n        self.links_table.update_from_csv(datafile=self.links_table.outfile)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.facebook","title":"<code>facebook()</code>","text":"<p>For Facebook URLs, collect data from CrowdTangle and coalesce in the database's 'links' and 'shared_content' tables.</p> Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def facebook(self):\n    \"\"\"For Facebook URLs, collect data from CrowdTangle and coalesce in the database's 'links' and 'shared_content' tables.\"\"\"\n    if self.keys.crowdtangle_token:\n        get_facebook_post_data(\n            data=self.filtered_links.facebook,\n            token=self.keys.crowdtangle_token,\n            rate_limit=self.keys.crowdtangle_rate_limit,\n            links_outfile=self.links_table.outfile,\n            shared_content_outfile=self.shared_content_table.outfile,\n        )\n        # Coalesce the results in the CSV File to the links table\n        self.links_table.update_from_csv(datafile=self.links_table.outfile)\n        self.shared_content_table.update_from_csv(\n            datafile=self.shared_content_table.outfile\n        )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.other_social_media","title":"<code>other_social_media()</code>","text":"<p>For select URLs, update the 'work_type' column in the database's 'links' table with the value 'SocialMediaPosting'.</p> Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def other_social_media(self):\n    \"\"\"For select URLs, update the 'work_type' column in the database's 'links' table with the value 'SocialMediaPosting'.\"\"\"\n    # Assign default type to social media post\n    add_type_data(\n        data=self.filtered_links.other_social, outfile=self.links_table.outfile\n    )\n    # Coalesce the results in the CSV File to the links table\n    self.links_table.update_from_csv(datafile=self.links_table.outfile)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.scraper","title":"<code>scraper()</code>","text":"<p>For select URLs, collect data via scraping and coalesce in the database's 'links' table.</p> Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def scraper(self):\n    \"\"\"For select URLs, collect data via scraping and coalesce in the database's 'links' table.\"\"\"\n\n    # In multiple threads, scrape HTML data and write to a CSV file\n    get_article_text(\n        data=self.filtered_links.to_scrape, outfile=self.links_table.outfile\n    )\n    # Coalesce the results in the CSV File to the links table\n    self.links_table.update_from_csv(datafile=self.links_table.outfile)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.youtube","title":"<code>youtube()</code>","text":"<p>For YouTube URLs, collect data from YouTube API and coalesce in the database's 'links' table.</p> Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def youtube(self):\n    \"\"\"For YouTube URLs, collect data from YouTube API and coalesce in the database's 'links' table.\"\"\"\n    if self.keys.youtube_key:\n        # In single thread, collect YouTube API data and write to a CSV file\n        get_youtube_data(\n            data=self.filtered_links.youtube,\n            keys=self.keys.youtube_key,\n            outfile=self.links_table.outfile,\n        )\n        # Coalesce the results in the CSV File to the links table\n        self.links_table.update_from_csv(datafile=self.links_table.outfile)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.utils","title":"<code>minall.enrichment.utils</code>","text":"<p>Functions for data collection.</p> <p>This module provides the following class and functions:</p> <ul> <li><code>get_domain(url)</code> - Parse domain from URL string.</li> <li><code>apply_domain(url)</code> - Generate SQL query to insert domain into table.</li> <li><code>FilteredLinks(table)</code> - From SQL table, select subsets of URLs based on domain name.</li> </ul>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks","title":"<code>FilteredLinks</code>","text":"<p>Selects all URLs from SQL table and returns subsets.</p> Source code in <code>minall/enrichment/utils.py</code> <pre><code>class FilteredLinks:\n    \"\"\"Selects all URLs from SQL table and returns subsets.\"\"\"\n\n    def __init__(self, table: LinksTable) -&gt; None:\n        \"\"\"Select and store all URLs from a target SQL table.\n\n        Args:\n            table (BaseTable): Target SQL table.\n        \"\"\"\n        cursor = table.conn.cursor()\n        self.all_links = [\n            row[0] for row in cursor.execute(f\"SELECT url FROM {table.name}\").fetchall()\n        ]\n\n    @property\n    def youtube(self) -&gt; List[str]:\n        \"\"\"List of URLs from YouTube.\n\n        Returns:\n            List[str]: List of URL strings.\n        \"\"\"\n        return [url for url in self.all_links if is_youtube_url(url=url)]\n\n    @property\n    def facebook(self) -&gt; List[str]:\n        \"\"\"List of URLs from Facebook.\n\n        Returns:\n            List[str]: List of URL strings.\n        \"\"\"\n        return [url for url in self.all_links if is_facebook_url(url=url)]\n\n    @property\n    def other_social(self) -&gt; List[str]:\n        \"\"\"List of URLs from social media platforms.\n\n        Returns:\n            List[str]: List of URL strings.\n        \"\"\"\n        return [\n            url\n            for url in self.all_links\n            if get_domain(url=url)\n            in [\n                \"facebook.com\",\n                \"youtube.com\",\n                \"tiktok.com\",\n                \"instagram.com\",\n                \"twitter.com\",\n                \"snapchat.com\",\n            ]\n        ]\n\n    @property\n    def to_scrape(self) -&gt; List[str]:\n        \"\"\"List of URLs not from social media platforms.\n\n        Returns:\n            List[str]: List of URL strings.\n        \"\"\"\n        return [\n            url\n            for url in self.all_links\n            if get_domain(url=url)\n            not in [\n                \"facebook.com\",\n                \"youtube.com\",\n                \"tiktok.com\",\n                \"instagram.com\",\n                \"twitter.com\",\n                \"snapchat.com\",\n            ]\n        ]\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks.facebook","title":"<code>facebook: List[str]</code>  <code>property</code>","text":"<p>List of URLs from Facebook.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of URL strings.</p>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks.other_social","title":"<code>other_social: List[str]</code>  <code>property</code>","text":"<p>List of URLs from social media platforms.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of URL strings.</p>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks.to_scrape","title":"<code>to_scrape: List[str]</code>  <code>property</code>","text":"<p>List of URLs not from social media platforms.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of URL strings.</p>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks.youtube","title":"<code>youtube: List[str]</code>  <code>property</code>","text":"<p>List of URLs from YouTube.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of URL strings.</p>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks.__init__","title":"<code>__init__(table)</code>","text":"<p>Select and store all URLs from a target SQL table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>BaseTable</code> <p>Target SQL table.</p> required Source code in <code>minall/enrichment/utils.py</code> <pre><code>def __init__(self, table: LinksTable) -&gt; None:\n    \"\"\"Select and store all URLs from a target SQL table.\n\n    Args:\n        table (BaseTable): Target SQL table.\n    \"\"\"\n    cursor = table.conn.cursor()\n    self.all_links = [\n        row[0] for row in cursor.execute(f\"SELECT url FROM {table.name}\").fetchall()\n    ]\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.utils.apply_domain","title":"<code>apply_domain(url)</code>","text":"<p>Compose SQL query to update the domain column of a URL's row in the 'links' SQLite table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apply_domain(url=\"https://www.youtube.com/channel/MkDocs\")\n(\"UPDATE links SET domain = 'youtube.com' WHERE url = 'https://www.youtube.com/channel/MkDocs'\", 'youtube.com')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL string.</p> required <p>Returns:</p> Type Description <code>Tuple[str | None, str | None]</code> <p>Tuple[str | None, str | None]: If domain was parsed, a tuple containing the SQL query and domain name.</p> Source code in <code>minall/enrichment/utils.py</code> <pre><code>def apply_domain(url: str) -&gt; Tuple[str | None, str | None]:\n    \"\"\"Compose SQL query to update the domain column of a URL's row in the 'links' SQLite table.\n\n    Examples:\n        &gt;&gt;&gt; apply_domain(url=\"https://www.youtube.com/channel/MkDocs\")\n        (\"UPDATE links SET domain = 'youtube.com' WHERE url = 'https://www.youtube.com/channel/MkDocs'\", 'youtube.com')\n\n    Args:\n        url (str): URL string.\n\n    Returns:\n        Tuple[str | None, str | None]: If domain was parsed, a tuple containing the SQL query and domain name.\n    \"\"\"\n\n    query = None\n    domain = get_domain(url)\n    if domain:\n        query = f\"UPDATE {LinksConstants.table_name} SET domain = '{domain}' WHERE {LinksConstants.primary_key} = '{url}'\"\n    return query, domain\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.utils.get_domain","title":"<code>get_domain(url)</code>","text":"<p>Parse the domain name of a given URL string.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_domain(url=\"https://www.youtube.com/channel/MkDocs\")\n'youtube.com'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL string.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: If successfully parsed, domain name.</p> Source code in <code>minall/enrichment/utils.py</code> <pre><code>def get_domain(url: str) -&gt; str | None:\n    \"\"\"Parse the domain name of a given URL string.\n\n    Examples:\n        &gt;&gt;&gt; get_domain(url=\"https://www.youtube.com/channel/MkDocs\")\n        'youtube.com'\n\n    Args:\n        url (str): URL string.\n\n    Returns:\n        str | None: If successfully parsed, domain name.\n    \"\"\"\n\n    domain_name = ural.get_domain_name(url)\n    if domain_name in YOUTUBE_DOMAINS:\n        domain_name = \"youtube.com\"\n    return domain_name\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text","title":"<code>minall.enrichment.article_text</code>","text":"<p>Something.</p>"},{"location":"reference/enrichment/#minall.enrichment.article_text.scraper","title":"<code>minall.enrichment.article_text.scraper</code>","text":"<p>Class and helper function for scraping HTML.</p> <p>This module's <code>Scraper</code> class enhances minet's <code>request()</code> and <code>extract()</code> methods by providing additional support for unexpected HTML encodings.</p> <ol> <li>Uses minet's <code>request()</code> method on a target URL to get a <code>Response</code> object.</li> <li>Verifies that the <code>Response</code> object is encoded in some form of utf-8.</li> <li>Extracts the HTML body from the <code>Response</code>. [<code>text = response.text()</code>]</li> <li>Uses bs4's fool-proof <code>UnicodeDammit</code> to parse the exact encoding. [<code>UnicodeDammit(text, \"html.parser\").declared_html_encoding</code>]</li> <li>Gives the encoding to bs4's <code>BeautifulSoup</code> to parse the HTML.</li> <li>Gives the <code>BeautifulSoup</code> result to minet's <code>extract()</code> method in order to return minet's <code>TrafilaturaResult</code> object.</li> </ol>"},{"location":"reference/enrichment/#minall.enrichment.article_text.scraper.Scraper","title":"<code>Scraper</code>","text":"<p>Class to manage HTML scraping.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; scraper = Scraper()\n&gt;&gt;&gt; url, result = scraper(url='https://zenodo.org/records/7974793')\n&gt;&gt;&gt; url == result.canonical_url\nTrue\n&gt;&gt;&gt; result.title\n'Minet, a webmining CLI tool &amp; library for python.'\n</code></pre> Source code in <code>minall/enrichment/article_text/scraper.py</code> <pre><code>class Scraper:\n    \"\"\"Class to manage HTML scraping.\n\n    Examples:\n        &gt;&gt;&gt; scraper = Scraper()\n        &gt;&gt;&gt; url, result = scraper(url='https://zenodo.org/records/7974793')\n        &gt;&gt;&gt; url == result.canonical_url\n        True\n        &gt;&gt;&gt; result.title\n        'Minet, a webmining CLI tool &amp; library for python.'\n    \"\"\"\n\n    def __init__(\n        self, progress: Progress | None = None, total: int | None = None\n    ) -&gt; None:\n        \"\"\"If provided the context of a rich progress bar, save it to the class instance and add the task 'Scraping webpage'.\n\n        Args:\n            progress (Progress | None, optional): Context of a rich progress bar instance. Defaults to None.\n            total (int | None, optional): Total number of items treated during progress context. Defaults to None.\n        \"\"\"\n        self.progress = progress\n        if progress:\n            self.progress = progress\n            t = progress.add_task(\n                description=\"[bold yellow]Scraping webpage\", total=total\n            )\n            self.task_id = t\n\n    def __call__(self, url: str) -&gt; Tuple[str, TrafilaturaResult | None]:\n        \"\"\"Requests and scrapes HTML, returning minet's Trafilatura Result object.\n\n        Args:\n            url (str): Target URL.\n\n        Returns:\n            Tuple[str, TrafilaturaResult | None]: The target URL and, if scraping was successful, minet's Trafilatura Result object.\n        \"\"\"\n        if self.progress:\n            self.progress.advance(self.task_id)\n        result = None\n        response = None\n\n        # Request URL's HTML\n        try:\n            response = request(url)\n        except Exception as e:\n            logging.error(e)\n\n        # Parse requested HTML\n        if response and good_response(response):\n            text = response.text()\n            try:\n                # Avoid input conversion error, deriving from inside Trafilatura's lxml dependency\n                encoding = UnicodeDammit(text, \"html.parser\").declared_html_encoding\n                soup = BeautifulSoup(text, features=\"lxml\", from_encoding=encoding)\n                text = soup.decode(formatter=\"html\")\n                result = extract(text)\n            except Exception as e:\n                logger.exception(e)\n        return url, result\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.scraper.Scraper.__call__","title":"<code>__call__(url)</code>","text":"<p>Requests and scrapes HTML, returning minet's Trafilatura Result object.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target URL.</p> required <p>Returns:</p> Type Description <code>Tuple[str, TrafilaturaResult | None]</code> <p>Tuple[str, TrafilaturaResult | None]: The target URL and, if scraping was successful, minet's Trafilatura Result object.</p> Source code in <code>minall/enrichment/article_text/scraper.py</code> <pre><code>def __call__(self, url: str) -&gt; Tuple[str, TrafilaturaResult | None]:\n    \"\"\"Requests and scrapes HTML, returning minet's Trafilatura Result object.\n\n    Args:\n        url (str): Target URL.\n\n    Returns:\n        Tuple[str, TrafilaturaResult | None]: The target URL and, if scraping was successful, minet's Trafilatura Result object.\n    \"\"\"\n    if self.progress:\n        self.progress.advance(self.task_id)\n    result = None\n    response = None\n\n    # Request URL's HTML\n    try:\n        response = request(url)\n    except Exception as e:\n        logging.error(e)\n\n    # Parse requested HTML\n    if response and good_response(response):\n        text = response.text()\n        try:\n            # Avoid input conversion error, deriving from inside Trafilatura's lxml dependency\n            encoding = UnicodeDammit(text, \"html.parser\").declared_html_encoding\n            soup = BeautifulSoup(text, features=\"lxml\", from_encoding=encoding)\n            text = soup.decode(formatter=\"html\")\n            result = extract(text)\n        except Exception as e:\n            logger.exception(e)\n    return url, result\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.scraper.Scraper.__init__","title":"<code>__init__(progress=None, total=None)</code>","text":"<p>If provided the context of a rich progress bar, save it to the class instance and add the task 'Scraping webpage'.</p> <p>Parameters:</p> Name Type Description Default <code>progress</code> <code>Progress | None</code> <p>Context of a rich progress bar instance. Defaults to None.</p> <code>None</code> <code>total</code> <code>int | None</code> <p>Total number of items treated during progress context. Defaults to None.</p> <code>None</code> Source code in <code>minall/enrichment/article_text/scraper.py</code> <pre><code>def __init__(\n    self, progress: Progress | None = None, total: int | None = None\n) -&gt; None:\n    \"\"\"If provided the context of a rich progress bar, save it to the class instance and add the task 'Scraping webpage'.\n\n    Args:\n        progress (Progress | None, optional): Context of a rich progress bar instance. Defaults to None.\n        total (int | None, optional): Total number of items treated during progress context. Defaults to None.\n    \"\"\"\n    self.progress = progress\n    if progress:\n        self.progress = progress\n        t = progress.add_task(\n            description=\"[bold yellow]Scraping webpage\", total=total\n        )\n        self.task_id = t\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.scraper.good_response","title":"<code>good_response(response)</code>","text":"<p>Verifies that the response that minet's request method returned is valid for scraping.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>Response</code> <p>Response object returned from minet's request method.</p> required <p>Returns:</p> Type Description <code>Response | None</code> <p>Response | None: If valid, the Response; otherwise None.</p> Source code in <code>minall/enrichment/article_text/scraper.py</code> <pre><code>def good_response(response: Response) -&gt; Response | None:\n    \"\"\"Verifies that the response that minet's request method returned is valid for scraping.\n\n    Args:\n        response (Response): Response object returned from minet's request method.\n\n    Returns:\n        Response | None: If valid, the Response; otherwise None.\n    \"\"\"\n    if (\n        response.is_text\n        and response.encoding\n        and \"utf\" in response.encoding\n        and \"8\" in response.encoding\n    ):\n        return response\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.get_data","title":"<code>minall.enrichment.article_text.get_data</code>","text":"<p>Something.</p>"},{"location":"reference/enrichment/#minall.enrichment.article_text.constants","title":"<code>minall.enrichment.article_text.constants</code>","text":"<p>Something.</p>"},{"location":"reference/enrichment/#minall.enrichment.article_text.constants.NormalizedScrapedWebPage","title":"<code>NormalizedScrapedWebPage</code>  <code>dataclass</code>","text":"<p>             Bases: <code>TabularRecord</code></p> <p>summary</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>description</p> <code>title</code> <code>str | None</code> <p>description</p> <code>text</code> <code>str | None</code> <p>description</p> <code>date_published</code> <code>str | None</code> <p>description</p> <code>work_type</code> <code>str</code> <p>description. Default = \"WebPage\".</p> Source code in <code>minall/enrichment/article_text/constants.py</code> <pre><code>@dataclass\nclass NormalizedScrapedWebPage(TabularRecord):\n    \"\"\"_summary_\n\n    Attributes:\n        url (str): __description__\n        title (str | None): __description__\n        text (str | None): __description__\n        date_published (str | None): __description__\n        work_type (str): __description__. Default = \"WebPage\".\n    \"\"\"\n\n    url: str\n    title: str | None\n    text: str | None\n    date_published: str | None\n    work_type: str = \"WebPage\"\n\n    @classmethod\n    def from_payload(\n        cls,\n        url: str,\n        result: TrafilaturaResult,\n    ) -&gt; \"NormalizedScrapedWebPage\":\n        return NormalizedScrapedWebPage(\n            url=url, title=result.title, text=result.content, date_published=result.date\n        )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.contexts","title":"<code>minall.enrichment.article_text.contexts</code>","text":"<p>Something.</p>"},{"location":"reference/home/","title":"Code base","text":"<p>The structure of the documentation resembles the code's architecture. Each page, as shown in the navigation bar on the left, represents a module or a folder descending from the source code's directory, <code>minall/</code>. The descriptions and examples of individual classes and functions are generated automatically from dostrings written in the Python modules.</p> <p>Click through the pages/modules and scroll down to different Python objects, as seen on the pages' right-hand navigation bar, to explore how the code works.</p> <ul> <li><code>docs/</code></li> <li><code>minall/</code><ul> <li><code>cli/</code></li> <li><code>enrichment/</code></li> <li><code>tables/</code></li> <li><code>utils/</code></li> <li><code>__init__.py</code></li> <li><code>__version__.py</code></li> <li><code>main.py</code></li> </ul> </li> <li><code>tests/</code></li> </ul>"},{"location":"reference/main/","title":"Minall","text":"<p>To facilitate the project's use as a Python library and as a CLI tool, <code>minall</code>'s workflow is managed via an exportable class, <code>Minall</code>.</p> <p>By creating a class instance of <code>Minall</code>, the following preliminary steps are taken:</p> <ul> <li>API credentials for the <code>minet</code> clients are parsed. (param: <code>config</code>)</li> <li>File paths to the workflow's eventual output, CSV files for the target URLs (<code>links.csv</code>) and their shared content (<code>shared_content.csv</code>), are prepared. This includes the creation of any necessary parent directories. (param: <code>out_dir</code>)</li> <li>The SQLite database connection is created. The connection can either be in-memory or, if a file path is provided, to an embedded SQLite database. If the user wants <code>Minall</code> to create and store the workflow's results in an SQLite database file, simply providing a file path will also create the file. (param: <code>database</code>)</li> <li>Through the SQLite connection, SQL tables are created for the user-provided data files. A file of target URLs is necessary, whose data will be parsed and inserted into the 'links' SQL table. (param: <code>links_file</code>, <code>url_col</code>, <code>shared_content_file</code>)</li> <li>The class instance remembers whether to (a) deploy all of the <code>minall</code> enrichment workflow or (b) only collect the generalized Buzzsumo metadata. (param: <code>buzzsumo_only</code>)</li> </ul>"},{"location":"reference/main/#minall.main","title":"<code>minall.main</code>","text":"<p>Minall enrichment workflow.</p> <p>With the class <code>Minall</code>, this module manages the entire workflow.</p> <p>The class contains the following methods:</p> <ul> <li><code>__init__(database, config, output_dir, links_file, url_col, shared_content_file, buzzsumo_only)</code> - Intialize SQLite database and out-file paths.</li> <li><code>collect_and_coalesce()</code> - Collect new data and coalesce with existing data in relevant SQL tables.</li> <li><code>export()</code> - Write enriched SQL tables to CSV out-files.</li> </ul>"},{"location":"reference/main/#minall.main.Minall","title":"<code>Minall</code>","text":"<p>Class to store variables and execute steps of enrichment.</p> Source code in <code>minall/main.py</code> <pre><code>class Minall:\n    \"\"\"Class to store variables and execute steps of enrichment.\"\"\"\n\n    def __init__(\n        self,\n        database: str | None,\n        config: str | dict | None,\n        output_dir: Path | str,\n        links_file: Path | str,\n        url_col: str,\n        shared_content_file: Path | str | None = None,\n        buzzsumo_only: bool = False,\n    ) -&gt; None:\n        \"\"\"Intialize SQLite database and out-file paths.\n\n        Examples:\n            &gt;&gt;&gt; # Set file path variables.\n            &gt;&gt;&gt; OUT_DIR = Path(__file__).parent.parent.joinpath(\"docs\").joinpath(\"doctest\")\n            &gt;&gt;&gt; LINKS_FILE = OUT_DIR.joinpath('minall_init_example.csv')\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Create Minall instance.\n            &gt;&gt;&gt; minall = Minall(database=None, config={}, output_dir=str(OUT_DIR), links_file=str(LINKS_FILE), url_col='target_url')\n            &gt;&gt;&gt; minall.links_table.table\n            LinksConstants(table_name='links', primary_key='url')\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Check that Minall's SQLite database connection has committed 1 change (creating the 'links' table).\n            &gt;&gt;&gt; minall.connection.total_changes\n            1\n\n        Args:\n            database (str | None): Path name to SQLite database. If None, creates database in memory.\n            config (str | dict | None): Credentials for API keys.\n            output_dir (Path | str): Path to directory for enriched CSV files.\n            links_file (Path | str): Path to in-file for URLs.\n            url_col (str): Name of URL column in URLs file.\n            shared_content_file (str | None): Path name to CSV file of shared content related to URLs.\n            buzzsumo_only (bool, optional): Whether to only run Buzzsumo enrichment. Defaults to False.\n        \"\"\"\n\n        # Connect to the SQLite database\n        self.connection = connect_to_database(database=database)\n\n        # Parse API keys from config file / dict\n        self.keys = APIKeys(config=config)\n\n        # Store Buzzsumo-only flag\n        self.buzzsumo_only = buzzsumo_only\n\n        # Set paths to output directory and out-files\n        if not isinstance(output_dir, Path):\n            output_dir = Path(output_dir)\n        self.output_dir = output_dir\n        self.output_dir.mkdir(exist_ok=True)\n        [p.mkdir(exist_ok=True) for p in self.output_dir.parents]\n        self.links_file = self.output_dir.joinpath(\"links.csv\")\n        self.shared_contents_file = self.output_dir.joinpath(\"shared_content.csv\")\n\n        # Input original data into the database\n        if not isinstance(links_file, Path):\n            links_file = Path(links_file)\n        self.links_table = LinksTable(\n            conn=self.connection,\n            infile=links_file,\n            url_col=url_col,\n            outfile=self.links_file,\n        )\n\n        if isinstance(shared_content_file, str):\n            shared_content_file = Path(shared_content_file)\n        self.shared_content_table = SharedContentTable(\n            conn=self.connection,\n            infile=shared_content_file,\n            outfile=self.shared_contents_file,\n        )\n\n    def collect_and_coalesce(self):\n        \"\"\"Collect new data and coalesce with existing data in relevant SQL tables.\n\n        This method creates an instance of the class `Enrichment` (from `minall.enrichment.enrichment`), providing the target URL table ('links' table, `self.links_table`), the minet API credentials (`self.keys`), and the related shared content table (`self.shared_content_table`) which may go unused depending on parameters used when `Enrichment` is called.\n\n        Having prepared the `Enrichment` instance, the method then calls the class, providing its `self.buzzsumo_only` instance attribute as the argument for `Enrichment`'s `buzzsumo_only` parameter. The latter boolean parameter determines whether all of the `Enrichment` class's methods will be deployed or only its Buzzsumo method.\n        \"\"\"\n        enricher = Enrichment(\n            links_table=self.links_table,\n            shared_content_table=self.shared_content_table,\n            keys=self.keys,\n        )\n        enricher(buzzsumo_only=self.buzzsumo_only)\n\n    def export(self) -&gt; Tuple[Path, Path]:\n        \"\"\"Write enriched SQL tables to CSV out-files.\n\n        This method simply exports to CSV files both of the `Minall` class instance's SQL tables, `self.links_table` and `self.shared_content_table`. The class that manages the SQL tables (`minall.tables.base.BaseTable`), stores each table's out-file path as an instance variable. The parent directory for both out-files was declared during `Minall`'s `__init__()` method via the parameter `output_dir`, from which the out-file paths were subsequently derived.\n\n        Returns:\n            Tuple[Path, Path]: Paths to links and shared content CSV files.\n        \"\"\"\n        self.links_table.export()\n        self.shared_content_table.export()\n        return self.links_file, self.shared_contents_file\n</code></pre>"},{"location":"reference/main/#minall.main.Minall.__init__","title":"<code>__init__(database, config, output_dir, links_file, url_col, shared_content_file=None, buzzsumo_only=False)</code>","text":"<p>Intialize SQLite database and out-file paths.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Set file path variables.\n&gt;&gt;&gt; OUT_DIR = Path(__file__).parent.parent.joinpath(\"docs\").joinpath(\"doctest\")\n&gt;&gt;&gt; LINKS_FILE = OUT_DIR.joinpath('minall_init_example.csv')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create Minall instance.\n&gt;&gt;&gt; minall = Minall(database=None, config={}, output_dir=str(OUT_DIR), links_file=str(LINKS_FILE), url_col='target_url')\n&gt;&gt;&gt; minall.links_table.table\nLinksConstants(table_name='links', primary_key='url')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check that Minall's SQLite database connection has committed 1 change (creating the 'links' table).\n&gt;&gt;&gt; minall.connection.total_changes\n1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>database</code> <code>str | None</code> <p>Path name to SQLite database. If None, creates database in memory.</p> required <code>config</code> <code>str | dict | None</code> <p>Credentials for API keys.</p> required <code>output_dir</code> <code>Path | str</code> <p>Path to directory for enriched CSV files.</p> required <code>links_file</code> <code>Path | str</code> <p>Path to in-file for URLs.</p> required <code>url_col</code> <code>str</code> <p>Name of URL column in URLs file.</p> required <code>shared_content_file</code> <code>str | None</code> <p>Path name to CSV file of shared content related to URLs.</p> <code>None</code> <code>buzzsumo_only</code> <code>bool</code> <p>Whether to only run Buzzsumo enrichment. Defaults to False.</p> <code>False</code> Source code in <code>minall/main.py</code> <pre><code>def __init__(\n    self,\n    database: str | None,\n    config: str | dict | None,\n    output_dir: Path | str,\n    links_file: Path | str,\n    url_col: str,\n    shared_content_file: Path | str | None = None,\n    buzzsumo_only: bool = False,\n) -&gt; None:\n    \"\"\"Intialize SQLite database and out-file paths.\n\n    Examples:\n        &gt;&gt;&gt; # Set file path variables.\n        &gt;&gt;&gt; OUT_DIR = Path(__file__).parent.parent.joinpath(\"docs\").joinpath(\"doctest\")\n        &gt;&gt;&gt; LINKS_FILE = OUT_DIR.joinpath('minall_init_example.csv')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create Minall instance.\n        &gt;&gt;&gt; minall = Minall(database=None, config={}, output_dir=str(OUT_DIR), links_file=str(LINKS_FILE), url_col='target_url')\n        &gt;&gt;&gt; minall.links_table.table\n        LinksConstants(table_name='links', primary_key='url')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Check that Minall's SQLite database connection has committed 1 change (creating the 'links' table).\n        &gt;&gt;&gt; minall.connection.total_changes\n        1\n\n    Args:\n        database (str | None): Path name to SQLite database. If None, creates database in memory.\n        config (str | dict | None): Credentials for API keys.\n        output_dir (Path | str): Path to directory for enriched CSV files.\n        links_file (Path | str): Path to in-file for URLs.\n        url_col (str): Name of URL column in URLs file.\n        shared_content_file (str | None): Path name to CSV file of shared content related to URLs.\n        buzzsumo_only (bool, optional): Whether to only run Buzzsumo enrichment. Defaults to False.\n    \"\"\"\n\n    # Connect to the SQLite database\n    self.connection = connect_to_database(database=database)\n\n    # Parse API keys from config file / dict\n    self.keys = APIKeys(config=config)\n\n    # Store Buzzsumo-only flag\n    self.buzzsumo_only = buzzsumo_only\n\n    # Set paths to output directory and out-files\n    if not isinstance(output_dir, Path):\n        output_dir = Path(output_dir)\n    self.output_dir = output_dir\n    self.output_dir.mkdir(exist_ok=True)\n    [p.mkdir(exist_ok=True) for p in self.output_dir.parents]\n    self.links_file = self.output_dir.joinpath(\"links.csv\")\n    self.shared_contents_file = self.output_dir.joinpath(\"shared_content.csv\")\n\n    # Input original data into the database\n    if not isinstance(links_file, Path):\n        links_file = Path(links_file)\n    self.links_table = LinksTable(\n        conn=self.connection,\n        infile=links_file,\n        url_col=url_col,\n        outfile=self.links_file,\n    )\n\n    if isinstance(shared_content_file, str):\n        shared_content_file = Path(shared_content_file)\n    self.shared_content_table = SharedContentTable(\n        conn=self.connection,\n        infile=shared_content_file,\n        outfile=self.shared_contents_file,\n    )\n</code></pre>"},{"location":"reference/main/#minall.main.Minall.collect_and_coalesce","title":"<code>collect_and_coalesce()</code>","text":"<p>Collect new data and coalesce with existing data in relevant SQL tables.</p> <p>This method creates an instance of the class <code>Enrichment</code> (from <code>minall.enrichment.enrichment</code>), providing the target URL table ('links' table, <code>self.links_table</code>), the minet API credentials (<code>self.keys</code>), and the related shared content table (<code>self.shared_content_table</code>) which may go unused depending on parameters used when <code>Enrichment</code> is called.</p> <p>Having prepared the <code>Enrichment</code> instance, the method then calls the class, providing its <code>self.buzzsumo_only</code> instance attribute as the argument for <code>Enrichment</code>'s <code>buzzsumo_only</code> parameter. The latter boolean parameter determines whether all of the <code>Enrichment</code> class's methods will be deployed or only its Buzzsumo method.</p> Source code in <code>minall/main.py</code> <pre><code>def collect_and_coalesce(self):\n    \"\"\"Collect new data and coalesce with existing data in relevant SQL tables.\n\n    This method creates an instance of the class `Enrichment` (from `minall.enrichment.enrichment`), providing the target URL table ('links' table, `self.links_table`), the minet API credentials (`self.keys`), and the related shared content table (`self.shared_content_table`) which may go unused depending on parameters used when `Enrichment` is called.\n\n    Having prepared the `Enrichment` instance, the method then calls the class, providing its `self.buzzsumo_only` instance attribute as the argument for `Enrichment`'s `buzzsumo_only` parameter. The latter boolean parameter determines whether all of the `Enrichment` class's methods will be deployed or only its Buzzsumo method.\n    \"\"\"\n    enricher = Enrichment(\n        links_table=self.links_table,\n        shared_content_table=self.shared_content_table,\n        keys=self.keys,\n    )\n    enricher(buzzsumo_only=self.buzzsumo_only)\n</code></pre>"},{"location":"reference/main/#minall.main.Minall.export","title":"<code>export()</code>","text":"<p>Write enriched SQL tables to CSV out-files.</p> <p>This method simply exports to CSV files both of the <code>Minall</code> class instance's SQL tables, <code>self.links_table</code> and <code>self.shared_content_table</code>. The class that manages the SQL tables (<code>minall.tables.base.BaseTable</code>), stores each table's out-file path as an instance variable. The parent directory for both out-files was declared during <code>Minall</code>'s <code>__init__()</code> method via the parameter <code>output_dir</code>, from which the out-file paths were subsequently derived.</p> <p>Returns:</p> Type Description <code>Tuple[Path, Path]</code> <p>Tuple[Path, Path]: Paths to links and shared content CSV files.</p> Source code in <code>minall/main.py</code> <pre><code>def export(self) -&gt; Tuple[Path, Path]:\n    \"\"\"Write enriched SQL tables to CSV out-files.\n\n    This method simply exports to CSV files both of the `Minall` class instance's SQL tables, `self.links_table` and `self.shared_content_table`. The class that manages the SQL tables (`minall.tables.base.BaseTable`), stores each table's out-file path as an instance variable. The parent directory for both out-files was declared during `Minall`'s `__init__()` method via the parameter `output_dir`, from which the out-file paths were subsequently derived.\n\n    Returns:\n        Tuple[Path, Path]: Paths to links and shared content CSV files.\n    \"\"\"\n    self.links_table.export()\n    self.shared_content_table.export()\n    return self.links_file, self.shared_contents_file\n</code></pre>"},{"location":"reference/tables/","title":"Table tools","text":"<p>With SQLite, the module <code>minall/tables</code> manages the data during the enrichment process, from the data input at the start to the updated version exported at the end. The process relies on the following two tables:</p> <ol> <li> <p>The <code>links</code> table, which is the backbone of the enrichment, stores the target URLs and their enriched metadata.</p> </li> <li> <p>The <code>shared_content</code> table, which is optional, stores URLs pointing to content shared via the target URLs' content.</p> </li> </ol> <p>As illustrated in the figure below, the two tables are related. The target URL (<code>url</code>) in the <code>links</code> table refers to the <code>post_url</code> in the <code>shared_content</code> table. A target URL (<code>url</code>) in the <code>links</code> table can share 0 or more items. Depending on the URLs dataset, it could be the case that no entities in the <code>links</code> table have shared any content. All entities in the <code>shared_content</code> must relate to at least one entity in the <code>links</code> table. Content in the <code>shared_content</code> table can have been shared by 1 or more URLs in the <code>links</code> table.</p> <pre><code>erDiagram\n    LINKS }|--o{ SHARED_CONTENT : shares\n    LINKS {\n        text url PK\n        text domain\n        text work_type\n        text duration\n        text identifier\n        text date_published\n        text date_modified\n        text country_of_origin\n        text abstract\n        text keywords\n        text title\n        text text\n        text hashtags\n        text creator_type\n        text creator_date_created\n        text creator_identifier\n        integer creator_facebook_follow\n        integer creator_facebook_subscribe\n        integer creator_twitter_follow\n        integer creator_youtube_subscribe\n        integer creator_create_video\n        text creator_name\n        text creator_url\n        integer facebook_comment\n        integer facebook_like\n        integer facebook_share\n        integer pinterest_share\n        integer twitter_share\n        integer tiktok_share\n        integer tiktok_comment\n        integer reddit_engagement\n        integer youtube_watch\n        integer youtube_comment\n        integer youtube_like\n        integer youtube_favorite\n        integer youtube_subscribe\n        integer create_video\n    }\n    SHARED_CONTENT {\n        text post_url PK\n        text content_url PK\n        text media_type\n        integer height\n        integer width\n    }</code></pre>"},{"location":"reference/tables/#minall.tables.links","title":"<code>minall.tables.links</code>","text":""},{"location":"reference/tables/#minall.tables.links.LinksConstants","title":"<code>LinksConstants</code>  <code>dataclass</code>","text":"<p>Dataclass to manage 'links' table.</p> <p>This dataclass manages the 'links' table's required column names and their data types.</p> <p>Attributes:</p> Name Type Description <code>table_name</code> <code>str</code> <p>Name of the table. Default = \"links\".</p> <code>primary_key</code> <code>str</code> <p>Text string of primary key. Default = \"url\".</p> <code>pk_list</code> <code>list</code> <p>List of primary key columns. Default = [\"url\"]</p> <code>dtypes</code> <code>dict</code> <p>Key-value pairs of column names and SQLite data type descriptions.</p> <code>col_names</code> <code>list</code> <p>List of column names.</p> Source code in <code>minall/tables/links.py</code> <pre><code>@dataclass\nclass LinksConstants:\n    \"\"\"Dataclass to manage 'links' table.\n\n    This dataclass manages the 'links' table's required column names and their data types.\n\n    Attributes:\n        table_name (str): Name of the table. Default = \"links\".\n        primary_key (str): Text string of primary key. Default = \"url\".\n        pk_list (list): List of primary key columns. Default = [\"url\"]\n        dtypes (dict): Key-value pairs of column names and SQLite data type descriptions.\n        col_names (list): List of column names.\n    \"\"\"\n\n    table_name: str = \"links\"\n    primary_key: str = \"url\"\n    pk_list = [\"url\"]\n    dtypes = {\n        \"url\": \"TEXT\",\n        \"domain\": \"TEXT\",\n        \"work_type\": \"TEXT\",\n        \"duration\": \"TEXT\",\n        \"identifier\": \"TEXT\",\n        \"date_published\": \"TEXT\",\n        \"date_modified\": \"TEXT\",\n        \"country_of_origin\": \"TEXT\",\n        \"abstract\": \"TEXT\",\n        \"keywords\": \"TEXT\",\n        \"title\": \"TEXT\",\n        \"text\": \"TEXT\",\n        \"hashtags\": \"TEXT\",\n        \"creator_type\": \"TEXT\",\n        \"creator_date_created\": \"TEXT\",\n        \"creator_location_created\": \"TEXT\",\n        \"creator_identifier\": \"TEXT\",\n        \"creator_facebook_follow\": \"INTEGER\",\n        \"creator_facebook_subscribe\": \"INTEGER\",\n        \"creator_twitter_follow\": \"INTEGER\",\n        \"creator_youtube_subscribe\": \"INTEGER\",\n        \"creator_create_video\": \"INTEGER\",\n        \"creator_name\": \"TEXT\",\n        \"creator_url\": \"TEXT\",\n        \"facebook_comment\": \"INTEGER\",\n        \"facebook_like\": \"INTEGER\",\n        \"facebook_share\": \"INTEGER\",\n        \"pinterest_share\": \"INTEGER\",\n        \"twitter_share\": \"INTEGER\",\n        \"tiktok_share\": \"INTEGER\",\n        \"tiktok_comment\": \"INTEGER\",\n        \"reddit_engagement\": \"INTEGER\",\n        \"youtube_watch\": \"INTEGER\",\n        \"youtube_comment\": \"INTEGER\",\n        \"youtube_like\": \"INTEGER\",\n        \"youtube_favorite\": \"INTEGER\",\n        \"youtube_subscribe\": \"INTEGER\",\n        \"create_video\": \"INTEGER\",\n    }\n    col_names = dtypes.keys()\n</code></pre>"},{"location":"reference/tables/#minall.tables.links.LinksTable","title":"<code>LinksTable</code>","text":"<p>             Bases: <code>BaseTable</code></p> <p>Class for creating, updating, and reading SQL table for target URLs.</p> Source code in <code>minall/tables/links.py</code> <pre><code>class LinksTable(BaseTable):\n    \"\"\"Class for creating, updating, and reading SQL table for target URLs.\"\"\"\n\n    dtypes = LinksConstants.dtypes\n    name = LinksConstants.table_name\n    pk_list = LinksConstants.pk_list\n\n    def __init__(\n        self, conn: Connection, infile: Path, outfile: Path, url_col: str | None = None\n    ):\n        \"\"\"In database connection, create SQL table and populate with data from target URLs dataset file.\n\n        Args:\n            conn (Connection): SQLite connection.\n            infile (Path): Path to URLs dataset file.\n            url_col (str | None, optional): Column name of target URLs. Defaults to None.\n\n        Raises:\n            NoCSVHeaders: Dataset file does not have headers.\n            KeyError: User did not define URL column and dataset file does not have default column 'url'.\n            NoURLColumn: User-defined URL column not found in dataset file.\n        \"\"\"\n        # Update the table's columns to include all in-file columns\n        self.dtypes = self._parse_infile_columns(\n            infile=infile, url_col=url_col, constant_cols=self.dtypes\n        )\n        # Inherit the parent base class\n        super().__init__(\n            name=self.name,\n            pk=self.pk_list,\n            dtypes=self.dtypes,\n            conn=conn,\n            outfile=outfile,\n        )\n\n        # Insert in-file data\n        with open(infile) as f:\n            reader = csv.DictReader(f)\n\n            # Confirm the in-file is compatible with the table\n            headers = reader.fieldnames\n            if not headers:\n                raise NoCSVHeaders()\n            elif len(set(headers).difference(self.dtype_dict.keys())) &gt; 0:\n                raise KeyError()\n\n            # Insert the in-file data\n            for row in reader:\n                if url_col:\n                    row.update({\"url\": row[url_col]})\n                placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n                cols, values = \", \".join(row.keys()), tuple(list(row.values()))\n                query = \"\"\"\n                INSERT OR IGNORE INTO {table}({cols})\n                VALUES ({placeholder})\n                \"\"\".format(\n                    table=self.name, cols=cols, placeholder=placeholder\n                )\n                self.execute(query=query, values=values)\n\n    def _parse_infile_columns(\n        self, infile: Path, constant_cols: Dict, url_col: str | None\n    ) -&gt; Dict:\n        \"\"\"During init method, modify table columns to include in-file's columns.\n\n        Args:\n            infile (Path): Path to URLs dataset.\n            constant_cols (Dict): Key-value pairs of table's standard columns and data types.\n            url_col (str | None, optional): Column name of target URLs.\n\n        Raises:\n            NoCSVHeaders: The infile does not have headers.\n            KeyError: The infile does not have a recognizable URL column.\n            NoURLColumn: The infile does not have the user-declared URL column.\n\n        Returns:\n            Dict: Key-value pairs of table's column names and data types.\n        \"\"\"\n        with casanova.reader(infile) as reader:\n            headers = reader.headers\n        if not headers:\n            raise NoCSVHeaders()\n        elif not url_col and not \"url\" in headers:\n            raise KeyError()\n        elif url_col and not url_col in headers:\n            raise NoURLColumn(url_col=url_col)\n        dtypes = {col: \"TEXT\" for col in headers}\n        return dtypes | constant_cols\n</code></pre>"},{"location":"reference/tables/#minall.tables.links.LinksTable.__init__","title":"<code>__init__(conn, infile, outfile, url_col=None)</code>","text":"<p>In database connection, create SQL table and populate with data from target URLs dataset file.</p> <p>Parameters:</p> Name Type Description Default <code>conn</code> <code>Connection</code> <p>SQLite connection.</p> required <code>infile</code> <code>Path</code> <p>Path to URLs dataset file.</p> required <code>url_col</code> <code>str | None</code> <p>Column name of target URLs. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>NoCSVHeaders</code> <p>Dataset file does not have headers.</p> <code>KeyError</code> <p>User did not define URL column and dataset file does not have default column 'url'.</p> <code>NoURLColumn</code> <p>User-defined URL column not found in dataset file.</p> Source code in <code>minall/tables/links.py</code> <pre><code>def __init__(\n    self, conn: Connection, infile: Path, outfile: Path, url_col: str | None = None\n):\n    \"\"\"In database connection, create SQL table and populate with data from target URLs dataset file.\n\n    Args:\n        conn (Connection): SQLite connection.\n        infile (Path): Path to URLs dataset file.\n        url_col (str | None, optional): Column name of target URLs. Defaults to None.\n\n    Raises:\n        NoCSVHeaders: Dataset file does not have headers.\n        KeyError: User did not define URL column and dataset file does not have default column 'url'.\n        NoURLColumn: User-defined URL column not found in dataset file.\n    \"\"\"\n    # Update the table's columns to include all in-file columns\n    self.dtypes = self._parse_infile_columns(\n        infile=infile, url_col=url_col, constant_cols=self.dtypes\n    )\n    # Inherit the parent base class\n    super().__init__(\n        name=self.name,\n        pk=self.pk_list,\n        dtypes=self.dtypes,\n        conn=conn,\n        outfile=outfile,\n    )\n\n    # Insert in-file data\n    with open(infile) as f:\n        reader = csv.DictReader(f)\n\n        # Confirm the in-file is compatible with the table\n        headers = reader.fieldnames\n        if not headers:\n            raise NoCSVHeaders()\n        elif len(set(headers).difference(self.dtype_dict.keys())) &gt; 0:\n            raise KeyError()\n\n        # Insert the in-file data\n        for row in reader:\n            if url_col:\n                row.update({\"url\": row[url_col]})\n            placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n            cols, values = \", \".join(row.keys()), tuple(list(row.values()))\n            query = \"\"\"\n            INSERT OR IGNORE INTO {table}({cols})\n            VALUES ({placeholder})\n            \"\"\".format(\n                table=self.name, cols=cols, placeholder=placeholder\n            )\n            self.execute(query=query, values=values)\n</code></pre>"},{"location":"reference/tables/#minall.tables.shared_content","title":"<code>minall.tables.shared_content</code>","text":""},{"location":"reference/tables/#minall.tables.shared_content.ShareContentConstants","title":"<code>ShareContentConstants</code>  <code>dataclass</code>","text":"<p>Dataclass to manage 'shared_content' table.</p> <p>This dataclass manages the 'shared_content' table's required column names and their data types. Being a dataclass, however, the instance of the class can also be subsequently modified to include other column names (and their data types) according to the input data. The 'shared_content' table is meant to relate to the 'links' table, wherein the former's 'post_url' column refers to the latter's 'url' column.</p> <p>Contrary to the 'links' table, whose primary key column can be derived from any declared target URL column in the input data, the 'shared_content' table requires the input data has the two columns that jointly compose its primary key, 'post_url' and 'content_url.'</p> <p>Attributes:</p> Name Type Description <code>table_name</code> <code>str</code> <p>Name of the table. Default = \"shared_content\".</p> <code>primary_key</code> <code>str</code> <p>Text string of composite primary key. Default = \"post_url,content_url\".</p> <code>pk_list</code> <code>list</code> <p>List of comosite primary key columns. Default = [\"post_url\", \"content_url]</p> <code>dtypes</code> <code>dict</code> <p>Key-value pairs of column names and SQLite data type descriptions.</p> <code>col_names</code> <code>list</code> <p>List of column names.</p> Source code in <code>minall/tables/shared_content.py</code> <pre><code>@dataclass\nclass ShareContentConstants:\n    \"\"\"Dataclass to manage 'shared_content' table.\n\n    This dataclass manages the 'shared_content' table's required column names and their data types. Being a dataclass, however, the instance of the class can also be subsequently modified to include other column names (and their data types) according to the input data. The 'shared_content' table is meant to relate to the 'links' table, wherein the former's 'post_url' column refers to the latter's 'url' column.\n\n    Contrary to the 'links' table, whose primary key column can be derived from any declared target URL column in the input data, the 'shared_content' table requires the input data has the two columns that jointly compose its primary key, 'post_url' and 'content_url.'\n\n    Attributes:\n        table_name (str): Name of the table. Default = \"shared_content\".\n        primary_key (str): Text string of composite primary key. Default = \"post_url,content_url\".\n        pk_list (list): List of comosite primary key columns. Default = [\"post_url\", \"content_url]\n        dtypes (dict): Key-value pairs of column names and SQLite data type descriptions.\n        col_names (list): List of column names.\n    \"\"\"\n\n    table_name = \"shared_content\"\n    primary_key = \"post_url,content_url\"\n    pk_list = [\"post_url\", \"content_url\"]\n    dtypes = {\n        \"post_url\": f\"TEXT REFERENCES {LinksConstants.table_name}(url) ON UPDATE CASCADE\",\n        \"media_type\": \"TEXT\",\n        \"content_url\": \"TEXT\",\n        \"height\": \"INTEGER\",\n        \"width\": \"INTEGER\",\n    }\n    col_names = dtypes.keys()\n</code></pre>"},{"location":"reference/tables/#minall.tables.shared_content.SharedContentTable","title":"<code>SharedContentTable</code>","text":"<p>             Bases: <code>BaseTable</code></p> <p>Class for creating, updating, and reading SQL table for shared media content, each of which is related to 1 or more entities in the 'links' table.</p> Source code in <code>minall/tables/shared_content.py</code> <pre><code>class SharedContentTable(BaseTable):\n    \"\"\"Class for creating, updating, and reading SQL table for shared media content, each of which is related to 1 or more entities in the 'links' table.\"\"\"\n\n    dtypes = ShareContentConstants.dtypes\n    name = ShareContentConstants.table_name\n    pk_list = ShareContentConstants.pk_list\n\n    def __init__(self, conn: Connection, infile: Path | None, outfile: Path):\n        \"\"\"In database connection, create SQL table. If the user provides an existing shared_content.csv file, populate the table with that input.\n\n        Args:\n            conn (Connection): SQLite connection.\n            infile (Path): Path to shared content dataset file.\n\n        Raises:\n            NoCSVHeaders: Dataset file does not have headers.\n            NoPrimaryKeyColumns: One or more of the required columns ('post_url', 'content_url') is not in the dataset file.\n        \"\"\"\n        # Update the table's columns to include all in-file columns\n        if infile:\n            self.dtypes = self._parse_infile_columns(\n                infile=infile, constant_cols=self.dtypes\n            )\n        # Inherit the parent base class\n        super().__init__(\n            name=self.name,\n            pk=self.pk_list,\n            dtypes=self.dtypes,\n            conn=conn,\n            outfile=outfile,\n        )\n\n        # Insert in-file data\n        if infile:\n            with open(infile) as f:\n                reader = csv.DictReader(f)\n\n                # Confirm the in-file is compatible with the table\n                headers = reader.fieldnames\n                if not headers:\n                    raise NoCSVHeaders()\n                elif len(set(headers).difference(self.dtype_dict.keys())) &gt; 0:\n                    raise KeyError()\n\n                # Insert the in-file data\n                for row in reader:\n                    placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n                    cols, values = \", \".join(row.keys()), tuple(list(row.values()))\n                    query = \"\"\"\n                    INSERT OR IGNORE INTO {table}({cols})\n                    VALUES ({placeholder})\n                    \"\"\".format(\n                        table=self.name, cols=cols, placeholder=placeholder\n                    )\n                    self.execute(query=query, values=values)\n\n    def _parse_infile_columns(self, infile: Path, constant_cols: Dict) -&gt; Dict:\n        \"\"\"During init method, modify table columns to include in-file's columns.\n\n        Args:\n            infile (Path): Path to URLs dataset.\n            constant_cols (Dict): Key-value pairs of table's standard columns and data types.\n            url_col (str | None, optional): Column name of target URLs.\n\n        Raises:\n            NoCSVHeaders: The infile does not have headers.\n            KeyError: The infile does not have a recognizable URL column.\n            NoURLColumn: The infile does not have the user-declared URL column.\n\n        Returns:\n            Dict: Key-value pairs of table's column names and data types.\n        \"\"\"\n        with casanova.reader(infile) as reader:\n            headers = reader.headers\n        if not headers:\n            raise NoCSVHeaders()\n        diff = set(self.pk_list).difference(headers)\n        if len(diff) &gt; 0:\n            raise NoPrimaryKeyColumns(col=list(diff)[0])\n        dtypes = {col: \"TEXT\" for col in headers}\n        return dtypes | constant_cols\n</code></pre>"},{"location":"reference/tables/#minall.tables.shared_content.SharedContentTable.__init__","title":"<code>__init__(conn, infile, outfile)</code>","text":"<p>In database connection, create SQL table. If the user provides an existing shared_content.csv file, populate the table with that input.</p> <p>Parameters:</p> Name Type Description Default <code>conn</code> <code>Connection</code> <p>SQLite connection.</p> required <code>infile</code> <code>Path</code> <p>Path to shared content dataset file.</p> required <p>Raises:</p> Type Description <code>NoCSVHeaders</code> <p>Dataset file does not have headers.</p> <code>NoPrimaryKeyColumns</code> <p>One or more of the required columns ('post_url', 'content_url') is not in the dataset file.</p> Source code in <code>minall/tables/shared_content.py</code> <pre><code>def __init__(self, conn: Connection, infile: Path | None, outfile: Path):\n    \"\"\"In database connection, create SQL table. If the user provides an existing shared_content.csv file, populate the table with that input.\n\n    Args:\n        conn (Connection): SQLite connection.\n        infile (Path): Path to shared content dataset file.\n\n    Raises:\n        NoCSVHeaders: Dataset file does not have headers.\n        NoPrimaryKeyColumns: One or more of the required columns ('post_url', 'content_url') is not in the dataset file.\n    \"\"\"\n    # Update the table's columns to include all in-file columns\n    if infile:\n        self.dtypes = self._parse_infile_columns(\n            infile=infile, constant_cols=self.dtypes\n        )\n    # Inherit the parent base class\n    super().__init__(\n        name=self.name,\n        pk=self.pk_list,\n        dtypes=self.dtypes,\n        conn=conn,\n        outfile=outfile,\n    )\n\n    # Insert in-file data\n    if infile:\n        with open(infile) as f:\n            reader = csv.DictReader(f)\n\n            # Confirm the in-file is compatible with the table\n            headers = reader.fieldnames\n            if not headers:\n                raise NoCSVHeaders()\n            elif len(set(headers).difference(self.dtype_dict.keys())) &gt; 0:\n                raise KeyError()\n\n            # Insert the in-file data\n            for row in reader:\n                placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n                cols, values = \", \".join(row.keys()), tuple(list(row.values()))\n                query = \"\"\"\n                INSERT OR IGNORE INTO {table}({cols})\n                VALUES ({placeholder})\n                \"\"\".format(\n                    table=self.name, cols=cols, placeholder=placeholder\n                )\n                self.execute(query=query, values=values)\n</code></pre>"},{"location":"reference/tables/#minall.tables.base","title":"<code>minall.tables.base</code>","text":"<p>Create and execute queries on SQLite tables.</p> <p>This module contains the class <code>BaseTable</code> that manages the SQLite database's tables. It contains the following methods:</p>"},{"location":"reference/tables/#minall.tables.base.BaseTable","title":"<code>BaseTable</code>","text":"<p>Base class for SQLite tables.</p> Source code in <code>minall/tables/base.py</code> <pre><code>class BaseTable:\n    \"\"\"Base class for SQLite tables.\"\"\"\n\n    def __init__(\n        self, name: str, pk: List[str], conn: Connection, dtypes: Dict, outfile: Path\n    ) -&gt; None:\n        \"\"\"Create the SQL table with the given columns and data types.\n\n        Args:\n            name (str): Table name.\n            pk (List[str]): List of primary keys.\n            conn (Connection): SQLite connection.\n            dtypes (Dict): Key-value pairs of column names and data types.\n            outfile (Path): Path to CSV file where the table will be exported.\n        \"\"\"\n        self.conn = conn\n        self.name = name\n        self.pk_list = pk\n        self.pk_str = \",\".join(pk)\n        self.dtype_dict = dtypes\n        self.outfile = outfile\n\n        # Create the table\n        self.execute(query=f\"DROP TABLE IF EXISTS {self.name}\")\n        self.execute(query=self.create_query)\n\n    def export(self, outfile: Path | None = None):\n        \"\"\"Write the SQL table to a CSV file.\n\n        Args:\n            outfile (Path | None, optional): Path to out-file. Defaults to None.\n        \"\"\"\n        if not outfile:\n            outfile = self.outfile\n        cursor = self.conn.cursor()\n        headers = [\n            t[1]\n            for t in cursor.execute(\n                \"SELECT * FROM pragma_table_info('{}');\".format(self.name)\n            ).fetchall()\n        ]\n        rows = cursor.execute(f\"SELECT * FROM {self.name}\").fetchall()\n        with open(outfile, \"w\") as f:\n            writer = csv.writer(f)\n            writer.writerow(headers)\n            for row in rows:\n                writer.writerow(row)\n\n    def update_from_csv(self, datafile: Path):\n        \"\"\"Reading from a CSV file, update the table rows.\n\n        Args:\n            datafile (Path): Path to file with new data.\n        \"\"\"\n        with open(datafile) as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n                cols_in_csv = \", \".join(row.keys())\n                values = tuple(list(row.values()))\n                coalesce_stmt = self.coalesce_statement(row.keys())\n                query = \"\"\"\n                INSERT INTO {table}({cols_in_csv})\n                VALUES ({placeholder})\n                ON CONFLICT ({pk})\n                DO UPDATE SET {coalesce_stmt}\n                \"\"\".format(\n                    table=self.name,\n                    cols_in_csv=cols_in_csv,\n                    placeholder=placeholder,\n                    pk=self.pk_str,\n                    coalesce_stmt=coalesce_stmt,\n                )\n                self.execute(query=query, values=values)\n\n    def coalesce_statement(self, cols: Iterable[str]) -&gt; str:\n        \"\"\"Compose SQL coalesce statement from columns to be updated.\n\n        Examples:\n            &gt;&gt;&gt; # Set up connection and columns / data types for table.\n            &gt;&gt;&gt; from minall.utils.database import connect_to_database\n            &gt;&gt;&gt; columns_n_datatypes = {\"url\": \"TEXT\", \"domain\": \"TEXT\", \"work_type\": \"TEXT\"}\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Create table.\n            &gt;&gt;&gt; table = BaseTable(name=\"test\", pk=[\"url\"], conn=connect_to_database(), dtypes=columns_n_datatypes, outfile=Path(\"test.csv\"))\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Compose SQL statement to replace table's row with new data.\n            &gt;&gt;&gt; table.coalesce_statement(cols=columns_n_datatypes.keys())\n            'domain=COALESCE(excluded.domain, domain), work_type=COALESCE(excluded.work_type, work_type)'\n\n        Args:\n            cols (Iterable[str]): Row columns.\n\n        Returns:\n            str: SQL statement.\n        \"\"\"\n        return \", \".join(\n            [f\"{k}=COALESCE(excluded.{k}, {k})\" for k in cols if k not in self.pk_list]\n        )\n\n    @property\n    def create_query(self) -&gt; str:\n        \"\"\"SQL statement to create table.\n\n        Examples:\n            &gt;&gt;&gt; # Set up connection and columns / data types for table.\n            &gt;&gt;&gt; from minall.utils.database import connect_to_database\n            &gt;&gt;&gt; columns_n_datatypes = {\"url\": \"TEXT\", \"domain\": \"TEXT\", \"work_type\": \"TEXT\"}\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Create table.\n            &gt;&gt;&gt; table = BaseTable(name=\"test\", pk=[\"url\"], conn=connect_to_database(), dtypes=columns_n_datatypes, outfile=Path(\"test.csv\"))\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Compose SQL statement to create table.\n            &gt;&gt;&gt; table.create_query\n            &gt;&gt;&gt; 'CREATE TABLE IF NOT EXISTS test(url TEXT, domain TEXT, work_type TEXT, PRIMARY KEY (url))'\n\n\n        Returns:\n            str: _description_\n        \"\"\"\n        cols = \", \".join([f\"{k} {v}\" for k, v in self.dtype_dict.items()])\n        return (\n            \"\"\"CREATE TABLE IF NOT EXISTS {table}({cols}, PRIMARY KEY ({pk}))\"\"\".format(\n                table=self.name, cols=cols, pk=self.pk_str\n            )\n        )\n\n    def execute(self, query: str, values: Tuple | None = None):\n        \"\"\"Function to commit a query to the database connection.\n\n        Args:\n            query (str): SQL statement.\n            values (Tuple | None, optional): Values to be inserted in the query's placeholders. Defaults to None.\n\n        Raises:\n            e: SQLite Exception.\n        \"\"\"\n        cursor = self.conn.cursor()\n        try:\n            if values:\n                cursor.execute(query, values)\n            else:\n                cursor.execute(query)\n        except Exception as e:\n            print(\"\\n\\n\", query, \"\\n\\n\")\n            raise e\n\n    def select_from(self, cols: str, filter: str | None = None) -&gt; List:\n        \"\"\"Function to select rows from the SQL table.\n\n        Args:\n            cols (str): Target of SELECT statement.\n            filter (str | None, optional): Where condition to apply after FROM statement. Defaults to None.\n\n        Raises:\n            e: SQLite Exception.\n\n        Returns:\n            List: List of rows.\n        \"\"\"\n        if not filter:\n            filter = \"\"\n        else:\n            filter = \" \" + filter\n        query = f\"select {cols} from {self.name}{filter}\"\n        cursor = self.conn.cursor()\n        try:\n            response = cursor.execute(query)\n            self.conn.commit()\n        except Exception as e:\n            print(\"\\n\\n\", query, \"\\n\\n\")\n            raise e\n        else:\n            return response.fetchall()\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.create_query","title":"<code>create_query: str</code>  <code>property</code>","text":"<p>SQL statement to create table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Set up connection and columns / data types for table.\n&gt;&gt;&gt; from minall.utils.database import connect_to_database\n&gt;&gt;&gt; columns_n_datatypes = {\"url\": \"TEXT\", \"domain\": \"TEXT\", \"work_type\": \"TEXT\"}\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create table.\n&gt;&gt;&gt; table = BaseTable(name=\"test\", pk=[\"url\"], conn=connect_to_database(), dtypes=columns_n_datatypes, outfile=Path(\"test.csv\"))\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Compose SQL statement to create table.\n&gt;&gt;&gt; table.create_query\n&gt;&gt;&gt; 'CREATE TABLE IF NOT EXISTS test(url TEXT, domain TEXT, work_type TEXT, PRIMARY KEY (url))'\n</code></pre> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>description</p>"},{"location":"reference/tables/#minall.tables.base.BaseTable.__init__","title":"<code>__init__(name, pk, conn, dtypes, outfile)</code>","text":"<p>Create the SQL table with the given columns and data types.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name.</p> required <code>pk</code> <code>List[str]</code> <p>List of primary keys.</p> required <code>conn</code> <code>Connection</code> <p>SQLite connection.</p> required <code>dtypes</code> <code>Dict</code> <p>Key-value pairs of column names and data types.</p> required <code>outfile</code> <code>Path</code> <p>Path to CSV file where the table will be exported.</p> required Source code in <code>minall/tables/base.py</code> <pre><code>def __init__(\n    self, name: str, pk: List[str], conn: Connection, dtypes: Dict, outfile: Path\n) -&gt; None:\n    \"\"\"Create the SQL table with the given columns and data types.\n\n    Args:\n        name (str): Table name.\n        pk (List[str]): List of primary keys.\n        conn (Connection): SQLite connection.\n        dtypes (Dict): Key-value pairs of column names and data types.\n        outfile (Path): Path to CSV file where the table will be exported.\n    \"\"\"\n    self.conn = conn\n    self.name = name\n    self.pk_list = pk\n    self.pk_str = \",\".join(pk)\n    self.dtype_dict = dtypes\n    self.outfile = outfile\n\n    # Create the table\n    self.execute(query=f\"DROP TABLE IF EXISTS {self.name}\")\n    self.execute(query=self.create_query)\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.coalesce_statement","title":"<code>coalesce_statement(cols)</code>","text":"<p>Compose SQL coalesce statement from columns to be updated.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Set up connection and columns / data types for table.\n&gt;&gt;&gt; from minall.utils.database import connect_to_database\n&gt;&gt;&gt; columns_n_datatypes = {\"url\": \"TEXT\", \"domain\": \"TEXT\", \"work_type\": \"TEXT\"}\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create table.\n&gt;&gt;&gt; table = BaseTable(name=\"test\", pk=[\"url\"], conn=connect_to_database(), dtypes=columns_n_datatypes, outfile=Path(\"test.csv\"))\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Compose SQL statement to replace table's row with new data.\n&gt;&gt;&gt; table.coalesce_statement(cols=columns_n_datatypes.keys())\n'domain=COALESCE(excluded.domain, domain), work_type=COALESCE(excluded.work_type, work_type)'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cols</code> <code>Iterable[str]</code> <p>Row columns.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>SQL statement.</p> Source code in <code>minall/tables/base.py</code> <pre><code>def coalesce_statement(self, cols: Iterable[str]) -&gt; str:\n    \"\"\"Compose SQL coalesce statement from columns to be updated.\n\n    Examples:\n        &gt;&gt;&gt; # Set up connection and columns / data types for table.\n        &gt;&gt;&gt; from minall.utils.database import connect_to_database\n        &gt;&gt;&gt; columns_n_datatypes = {\"url\": \"TEXT\", \"domain\": \"TEXT\", \"work_type\": \"TEXT\"}\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create table.\n        &gt;&gt;&gt; table = BaseTable(name=\"test\", pk=[\"url\"], conn=connect_to_database(), dtypes=columns_n_datatypes, outfile=Path(\"test.csv\"))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Compose SQL statement to replace table's row with new data.\n        &gt;&gt;&gt; table.coalesce_statement(cols=columns_n_datatypes.keys())\n        'domain=COALESCE(excluded.domain, domain), work_type=COALESCE(excluded.work_type, work_type)'\n\n    Args:\n        cols (Iterable[str]): Row columns.\n\n    Returns:\n        str: SQL statement.\n    \"\"\"\n    return \", \".join(\n        [f\"{k}=COALESCE(excluded.{k}, {k})\" for k in cols if k not in self.pk_list]\n    )\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.execute","title":"<code>execute(query, values=None)</code>","text":"<p>Function to commit a query to the database connection.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SQL statement.</p> required <code>values</code> <code>Tuple | None</code> <p>Values to be inserted in the query's placeholders. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>e</code> <p>SQLite Exception.</p> Source code in <code>minall/tables/base.py</code> <pre><code>def execute(self, query: str, values: Tuple | None = None):\n    \"\"\"Function to commit a query to the database connection.\n\n    Args:\n        query (str): SQL statement.\n        values (Tuple | None, optional): Values to be inserted in the query's placeholders. Defaults to None.\n\n    Raises:\n        e: SQLite Exception.\n    \"\"\"\n    cursor = self.conn.cursor()\n    try:\n        if values:\n            cursor.execute(query, values)\n        else:\n            cursor.execute(query)\n    except Exception as e:\n        print(\"\\n\\n\", query, \"\\n\\n\")\n        raise e\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.export","title":"<code>export(outfile=None)</code>","text":"<p>Write the SQL table to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>outfile</code> <code>Path | None</code> <p>Path to out-file. Defaults to None.</p> <code>None</code> Source code in <code>minall/tables/base.py</code> <pre><code>def export(self, outfile: Path | None = None):\n    \"\"\"Write the SQL table to a CSV file.\n\n    Args:\n        outfile (Path | None, optional): Path to out-file. Defaults to None.\n    \"\"\"\n    if not outfile:\n        outfile = self.outfile\n    cursor = self.conn.cursor()\n    headers = [\n        t[1]\n        for t in cursor.execute(\n            \"SELECT * FROM pragma_table_info('{}');\".format(self.name)\n        ).fetchall()\n    ]\n    rows = cursor.execute(f\"SELECT * FROM {self.name}\").fetchall()\n    with open(outfile, \"w\") as f:\n        writer = csv.writer(f)\n        writer.writerow(headers)\n        for row in rows:\n            writer.writerow(row)\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.select_from","title":"<code>select_from(cols, filter=None)</code>","text":"<p>Function to select rows from the SQL table.</p> <p>Parameters:</p> Name Type Description Default <code>cols</code> <code>str</code> <p>Target of SELECT statement.</p> required <code>filter</code> <code>str | None</code> <p>Where condition to apply after FROM statement. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>e</code> <p>SQLite Exception.</p> <p>Returns:</p> Name Type Description <code>List</code> <code>List</code> <p>List of rows.</p> Source code in <code>minall/tables/base.py</code> <pre><code>def select_from(self, cols: str, filter: str | None = None) -&gt; List:\n    \"\"\"Function to select rows from the SQL table.\n\n    Args:\n        cols (str): Target of SELECT statement.\n        filter (str | None, optional): Where condition to apply after FROM statement. Defaults to None.\n\n    Raises:\n        e: SQLite Exception.\n\n    Returns:\n        List: List of rows.\n    \"\"\"\n    if not filter:\n        filter = \"\"\n    else:\n        filter = \" \" + filter\n    query = f\"select {cols} from {self.name}{filter}\"\n    cursor = self.conn.cursor()\n    try:\n        response = cursor.execute(query)\n        self.conn.commit()\n    except Exception as e:\n        print(\"\\n\\n\", query, \"\\n\\n\")\n        raise e\n    else:\n        return response.fetchall()\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.update_from_csv","title":"<code>update_from_csv(datafile)</code>","text":"<p>Reading from a CSV file, update the table rows.</p> <p>Parameters:</p> Name Type Description Default <code>datafile</code> <code>Path</code> <p>Path to file with new data.</p> required Source code in <code>minall/tables/base.py</code> <pre><code>def update_from_csv(self, datafile: Path):\n    \"\"\"Reading from a CSV file, update the table rows.\n\n    Args:\n        datafile (Path): Path to file with new data.\n    \"\"\"\n    with open(datafile) as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n            cols_in_csv = \", \".join(row.keys())\n            values = tuple(list(row.values()))\n            coalesce_stmt = self.coalesce_statement(row.keys())\n            query = \"\"\"\n            INSERT INTO {table}({cols_in_csv})\n            VALUES ({placeholder})\n            ON CONFLICT ({pk})\n            DO UPDATE SET {coalesce_stmt}\n            \"\"\".format(\n                table=self.name,\n                cols_in_csv=cols_in_csv,\n                placeholder=placeholder,\n                pk=self.pk_str,\n                coalesce_stmt=coalesce_stmt,\n            )\n            self.execute(query=query, values=values)\n</code></pre>"},{"location":"reference/tables/#minall.tables.exceptions","title":"<code>minall.tables.exceptions</code>","text":"<p>Exceptions for validating CSV files used to create SQLite tables.</p> <p>This module contains exceptions to manage the process of validating a CSV file given as input for the enrichment process. The module contains the following exceptions:</p> <ul> <li><code>NoCSVHeaders</code> - The CSV does not have headers.</li> <li><code>NoURLColumn</code> - When building the 'links' table, the declared URL column is not in the CSV file.</li> <li><code>NoPrimaryKeyColumns</code> - When building the 'shared_content' table, either the 'post_url' column or the 'content_url' column are missing from the CSV file.</li> </ul> <p>When creating the 'links' table, the input CSV file must have a column for URLs; the URLs must be cleaned and/or ready to serve as the source for the data collection. The name of the URL column can vary and must be declared.</p> <p>When creating the 'shared_content' table, the column names are not modifiable. The CSV must have the columns 'post_url' and 'content_url;' the former relates to a URL in the 'links' table, and the latter incidates a URL for content embedded in the Web Content of the former.</p>"},{"location":"reference/tables/#minall.tables.exceptions.NoCSVHeaders","title":"<code>NoCSVHeaders</code>","text":"<p>             Bases: <code>Exception</code></p> <p>The CSV in-file lacks headers.</p> Source code in <code>minall/tables/exceptions.py</code> <pre><code>class NoCSVHeaders(Exception):\n    \"\"\"The CSV in-file lacks headers.\"\"\"\n\n    def __init__(self) -&gt; None:\n        message = \"No headers detected in CSV file.\"\n        super().__init__(message)\n</code></pre>"},{"location":"reference/tables/#minall.tables.exceptions.NoPrimaryKeyColumns","title":"<code>NoPrimaryKeyColumns</code>","text":"<p>             Bases: <code>Exception</code></p> <p>The CSV in-file is missing a required column.</p> Source code in <code>minall/tables/exceptions.py</code> <pre><code>class NoPrimaryKeyColumns(Exception):\n    \"\"\"The CSV in-file is missing a required column.\"\"\"\n\n    def __init__(self, col: str) -&gt; None:\n        message = f\"Required primary key column '{col}' is not a header in the given CSV file.\"\n        super().__init__(message)\n</code></pre>"},{"location":"reference/tables/#minall.tables.exceptions.NoURLColumn","title":"<code>NoURLColumn</code>","text":"<p>             Bases: <code>Exception</code></p> <p>The CSV in-file is missing a user-declared column.</p> Source code in <code>minall/tables/exceptions.py</code> <pre><code>class NoURLColumn(Exception):\n    \"\"\"The CSV in-file is missing a user-declared column.\"\"\"\n\n    def __init__(self, url_col: str) -&gt; None:\n        message = f\"The declared URL column '{url_col}' is not a header in the given CSV file.\"\n        super().__init__(message)\n</code></pre>"},{"location":"reference/utils/","title":"Utilities","text":"<p>Little blurb</p>"},{"location":"reference/utils/#minall.utils.database","title":"<code>minall.utils.database</code>","text":"<p>Utilities to manage SQLite database connection.</p> <p>The module contains the following function and class:</p> <ul> <li><code>connect_to_database(database)</code> - If provided with path, connects to embedded SQLite database; otherwise, connects to in-memory SQLite database.</li> <li><code>SQLiteWrapper(connection)</code> - Stores connection and cursor, executes queries.</li> </ul>"},{"location":"reference/utils/#minall.utils.database.SQLiteWrapper","title":"<code>SQLiteWrapper</code>","text":"<p>Class to store SQLite database connection and execute SQL queries.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n&gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n&gt;&gt;&gt; wrapper.select(\"select * from test\")\n[]\n</code></pre> Source code in <code>minall/utils/database.py</code> <pre><code>class SQLiteWrapper:\n    \"\"\"Class to store SQLite database connection and execute SQL queries.\n\n    Examples:\n        &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n        &gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n        &gt;&gt;&gt; wrapper.select(\"select * from test\")\n        []\n\n    \"\"\"\n\n    def __init__(self, connection: Connection) -&gt; None:\n        \"\"\"Store database connection and create cursor.\n\n        Examples:\n            &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n            &gt;&gt;&gt; type(wrapper.cursor)\n            &lt;class 'sqlite3.Cursor'&gt;\n\n        Args:\n            connection (Connection): Connection to SQLite database.\n        \"\"\"\n        self.connection = connection\n        self.cursor = self.connection.cursor()\n\n    def __call__(self, query: str, values: List[Tuple] | None = None) -&gt; None:\n        \"\"\"Execute and commit SQL query.\n\n        Examples:\n            &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n            &gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n            &gt;&gt;&gt; wrapper.select(\"select * from test\")\n            []\n\n        Args:\n            query (str): Query string, can contain SQL place holders for values (?).\n            values (list[tuple] | None, optional): Values to be included in query. Defaults to None.\n\n        Raises:\n            Exception: `sqlite3` Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.\n        \"\"\"\n        try:\n            if values:\n                self.cursor.execute(query, values)\n            else:\n                self.cursor.execute(query)\n            self.connection.commit()\n        except Exception as e:\n            print(\"\\n\", query, \"\\n\")\n            print(values)\n            raise e\n\n    def select(self, query: str) -&gt; List:\n        \"\"\"Return selection from SQLite database.\n\n        Examples:\n            &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n            &gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n            &gt;&gt;&gt; wrapper.select(\"select * from test\")\n            []\n\n        Args:\n            query (str): SQL select query.\n\n        Raises:\n            Exception: `sqlite3` Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.\n\n        Returns:\n            List: Array of results from SQL query.\n        \"\"\"\n        try:\n            response = self.cursor.execute(query)\n            self.connection.commit()\n        except Exception as e:\n            print(\"\\n\", query, \"\\n\")\n            raise e\n        else:\n            return response.fetchall()\n</code></pre>"},{"location":"reference/utils/#minall.utils.database.SQLiteWrapper.__call__","title":"<code>__call__(query, values=None)</code>","text":"<p>Execute and commit SQL query.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n&gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n&gt;&gt;&gt; wrapper.select(\"select * from test\")\n[]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Query string, can contain SQL place holders for values (?).</p> required <code>values</code> <code>list[tuple] | None</code> <p>Values to be included in query. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p><code>sqlite3</code> Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.</p> Source code in <code>minall/utils/database.py</code> <pre><code>def __call__(self, query: str, values: List[Tuple] | None = None) -&gt; None:\n    \"\"\"Execute and commit SQL query.\n\n    Examples:\n        &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n        &gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n        &gt;&gt;&gt; wrapper.select(\"select * from test\")\n        []\n\n    Args:\n        query (str): Query string, can contain SQL place holders for values (?).\n        values (list[tuple] | None, optional): Values to be included in query. Defaults to None.\n\n    Raises:\n        Exception: `sqlite3` Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.\n    \"\"\"\n    try:\n        if values:\n            self.cursor.execute(query, values)\n        else:\n            self.cursor.execute(query)\n        self.connection.commit()\n    except Exception as e:\n        print(\"\\n\", query, \"\\n\")\n        print(values)\n        raise e\n</code></pre>"},{"location":"reference/utils/#minall.utils.database.SQLiteWrapper.__init__","title":"<code>__init__(connection)</code>","text":"<p>Store database connection and create cursor.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n&gt;&gt;&gt; type(wrapper.cursor)\n&lt;class 'sqlite3.Cursor'&gt;\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Connection</code> <p>Connection to SQLite database.</p> required Source code in <code>minall/utils/database.py</code> <pre><code>def __init__(self, connection: Connection) -&gt; None:\n    \"\"\"Store database connection and create cursor.\n\n    Examples:\n        &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n        &gt;&gt;&gt; type(wrapper.cursor)\n        &lt;class 'sqlite3.Cursor'&gt;\n\n    Args:\n        connection (Connection): Connection to SQLite database.\n    \"\"\"\n    self.connection = connection\n    self.cursor = self.connection.cursor()\n</code></pre>"},{"location":"reference/utils/#minall.utils.database.SQLiteWrapper.select","title":"<code>select(query)</code>","text":"<p>Return selection from SQLite database.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n&gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n&gt;&gt;&gt; wrapper.select(\"select * from test\")\n[]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SQL select query.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p><code>sqlite3</code> Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.</p> <p>Returns:</p> Name Type Description <code>List</code> <code>List</code> <p>Array of results from SQL query.</p> Source code in <code>minall/utils/database.py</code> <pre><code>def select(self, query: str) -&gt; List:\n    \"\"\"Return selection from SQLite database.\n\n    Examples:\n        &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n        &gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n        &gt;&gt;&gt; wrapper.select(\"select * from test\")\n        []\n\n    Args:\n        query (str): SQL select query.\n\n    Raises:\n        Exception: `sqlite3` Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.\n\n    Returns:\n        List: Array of results from SQL query.\n    \"\"\"\n    try:\n        response = self.cursor.execute(query)\n        self.connection.commit()\n    except Exception as e:\n        print(\"\\n\", query, \"\\n\")\n        raise e\n    else:\n        return response.fetchall()\n</code></pre>"},{"location":"reference/utils/#minall.utils.database.connect_to_database","title":"<code>connect_to_database(database=None)</code>","text":"<p>Connect to SQLite database.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; conn = connect_to_database()\n&gt;&gt;&gt; type(conn)\n&lt;class 'sqlite3.Connection'&gt;\n&gt;&gt;&gt; _ = conn.cursor().execute(\"create table test(name text)\")\n&gt;&gt;&gt; conn.cursor().execute(\"select * from test\").fetchall()\n[]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>database</code> <code>str | None</code> <p>If given, path to embedded SQLite database. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Connection</code> <code>Connection</code> <p>description</p> Source code in <code>minall/utils/database.py</code> <pre><code>def connect_to_database(database: str | None = None) -&gt; Connection:\n    \"\"\"Connect to SQLite database.\n\n    Examples:\n        &gt;&gt;&gt; conn = connect_to_database()\n        &gt;&gt;&gt; type(conn)\n        &lt;class 'sqlite3.Connection'&gt;\n        &gt;&gt;&gt; _ = conn.cursor().execute(\"create table test(name text)\")\n        &gt;&gt;&gt; conn.cursor().execute(\"select * from test\").fetchall()\n        []\n\n    Args:\n        database (str | None, optional): If given, path to embedded SQLite database. Defaults to None.\n\n    Returns:\n        Connection: _description_\n    \"\"\"\n\n    if database:\n        [p.mkdir(exist_ok=True) for p in Path(database).parents]\n        connection = sqlite3.connect(database)\n    else:\n        connection = sqlite3.connect(\":memory:\")\n    return connection\n</code></pre>"},{"location":"reference/utils/#minall.utils.parse_config","title":"<code>minall.utils.parse_config</code>","text":"<p>Data class to store and manage minet client credentials.</p> <p>The class <code>APIKeys</code> contains the following methods and properties:</p> <ul> <li><code>__init__(config)</code> - Parses the minet client configuration details.</li> <li><code>env_string()</code> - Formats the minet client credentials as an environment variable string.</li> <li><code>load_config_file(config_file)</code> - Parse client configuration details from JSON or YAML file.</li> </ul>"},{"location":"reference/utils/#minall.utils.parse_config.APIKeys","title":"<code>APIKeys</code>  <code>dataclass</code>","text":"<p>Data class to store and manage minet client credentials.</p> <p>Attributes:</p> Name Type Description <code>buzzsumo_token</code> <code>Optional[str]</code> <p>Buzzsumo API token. Optional.</p> <code>crowdtangle_token</code> <code>Optional[str]</code> <p>CrowdTangle API token. Optional.</p> <code>crowdtangle_rate_limit</code> <code>Optional[str]</code> <p>CrowdTangle API rate limit, cast as a string. Optional.</p> <code>youtube_key</code> <code>Optional[List[str]]) </code> <p>List of YouTube API keys. Optional.</p> Source code in <code>minall/utils/parse_config.py</code> <pre><code>@dataclass\nclass APIKeys:\n    \"\"\"Data class to store and manage minet client credentials.\n\n    Attributes:\n        buzzsumo_token (Optional[str]): Buzzsumo API token. Optional.\n        crowdtangle_token (Optional[str]):  CrowdTangle API token. Optional.\n        crowdtangle_rate_limit (Optional[str]): CrowdTangle API rate limit, cast as a string. Optional.\n        youtube_key (Optional[List[str]]) : List of YouTube API keys. Optional.\n    \"\"\"\n\n    buzzsumo_token: Optional[str]\n    crowdtangle_token: Optional[str]\n    crowdtangle_rate_limit: Optional[str]\n    youtube_key: Optional[List[str]]\n\n    def __init__(self, config: str | dict | None = None):\n        \"\"\"Parse and save minet API client configuration details.\n\n        Examples:\n            &gt;&gt;&gt; keys = APIKeys(config={\"youtube\": {\"key\": \"key1,key2\"}})\n            &gt;&gt;&gt; keys\n            APIKeys(buzzsumo_token=None, crowdtangle_token=None, crowdtangle_rate_limit=None, youtube_key=[\"key1\", \"key2\"])\n            &gt;&gt;&gt; keys.youtube_key\n            [\"key1, \"key2]\n\n        Args:\n            config (str | dict | None, optional): If string, string is treated like file path to JSON or YAML file that contains details; if dict, details are directly parsed; if None, details are searched from environment variables. Defaults to None.\n        \"\"\"\n        if config:\n            if isinstance(config, str):\n                parsed_config = self.load_config_file(config)\n            else:\n                parsed_config = config\n            self.buzzsumo_token = parsed_config[\"buzzsumo\"][\"token\"]\n            self.crowdtangle_token = parsed_config[\"crowdtangle\"][\"token\"]\n            self.crowdtangle_rate_limit = parsed_config[\"crowdtangle\"][\"rate_limit\"]\n            yt_keys = parsed_config[\"youtube\"][\"key\"]\n            if isinstance(yt_keys, list):\n                self.youtube_key = yt_keys\n            else:\n                self.youtube_key = parsed_config[\"youtube\"][\"key\"].split(\",\")\n        else:\n            self.buzzsumo_token = os.environ.get(\"BUZZSUMO_TOKEN\")\n            self.crowdtangle_token = os.environ.get(\"CROWDTANGLE_TOKEN\")\n            self.crowdtangle_rate_limit = os.environ.get(\"CROWDTANGLE_RATE_LIMIT\")\n            youtube_key = os.environ.get(\"YOUTUBE_KEY\")\n            if youtube_key:\n                self.youtube_key = youtube_key.split(\",\")\n            else:\n                self.youtube_key = []\n\n    @property\n    def env_string(self) -&gt; str:\n        r\"\"\"Formatted string for setting environment variables.\n\n        Examples:\n            &gt;&gt;&gt; keys = APIKeys(config={'buzzsumo': {'token': 'bz_token'}, 'crowdtangle': {'token': 'ct_token', 'rate_limit': 10}, 'youtube': {'key': 'key1,key2'}})\n            &gt;&gt;&gt; keys.env_string\n            \"BUZZSUMO_TOKEN=bz_token\\nCROWDTANGLE_TOKEN=ct_token\\nCROWDTANGLE_RATE_LIMIT=10\\nYOUTUBE_KEY=['key1', 'key2']\\n\"\n\n        Returns:\n            str: String declaring environment variables.\n        \"\"\"\n\n        return \"BUZZSUMO_TOKEN={bz}\\nCROWDTANGLE_TOKEN={ct}\\nCROWDTANGLE_RATE_LIMIT={crl}\\nYOUTUBE_KEY={yt}\\n\".format(\n            bz=self.buzzsumo_token,\n            ct=self.crowdtangle_token,\n            crl=self.crowdtangle_rate_limit,\n            yt=self.youtube_key,\n        )\n\n    def load_config_file(self, config_file: str) -&gt; dict:\n        \"\"\"Parse dictionary from JSON or YAML configuration file.\n\n        Args:\n            config_file (str): Path to JSON or YAML file.\n\n        Raises:\n            OSError: Error raised if given file path does not have the extension \".json\", \".yml\", or \".yaml\".\n\n        Returns:\n            dict: Parsed dictionary from JSON or YAML configuration file.\n        \"\"\"\n\n        with open(config_file) as f:\n            extension = Path(config_file).suffix\n            if extension == \".json\":\n                return json.load(f)\n            elif extension == \".yml\" or extension == \".yaml\":\n                return yaml.safe_load(f)\n            else:\n                raise OSError\n</code></pre>"},{"location":"reference/utils/#minall.utils.parse_config.APIKeys.env_string","title":"<code>env_string: str</code>  <code>property</code>","text":"<p>Formatted string for setting environment variables.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; keys = APIKeys(config={'buzzsumo': {'token': 'bz_token'}, 'crowdtangle': {'token': 'ct_token', 'rate_limit': 10}, 'youtube': {'key': 'key1,key2'}})\n&gt;&gt;&gt; keys.env_string\n\"BUZZSUMO_TOKEN=bz_token\\nCROWDTANGLE_TOKEN=ct_token\\nCROWDTANGLE_RATE_LIMIT=10\\nYOUTUBE_KEY=['key1', 'key2']\\n\"\n</code></pre> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>String declaring environment variables.</p>"},{"location":"reference/utils/#minall.utils.parse_config.APIKeys.__init__","title":"<code>__init__(config=None)</code>","text":"<p>Parse and save minet API client configuration details.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; keys = APIKeys(config={\"youtube\": {\"key\": \"key1,key2\"}})\n&gt;&gt;&gt; keys\nAPIKeys(buzzsumo_token=None, crowdtangle_token=None, crowdtangle_rate_limit=None, youtube_key=[\"key1\", \"key2\"])\n&gt;&gt;&gt; keys.youtube_key\n[\"key1, \"key2]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>str | dict | None</code> <p>If string, string is treated like file path to JSON or YAML file that contains details; if dict, details are directly parsed; if None, details are searched from environment variables. Defaults to None.</p> <code>None</code> Source code in <code>minall/utils/parse_config.py</code> <pre><code>def __init__(self, config: str | dict | None = None):\n    \"\"\"Parse and save minet API client configuration details.\n\n    Examples:\n        &gt;&gt;&gt; keys = APIKeys(config={\"youtube\": {\"key\": \"key1,key2\"}})\n        &gt;&gt;&gt; keys\n        APIKeys(buzzsumo_token=None, crowdtangle_token=None, crowdtangle_rate_limit=None, youtube_key=[\"key1\", \"key2\"])\n        &gt;&gt;&gt; keys.youtube_key\n        [\"key1, \"key2]\n\n    Args:\n        config (str | dict | None, optional): If string, string is treated like file path to JSON or YAML file that contains details; if dict, details are directly parsed; if None, details are searched from environment variables. Defaults to None.\n    \"\"\"\n    if config:\n        if isinstance(config, str):\n            parsed_config = self.load_config_file(config)\n        else:\n            parsed_config = config\n        self.buzzsumo_token = parsed_config[\"buzzsumo\"][\"token\"]\n        self.crowdtangle_token = parsed_config[\"crowdtangle\"][\"token\"]\n        self.crowdtangle_rate_limit = parsed_config[\"crowdtangle\"][\"rate_limit\"]\n        yt_keys = parsed_config[\"youtube\"][\"key\"]\n        if isinstance(yt_keys, list):\n            self.youtube_key = yt_keys\n        else:\n            self.youtube_key = parsed_config[\"youtube\"][\"key\"].split(\",\")\n    else:\n        self.buzzsumo_token = os.environ.get(\"BUZZSUMO_TOKEN\")\n        self.crowdtangle_token = os.environ.get(\"CROWDTANGLE_TOKEN\")\n        self.crowdtangle_rate_limit = os.environ.get(\"CROWDTANGLE_RATE_LIMIT\")\n        youtube_key = os.environ.get(\"YOUTUBE_KEY\")\n        if youtube_key:\n            self.youtube_key = youtube_key.split(\",\")\n        else:\n            self.youtube_key = []\n</code></pre>"},{"location":"reference/utils/#minall.utils.parse_config.APIKeys.load_config_file","title":"<code>load_config_file(config_file)</code>","text":"<p>Parse dictionary from JSON or YAML configuration file.</p> <p>Parameters:</p> Name Type Description Default <code>config_file</code> <code>str</code> <p>Path to JSON or YAML file.</p> required <p>Raises:</p> Type Description <code>OSError</code> <p>Error raised if given file path does not have the extension \".json\", \".yml\", or \".yaml\".</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Parsed dictionary from JSON or YAML configuration file.</p> Source code in <code>minall/utils/parse_config.py</code> <pre><code>def load_config_file(self, config_file: str) -&gt; dict:\n    \"\"\"Parse dictionary from JSON or YAML configuration file.\n\n    Args:\n        config_file (str): Path to JSON or YAML file.\n\n    Raises:\n        OSError: Error raised if given file path does not have the extension \".json\", \".yml\", or \".yaml\".\n\n    Returns:\n        dict: Parsed dictionary from JSON or YAML configuration file.\n    \"\"\"\n\n    with open(config_file) as f:\n        extension = Path(config_file).suffix\n        if extension == \".json\":\n            return json.load(f)\n        elif extension == \".yml\" or extension == \".yaml\":\n            return yaml.safe_load(f)\n        else:\n            raise OSError\n</code></pre>"},{"location":"reference/utils/#minall.utils.progress_bar","title":"<code>minall.utils.progress_bar</code>","text":"<p>Context for rich progress bar.</p>"},{"location":"reference/utils/#minall.utils.progress_bar.progress_bar","title":"<code>progress_bar()</code>","text":"<p>Rich progress bar with Spinner column.</p> <p>Yields:</p> Type Description <code>Progress</code> <p>Generator[Progress, None, None]: Rich progress bar context</p> Source code in <code>minall/utils/progress_bar.py</code> <pre><code>@contextmanager\ndef progress_bar() -&gt; Generator[Progress, None, None]:\n    \"\"\"Rich progress bar with Spinner column.\n\n    Yields:\n        Generator[Progress, None, None]: Rich progress bar context\n    \"\"\"\n    with Progress(\n        TextColumn(\"[progress.description]{task.description}\"),\n        SpinnerColumn(),\n        MofNCompleteColumn(),\n        TimeElapsedColumn(),\n    ) as progress:\n        yield progress\n</code></pre>"}]}