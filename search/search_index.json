{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This site contains documentation for the <code>minall</code> data enrichment workflow. The project's aim is to collect and update metadata about web content, targeted via Unique Resource Identifiers (URIs / URLs).</p> <p><code>minall</code> is built atop the data-mining tool <code>minet</code>, which was designed to collect data about media content online.</p>"},{"location":"#table-of-contents","title":"Table Of Contents","text":"<ul> <li>Tutorials : Articles demonstrating how to use the project for various use cases.</li> <li>How-To Guides : Straight-to-the-point, step-by-step guides.</li> <li>Reference : Documentation of the project's code base.</li> <li>Explanation : Article explaining the project's motivation and implementation.</li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This project was developed as a response to research needs in the European project De Facto and with the help of members of the m\u00e9dialab at Sciences Po. In particular, the project depends on the excellent work of Guillaume Plique and other contributors to the m\u00e9dialab's tool <code>minet</code>.</p>"},{"location":"explanation/","title":"Explanation","text":"<p>This part of the project documentation focuses on an understanding-oriented approach. You'll get a chance to read about the background of the project, as well as reasoning about how it was implemented.</p> <p>Note: Expand this section by considering the following points:</p> <ul> <li>Give context and background on your library</li> <li>Explain why you created it</li> <li>Provide multiple examples and approaches of how   to work with it</li> <li>Help the reader make connections</li> <li>Avoid writing instructions or technical descriptions   here</li> </ul> <pre><code>graph\nA(\"What is the nature of the URL?\")\nB(\"Is the URL of a video?\")\nC[\"Call YouTube API for video metadata, including channel ID.\"]\nD(\"Is the URL of a channel?\")\nE[\"Call YouTube API for channel metadata\"]\n\nF(\"Is the URL of a Facebook post?\")\nG[\"Call CrowdTangle API for post metadata\"]\n\nH(\"Is the URL from a media platform other than YouTube or Facebook?\")\nI[\"Assign '@type' = 'SocialMediaPosting'.\"]\n\nJ(\"Is the URL not from a social media platform?\")\nK[\"Scrape text and metadata.\"]\n\nL[\"Call Buzzsumo API for metadata.\"]\n\nA==YouTube==&gt;B\nB==Y==&gt;C\nB==N==&gt;D\nC---E\nD---E\nA==Facebook==&gt;F\nF---G\nA==Other Social Media==&gt;H\nH---I\nA==Article==&gt;J\nJ---K\nE---L\nG---L\nI---L\nK---L</code></pre>"},{"location":"explanation/#data-fields","title":"Data fields","text":"<ul> <li><code>url</code> : the URL that will be used for the metadata collection</li> <li><code>domain</code> : the URL's domain name</li> <li><code>work_type</code> : a Schema.org classification for the URL as a CreativeWork</li> <li><code>duration</code> : if the URL is of a video, the video's duration</li> <li><code>identifier</code> : the identifier given to the URL via a platform (i.e. YouTube ID, Twitter user ID)</li> <li><code>date_published</code> : date (YYYY-MM-DD) when the URL's content was originally published</li> <li><code>date_modified</code> : date (YYYY-MM-DD) when the URL's content was last updated</li> <li><code>country_of_origin</code> : if the URL is of a YouTube channel, the channel's registered country</li> <li><code>abstract</code> : abbreviated description of the URL's content</li> <li><code>keywords</code> : keywords associated with the URL</li> <li><code>title</code> : title given to the URL's content</li> <li><code>text</code> : the URL's main textual content</li> <li><code>hashtags</code> : hashtags associated with the URL</li> <li><code>creator_type</code> : a Schema.org or De Facto classification for the creator of the URL's content</li> <li><code>creator_date_created</code> : if the URL's content was created by a social media account, the date of the account's creation on the site</li> <li><code>creator_location_created</code> : if the URL's content was created by a social media account, the country in which the account is registered</li> <li><code>creator_identifier</code> if the URL's content was created by a social media account, the social media platform's identifier for the account</li> <li><code>creator_facebook_follow</code> : if the URL is a Facebook post, the number of Facebook followers the creator's account has</li> <li><code>creator_facebook_subscribe</code> : if the URL is a Facebook post, the number of Facebook subscribers the creator's account has</li> <li><code>creator_twitter_follow</code> : if the URL is a Tweet, the number of Twitter / X followers the creator's account has</li> <li><code>creator_youtube_subscribe</code> : if the URL is a YouTube video, the number of YouTube channel subscribers the channel has</li> <li><code>creator_create_video</code> : if the URL is a YouTube video, the number of videos the YouTube channel has created</li> <li><code>creator_name</code> : the name of the creator of the URL's content</li> <li><code>creator_url</code> : if the URL is a social media post, a link to the creator's account page on the platform</li> <li><code>facebook_comment</code> : number of comments the URL has received on Facebook</li> <li><code>facebook_like</code> : number of likes the URL has received on Facebook</li> <li><code>facebook_share</code> : number of shares the URL has received on Facebook</li> <li><code>pinterest_share</code> : number of shares the URL has received on Pinterest</li> <li><code>twitter_share</code> : number of shares the URL has received on Twitter / X</li> <li><code>tiktok_share</code> : number of shares the URL has received on TikTok</li> <li><code>tiktok_comment</code> : number of comments the URL has received on TikTok</li> <li><code>reddit_engagement</code> : metric engagement the URL has received on Reddit</li> <li><code>youtube_watch</code> : number of views the URL has received on YouTube</li> <li><code>youtube_comment</code> : number of comments the URL has received on YouTube</li> <li><code>youtube_like</code> : number of likes the URL has received on YouTube</li> <li><code>youtube_favorite</code> : number of favorite reactions the URL has received on YouTube</li> <li><code>youtube_subscribe</code> : if the URL is of a YouTube channel, the channel's number of subscribers</li> <li><code>create_video</code>: if the URL is of a YouTube channel, the number of videos the channel has created</li> </ul> <p>Example from https://realpython.com/python-project-documentation-with-mkdocs/</p>"},{"location":"how-to-guides/","title":"How-To Guides","text":""},{"location":"how-to-guides/#using-minall-from-the-command-line","title":"Using <code>minall</code> from the command line","text":""},{"location":"how-to-guides/#context","title":"Context","text":"<p>Let's say we have a set of 2 URLs, one is a web page and the other is a YouTube video.</p> <p><code>data.csv</code></p> target_url https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ https://www.youtube.com/watch?v=BTvfWbAjh1w <p>And we've stored the data file in our current working directory under the name <code>data.csv</code>.</p> <pre><code>.\n\u2502\n\u2514\u2500\u2500 data.csv\n</code></pre>"},{"location":"how-to-guides/#set-up-files","title":"Set up files","text":"<p>For the purposes of this demonstration, we'll need to create an additional file, <code>config.yml</code>.</p> <pre><code>.\n\u2502\n\u251c\u2500\u2500 config.yml\n\u2502\n\u2514\u2500\u2500 data.csv\n</code></pre> <p>This YAML file is a configuration file in the same format as that used in <code>minet</code>, and it contains API keys.</p> <p><code>config.yml</code> <pre><code>---\nbuzzsumo:\n  token: \"XXXX\" # Used as --token for `minet bz` commands\ncrowdtangle:\n  token: \"XXXX\" # Used as --token for `minet ct` commands\n  rate_limit: 50 # Used as --rate-limit for `minet ct` commands\nyoutube:\n  key: \"XXXX\" # Used as --key for `minet yt` commands\n</code></pre></p>"},{"location":"how-to-guides/#set-up-minall","title":"Set up <code>minall</code>","text":"<p>Now we'll install <code>minall</code>. Create and activate a virtual Python environment, using version 3.11. Then install the tool with pip.</p> <pre><code>$ pip install git+https://github.com/medialab/minall.git\n</code></pre>"},{"location":"how-to-guides/#run","title":"Run","text":"<p>Finally, let's run the workflow on our dataset. We'll set the parameters as follows:</p> <ul> <li><code>--config</code> : Path to the YAML configuration file, <code>./config.yml</code></li> <li><code>--links</code> : Path to the dataset of target URLs, <code>./data.csv</code></li> <li><code>--url-col</code>: Name of the column in the dataset file with the target URLs. <code>target_url</code></li> <li><code>--output-dir</code>: Path to where <code>minall</code> will export its results. <code>./output/</code></li> </ul> <pre><code>$ minall --config config.yml --output-dir output/ --links data.csv --url-col target_url\n</code></pre> <p>While <code>minall</code> is running, we'll see the following commands proceed:</p> <pre><code>Querying YouTube videos   1/1 0:00:00\nQuerying YouTube channels   1/1 0:00:00\nScraping webpage   1/1 0:00:00\nCalling Buzzsumo API   2/2 0:00:05\n</code></pre>"},{"location":"how-to-guides/#results","title":"Results","text":"<p>The results will be written to files in the directory whose path was given to the parameter <code>--output-dir</code>.</p> <pre><code>.\n\u2502\n\u251c\u2500\u2500 config.yml\n\u2502\n\u251c\u2500\u2500 data.csv\n\u2502\n\u2514\u2500\u2500 output/\n    \u251c\u2500\u2500 links.csv\n    \u2514\u2500\u2500 shared_content.csv\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>This tutorial will walk you through a real-life example of why and how to use <code>minall</code>.</p>"},{"location":"tutorials/#example-dataset","title":"Example dataset","text":"<p>Let's say we have a list of URLs whose basic metadata and propagation online we want to study. We've stored those URLs in a CSV file under the column <code>target_url</code>. Both are about Guillaume Plique's presentation of <code>minet</code> at the FOSDEM conference in 2020. One of the URLs is of a web page from the conference's site and the other is a YouTube video, published by the conference organization.</p> target_url https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ https://www.youtube.com/watch?v=BTvfWbAjh1w <p>If using <code>minet</code>, we'd need to run 2 different commands based on the type of URL, <code>minet yt</code> for the YouTube video and <code>minet fetch</code> / <code>minet extract</code> for the web page. When working with just 2 URLs, that's not such a problem. However, let's imagine our list of URLs is much bigger than these 2 rows and that we don't aleady know what type of content is in it. Plus, we want to be able to work with the collected data as a set, comparing identical attributes of both the web page and the YouTube video. <code>minet</code>'s commands write their results in data fields that are unique to each sub-command. This idiosyncracy complicates comparative analysis. What <code>minall</code> does, in one single command, is output fewer but harmonized data fields, which apply to all types of web content.</p>"},{"location":"tutorials/#set-up-required-files","title":"Set up required files","text":"<p>For the purposes of this tutorial, let's create two files in our current working directory. One is the dataset described above (<code>data.csv</code>) and the second is a YAML configuation file, which is the same as that used in <code>minet</code> (<code>config.yml</code>).</p> <pre><code>.\n\u2502\n\u251c\u2500\u2500 config.yml\n\u2502\n\u2514\u2500\u2500 data.csv\n</code></pre> <p>Because API keys are not always available, <code>minall</code> does not require them to function. However, the majority of its enrichments depend on various APIs and, if not using any, we might as well just use <code>minet</code>'s scraping commands directly.</p> <p>Let's assume we only have a YouTube API key, which is free and can be obtained from Google with a Gmail account. We'll set up the configuration file like so:</p> <p><code>config.yml</code> <pre><code>---\nyoutube:\n  key: \"XXXX\"\n</code></pre></p>"},{"location":"tutorials/#api-keys","title":"API keys","text":"<p>Technically, <code>minall</code> does not require a configuration file to function because it can skip over any enrichment methods that require API keys the user did not provide. Only the dataset file, which contains target URLs, is absolutley necessary. However, the purpose of using <code>minall</code> is to take advantage of <code>minet</code>'s many API clients in one single command. Thus, though not important for this tutorial, it's best if you can fill out the entire configuration file below:</p> <pre><code>---\nbuzzsumo:\n  token: \"XXXX\" # Used as --token for `minet bz` commands\ncrowdtangle:\n  token: \"XXXX\" # Used as --token for `minet ct` commands\n  rate_limit: 50 # Used as --rate-limit for `minet ct` commands\nyoutube:\n  key: \"XXXX\" # Used as --key for `minet yt` commands\n</code></pre> <ul> <li>YouTube's API key can be requested from Google.</li> <li>CrowdTangle's API key can be requested from Meta</li> <li>Buzzsumo's API key can be purchased from Buzzsumo.</li> </ul>"},{"location":"tutorials/#install-minall","title":"Install <code>minall</code>","text":"<p>Because <code>minall</code> is written entirely in Python, we need to have Python installed, specifically version 3.11-something. We also need to create a \"virtual\" Python environment.</p> <p>In a shell with the virtual Python environment activated, install <code>minall</code> from GitHub.</p> <pre><code>$ pip install git+https://github.com/medialab/minall.git\n</code></pre> <p>Let's check that we installed it correctly by entering the command <code>minall --help</code>. The following should show up in the console:</p> <pre><code>usage: Minall [-h] [--database DATABASE] [--config CONFIG] --output-dir\n              OUTPUT_DIR --links LINKS_FILE --url-col URL_COL\n              [--shared-content SHARED_CONTENT_FILE] [--buzzsumo-only]\n\noptions:\n  -h, --help            show this help message and exit\n  --database DATABASE   [Optional] Path to SQLite database. If not given,\n                        database written to memory.\n  --config CONFIG       [Optional] Path to configuration file. If not\n                        given, environment variables are expected.\n  --output-dir OUTPUT_DIR\n                        [Required] Path to directory in which a links and\n                        shared_content file will be written.\n  --links LINKS_FILE    [Required] Path to links file.\n  --url-col URL_COL     [Required] Name of URL column in links file.\n  --shared-content SHARED_CONTENT_FILE\n                        [Optional] Path to shared_content file.\n  --buzzsumo-only       [Optional] Flag indicating only Buzzsumo API will\n                        be called on links file.\n</code></pre>"},{"location":"tutorials/#run","title":"Run","text":"<p>Now we're ready to run <code>minall</code> on our dataset of URLs about Guillaume Plique's FOSDEM presentation. The <code>minall</code> command will produce 2 new CSV files, one has all of the dataset's URLs and their newly collected metadata (<code>links.csv</code>), the other has URLs pointing to media content that was embedded inside the target URL's web content (<code>shared_content.csv</code>).</p> <p>Note: Currently, <code>minall</code> only records the URLS of embedded media content when it's shared inside a Facebook post. This feature, however, should be expanded to include media (images, videos) shared inside articles.</p> <p>We'll ask <code>minall</code> to write the 2 new files to a directory named <code>output</code>, which will eventually (at the end of the workflow) change our current working directory like so:</p> <pre><code>.\n\u2502\n\u251c\u2500\u2500 config.yml\n\u2502\n\u251c\u2500\u2500 data.csv\n\u2502\n\u2514\u2500\u2500 output/\n    \u251c\u2500\u2500 links.csv\n    \u2514\u2500\u2500 shared_content.csv\n</code></pre> <p>To run <code>minall</code>, we'll call the command with the following options:</p> <ul> <li><code>--config</code> : Path to the YAML configuration file, <code>./config.yml</code></li> <li><code>--links</code> : Path to the dataset of target URLs, <code>./data.csv</code></li> <li><code>--url-col</code>: Name of the column in the dataset file with the target URLs. <code>target_url</code></li> <li><code>--output-dir</code>: Path to where <code>minall</code> will export its results. <code>./output/</code></li> </ul> <pre><code>$ minall --config config.yml --output-dir output/ --links data.csv --url-col target_url\n</code></pre> <p>While <code>minall</code> is running, we'll see the following commands proceed:</p> <pre><code>Querying YouTube videos   1/1 0:00:00\nQuerying YouTube channels   1/1 0:00:00\nScraping webpage   1/1 0:00:00\n</code></pre> <p>Had our dataset included URLs from Facebook and had we provided a CrowdTangle API key, <code>minall</code> would have also called the CrowdTangle API. But because our dataset only included the URL of a web page and of a YouTube video, it ran through only its YouTube API and scraping utilities. Had we provided a Buzzsumo API key, it would have also called the Buzzsumo API twice, searching for both the web page's URL and the YouTube video's URL in Buzzsumo's database.</p>"},{"location":"tutorials/#understanding-the-results","title":"Understanding the results","text":"<p>A portion of the <code>output/links.csv</code> file that <code>minall</code> created is shown below.</p> target_url url domain work_type duration identifier date_published ... title https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ fosdem.org WebPage 2020-02-01 ... FOSDEM 2020 - Empowering social scientists with web mining tools https://www.youtube.com/watch?v=BTvfWbAjh1w https://www.youtube.com/watch?v=BTvfWbAjh1w youtube.com VideoObject 1431 BTvfWbAjh1w 2021-07-12T06:53:30 ... Empowering social scientists with web mining tools Why and how to enable researchers to perform com\u2026 <p>We see that <code>minall</code> read the columns in our data file, specifically <code>target_url</code>, conserved the original column, and appended the enrichment's additional columns to the right.</p> <p>We also see that FOSDEM published the announcement of Guillaume Plique's presentation about <code>minet</code> on their website just before the conference, on 1 February 2020. However, FOSDEM uploaded a video of the presentation to YouTube over a year later, on 12 July 2021. Though we have no way of knowing how many people viewed the web page, YouTube's API allows us know how many people viewed, commented on, and liked the video.</p> target_url ... reddit_engagement youtube_watch youtube_comment youtube_like https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ https://www.youtube.com/watch?v=BTvfWbAjh1w 69 0 3"},{"location":"tutorials/#buzzsumo","title":"Buzzsumo","text":"<p>Because we didn't provide <code>minall</code> with a Buzzsumo API key, it was unable to ask Buzzsumo if the database had cached metadata about either of our dataset's URLs. Had we included Buzzsumo in our configuration file, <code>minall</code> would have told us that Buzzsumo does have information about the FOSDEM video on YouTube; however, it does not have any information about the web page on FOSDEM's site.</p> <p>We know when Buzzsumo has stored information about one of our target URLs because certain data fields in the <code>links.csv</code> file will have a value. For example, if we were to run <code>minall</code> again with a Buzzsumo API key in the configuration file, we would know Buzzsumo cached our dataset's YouTube video because we see values in data fields that are beyond the scope of YouTube's API, specifically <code>facebook_comment</code>, <code>pinterest_share</code>, and <code>twitter_share</code>. It is normal that some of Buzzsumo's data fields, such as <code>tiktok_share</code>, are empty even though Buzzsumo found an exact match of our target URL in its database. The fact that none of the data fields for our dataset's web page have any value means that Buzzsumo did not find the FOSDEM URL.</p> target_url ... facebook_comment facebook_like pinterest_share twitter_share tiktok_share https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/ https://www.youtube.com/watch?v=BTvfWbAjh1w 0 0 0"},{"location":"reference/cli/","title":"CLI tools","text":""},{"location":"reference/cli/#minall.cli.run","title":"<code>minall.cli.run</code>","text":"<p>CLI action for minall workflow.</p> <p>This module contains the function <code>cli()</code>, which runs the minall workflow as a CLI tool.</p> <p>The function <code>cli()</code> requests and parses the command-line arguments that are necessary to create an instance of the <code>Minall</code> class. Then, it deploys the <code>Minall</code> class's workflow.</p>"},{"location":"reference/cli/#minall.cli.run.cli","title":"<code>cli()</code>","text":"<p>Run minall workflow from the command line.</p> Source code in <code>minall/cli/run.py</code> <pre><code>def cli():\n    \"\"\"Run minall workflow from the command line.\"\"\"\n\n    args = cli_args()\n\n    app = Minall(**args)\n\n    app.collect_and_coalesce()\n\n    app.export()\n</code></pre>"},{"location":"reference/cli/#minall.cli.parse_args","title":"<code>minall.cli.parse_args</code>","text":"<p>Helper functions for CLI action.</p> <p>This module contains the following helper functions for parsing command-line arguments:</p> <ul> <li><code>cli_args()</code> - Parse CLI arguments.</li> <li><code>dir_path(path_name)</code> - Create directory and necessary parent directories.</li> <li><code>file_path(path_name)</code> - Verify existence of given file.</li> <li><code>has_parent(path_name)</code> - Create necessary parent directories for file path.</li> </ul>"},{"location":"reference/cli/#minall.cli.parse_args.cli_args","title":"<code>cli_args()</code>","text":"<p>Function to call and parse command-line arguments.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary of parsed command-line arguments.</p> Source code in <code>minall/cli/parse_args.py</code> <pre><code>def cli_args() -&gt; dict:\n    \"\"\"Function to call and parse command-line arguments.\n\n    Returns:\n        dict: Dictionary of parsed command-line arguments.\n    \"\"\"\n    parser = ArgumentParser(\n        add_help=True, prog=\"Minall\", formatter_class=RawDescriptionHelpFormatter\n    )\n    parser.add_argument(\n        \"--database\",\n        dest=\"database\",\n        required=False,\n        type=has_parent,\n        help=\"[Optional] Path to SQLite database. If not given, database written to memory.\",\n    )\n    parser.add_argument(\n        \"--config\",\n        dest=\"config\",\n        type=file_path,\n        required=False,\n        help=\"[Optional] Path to configuration file. If not given, environment variables are expected.\",\n    )\n    parser.add_argument(\n        \"--output-dir\",\n        dest=\"output_dir\",\n        type=dir_path,\n        required=True,\n        help=\"[Required] Path to directory in which a links and shared_content file will be written.\",\n    )\n    parser.add_argument(\n        \"--links\",\n        dest=\"links_file\",\n        type=file_path,\n        required=True,\n        help=\"[Required] Path to links file.\",\n    )\n    parser.add_argument(\n        \"--url-col\",\n        dest=\"url_col\",\n        type=str,\n        required=True,\n        help=\"[Required] Name of URL column in links file.\",\n    )\n    parser.add_argument(\n        \"--shared-content\",\n        dest=\"shared_content_file\",\n        type=file_path,\n        required=False,\n        help=\"[Optional] Path to shared_content file.\",\n    )\n    parser.add_argument(\n        \"--buzzsumo-only\",\n        dest=\"buzzsumo_only\",\n        default=False,\n        required=False,\n        action=\"store_true\",\n        help=\"[Optional] Flag indicating only Buzzsumo API will be called on links file.\",\n    )\n    args = parser.parse_args()\n    return args.__dict__\n</code></pre>"},{"location":"reference/cli/#minall.cli.parse_args.dir_path","title":"<code>dir_path(path_name)</code>","text":"<p>Function to convert CLI argument to created directory.</p> <p>Parameters:</p> Name Type Description Default <code>path_name</code> <code>str</code> <p>Path to target directory.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to prepared directory.</p> Source code in <code>minall/cli/parse_args.py</code> <pre><code>def dir_path(path_name: str) -&gt; str:\n    \"\"\"Function to convert CLI argument to created directory.\n\n    Args:\n        path_name (str): Path to target directory.\n\n    Returns:\n        str: Path to prepared directory.\n    \"\"\"\n    if Path(path_name).is_dir():\n        return path_name\n    else:\n        Path(path_name).mkdir(exist_ok=True)\n        [p.mkdir(exist_ok=True) for p in Path(path_name).parents]\n        return path_name\n</code></pre>"},{"location":"reference/cli/#minall.cli.parse_args.file_path","title":"<code>file_path(path_name)</code>","text":"<p>Function to convert CLI argument to verified, found file path.</p> <p>Parameters:</p> Name Type Description Default <code>path_name</code> <code>str</code> <p>Path to data file.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>Data file not found at given path.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Verified path to data file.</p> Source code in <code>minall/cli/parse_args.py</code> <pre><code>def file_path(path_name: str) -&gt; str:\n    \"\"\"Function to convert CLI argument to verified, found file path.\n\n    Args:\n        path_name (str): Path to data file.\n\n    Raises:\n        FileNotFoundError: Data file not found at given path.\n\n    Returns:\n        str: Verified path to data file.\n    \"\"\"\n    if Path(path_name).is_file():\n        return path_name\n    else:\n        raise FileNotFoundError(path_name)\n</code></pre>"},{"location":"reference/cli/#minall.cli.parse_args.has_parent","title":"<code>has_parent(path_name)</code>","text":"<p>Function to convert CLI argument to file path with created parent directories.</p> <p>Parameters:</p> Name Type Description Default <code>path_name</code> <code>str</code> <p>Path to out-file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to out-file with created parent directories.</p> Source code in <code>minall/cli/parse_args.py</code> <pre><code>def has_parent(path_name: str) -&gt; str:\n    \"\"\"Function to convert CLI argument to file path with created parent directories.\n\n    Args:\n        path_name (str): Path to out-file.\n\n    Returns:\n        str: Path to out-file with created parent directories.\n    \"\"\"\n    [p.mkdir(exist_ok=True) for p in Path(path_name).parents]\n    return path_name\n</code></pre>"},{"location":"reference/enrichment/","title":"Enrichment tools","text":""},{"location":"reference/enrichment/#minall.enrichment.enrichment","title":"<code>minall.enrichment.enrichment</code>","text":"<p>Class for data collection and coalescing.</p> <p>With the class <code>Enrichment</code>, this module manages the data collection process.</p> <p>The class contains the following methods:</p> <ul> <li><code>__init__(links_table, shared_content_table, keys)</code> -</li> </ul>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment","title":"<code>Enrichment</code>","text":"Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>class Enrichment:\n    def __init__(\n        self,\n        links_table: LinksTable,\n        shared_content_table: SharedContentTable,\n        keys: APIKeys,\n    ) -&gt; None:\n        \"\"\"From given API keys and URL data set, filter URLs by domain and initialize data enrichment class.\n\n        Args:\n            links_table (BaseTable): BaseTable class instance of SQL table for URL dataset.\n            shared_content_table (BaseTable): BaseTable class instance of SQL table for shared content related to URLs in dataset.\n            keys (APIKeys): APIKeys class instance of minet API client configurations.\n        \"\"\"\n\n        self.links_table = links_table\n        self.shared_content_table = shared_content_table\n        self.keys = keys\n        self.filtered_links = FilteredLinks(self.links_table)\n\n    def buzzsumo(self):\n        \"\"\"For all URLs, collect data from Buzzsumo and coalesce in the database's 'links' table.\"\"\"\n\n        if self.keys.buzzsumo_token:\n            get_buzzsumo_data(\n                data=self.filtered_links.all_links,\n                token=self.keys.buzzsumo_token,\n                outfile=self.links_table.outfile,\n            )\n            self.links_table.update_from_csv(datafile=self.links_table.outfile)\n\n    def scraper(self):\n        \"\"\"For select URLs, collect data via scraping and coalesce in the database's 'links' table.\"\"\"\n\n        # In multiple threads, scrape HTML data and write to a CSV file\n        get_article_text(\n            data=self.filtered_links.to_scrape, outfile=self.links_table.outfile\n        )\n        # Coalesce the results in the CSV File to the links table\n        self.links_table.update_from_csv(datafile=self.links_table.outfile)\n\n    def other_social_media(self):\n        \"\"\"For select URLs, update the 'work_type' column in the database's 'links' table with the value 'SocialMediaPosting'.\"\"\"\n        # Assign default type to social media post\n        add_type_data(\n            data=self.filtered_links.other_social, outfile=self.links_table.outfile\n        )\n        # Coalesce the results in the CSV File to the links table\n        self.links_table.update_from_csv(datafile=self.links_table.outfile)\n\n    def facebook(self):\n        \"\"\"For Facebook URLs, collect data from CrowdTangle and coalesce in the database's 'links' and 'shared_content' tables.\"\"\"\n        if self.keys.crowdtangle_token:\n            get_facebook_post_data(\n                data=self.filtered_links.facebook,\n                token=self.keys.crowdtangle_token,\n                rate_limit=self.keys.crowdtangle_rate_limit,\n                links_outfile=self.links_table.outfile,\n                shared_content_outfile=self.shared_content_table.outfile,\n            )\n            # Coalesce the results in the CSV File to the links table\n            self.links_table.update_from_csv(datafile=self.links_table.outfile)\n            self.shared_content_table.update_from_csv(\n                datafile=self.shared_content_table.outfile\n            )\n\n    def youtube(self):\n        \"\"\"For YouTube URLs, collect data from YouTube API and coalesce in the database's 'links' table.\"\"\"\n        if self.keys.youtube_key:\n            # In single thread, collect YouTube API data and write to a CSV file\n            get_youtube_data(\n                data=self.filtered_links.youtube,\n                keys=self.keys.youtube_key,\n                outfile=self.links_table.outfile,\n            )\n            # Coalesce the results in the CSV File to the links table\n            self.links_table.update_from_csv(datafile=self.links_table.outfile)\n\n    def __call__(self, buzzsumo_only: bool):\n        executor = SQLiteWrapper(connection=self.links_table.conn)\n        # apply domain to all urls\n        for link in self.filtered_links.all_links:\n            query, domain = apply_domain(link)\n            if query and domain:\n                self.links_table.conn\n                executor(query=query)\n\n        if not buzzsumo_only:\n            if len(self.filtered_links.youtube) &gt; 0:\n                self.youtube()\n            if len(self.filtered_links.facebook) &gt; 0:\n                self.facebook()\n            if len(self.filtered_links.other_social) &gt; 0:\n                self.other_social_media()\n            if len(self.filtered_links.to_scrape) &gt; 0:\n                self.scraper()\n        self.buzzsumo()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.__init__","title":"<code>__init__(links_table, shared_content_table, keys)</code>","text":"<p>From given API keys and URL data set, filter URLs by domain and initialize data enrichment class.</p> <p>Parameters:</p> Name Type Description Default <code>links_table</code> <code>BaseTable</code> <p>BaseTable class instance of SQL table for URL dataset.</p> required <code>shared_content_table</code> <code>BaseTable</code> <p>BaseTable class instance of SQL table for shared content related to URLs in dataset.</p> required <code>keys</code> <code>APIKeys</code> <p>APIKeys class instance of minet API client configurations.</p> required Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def __init__(\n    self,\n    links_table: LinksTable,\n    shared_content_table: SharedContentTable,\n    keys: APIKeys,\n) -&gt; None:\n    \"\"\"From given API keys and URL data set, filter URLs by domain and initialize data enrichment class.\n\n    Args:\n        links_table (BaseTable): BaseTable class instance of SQL table for URL dataset.\n        shared_content_table (BaseTable): BaseTable class instance of SQL table for shared content related to URLs in dataset.\n        keys (APIKeys): APIKeys class instance of minet API client configurations.\n    \"\"\"\n\n    self.links_table = links_table\n    self.shared_content_table = shared_content_table\n    self.keys = keys\n    self.filtered_links = FilteredLinks(self.links_table)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.buzzsumo","title":"<code>buzzsumo()</code>","text":"<p>For all URLs, collect data from Buzzsumo and coalesce in the database's 'links' table.</p> Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def buzzsumo(self):\n    \"\"\"For all URLs, collect data from Buzzsumo and coalesce in the database's 'links' table.\"\"\"\n\n    if self.keys.buzzsumo_token:\n        get_buzzsumo_data(\n            data=self.filtered_links.all_links,\n            token=self.keys.buzzsumo_token,\n            outfile=self.links_table.outfile,\n        )\n        self.links_table.update_from_csv(datafile=self.links_table.outfile)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.facebook","title":"<code>facebook()</code>","text":"<p>For Facebook URLs, collect data from CrowdTangle and coalesce in the database's 'links' and 'shared_content' tables.</p> Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def facebook(self):\n    \"\"\"For Facebook URLs, collect data from CrowdTangle and coalesce in the database's 'links' and 'shared_content' tables.\"\"\"\n    if self.keys.crowdtangle_token:\n        get_facebook_post_data(\n            data=self.filtered_links.facebook,\n            token=self.keys.crowdtangle_token,\n            rate_limit=self.keys.crowdtangle_rate_limit,\n            links_outfile=self.links_table.outfile,\n            shared_content_outfile=self.shared_content_table.outfile,\n        )\n        # Coalesce the results in the CSV File to the links table\n        self.links_table.update_from_csv(datafile=self.links_table.outfile)\n        self.shared_content_table.update_from_csv(\n            datafile=self.shared_content_table.outfile\n        )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.other_social_media","title":"<code>other_social_media()</code>","text":"<p>For select URLs, update the 'work_type' column in the database's 'links' table with the value 'SocialMediaPosting'.</p> Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def other_social_media(self):\n    \"\"\"For select URLs, update the 'work_type' column in the database's 'links' table with the value 'SocialMediaPosting'.\"\"\"\n    # Assign default type to social media post\n    add_type_data(\n        data=self.filtered_links.other_social, outfile=self.links_table.outfile\n    )\n    # Coalesce the results in the CSV File to the links table\n    self.links_table.update_from_csv(datafile=self.links_table.outfile)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.scraper","title":"<code>scraper()</code>","text":"<p>For select URLs, collect data via scraping and coalesce in the database's 'links' table.</p> Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def scraper(self):\n    \"\"\"For select URLs, collect data via scraping and coalesce in the database's 'links' table.\"\"\"\n\n    # In multiple threads, scrape HTML data and write to a CSV file\n    get_article_text(\n        data=self.filtered_links.to_scrape, outfile=self.links_table.outfile\n    )\n    # Coalesce the results in the CSV File to the links table\n    self.links_table.update_from_csv(datafile=self.links_table.outfile)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.enrichment.Enrichment.youtube","title":"<code>youtube()</code>","text":"<p>For YouTube URLs, collect data from YouTube API and coalesce in the database's 'links' table.</p> Source code in <code>minall/enrichment/enrichment.py</code> <pre><code>def youtube(self):\n    \"\"\"For YouTube URLs, collect data from YouTube API and coalesce in the database's 'links' table.\"\"\"\n    if self.keys.youtube_key:\n        # In single thread, collect YouTube API data and write to a CSV file\n        get_youtube_data(\n            data=self.filtered_links.youtube,\n            keys=self.keys.youtube_key,\n            outfile=self.links_table.outfile,\n        )\n        # Coalesce the results in the CSV File to the links table\n        self.links_table.update_from_csv(datafile=self.links_table.outfile)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.utils","title":"<code>minall.enrichment.utils</code>","text":"<p>Functions for data collection.</p> <p>This module provides the following class and functions:</p> <ul> <li><code>get_domain(url)</code> - Parse domain from URL string.</li> <li><code>apply_domain(url)</code> - Generate SQL query to insert domain into table.</li> <li><code>FilteredLinks(table)</code> - From SQL table, select subsets of URLs based on domain name.</li> </ul>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks","title":"<code>FilteredLinks</code>","text":"<p>Selects all URLs from SQL table and returns subsets.</p> Source code in <code>minall/enrichment/utils.py</code> <pre><code>class FilteredLinks:\n    \"\"\"Selects all URLs from SQL table and returns subsets.\"\"\"\n\n    def __init__(self, table: LinksTable) -&gt; None:\n        \"\"\"Select and store all URLs from a target SQL table.\n\n        Args:\n            table (BaseTable): Target SQL table.\n        \"\"\"\n        cursor = table.conn.cursor()\n        self.all_links = [\n            row[0] for row in cursor.execute(f\"SELECT url FROM {table.name}\").fetchall()\n        ]\n\n    @property\n    def youtube(self) -&gt; List[str]:\n        \"\"\"List of URLs from YouTube.\n\n        Returns:\n            List[str]: List of URL strings.\n        \"\"\"\n        return [url for url in self.all_links if is_youtube_url(url=url)]\n\n    @property\n    def facebook(self) -&gt; List[str]:\n        \"\"\"List of URLs from Facebook.\n\n        Returns:\n            List[str]: List of URL strings.\n        \"\"\"\n        return [url for url in self.all_links if is_facebook_url(url=url)]\n\n    @property\n    def other_social(self) -&gt; List[str]:\n        \"\"\"List of URLs from social media platforms.\n\n        Returns:\n            List[str]: List of URL strings.\n        \"\"\"\n        return [\n            url\n            for url in self.all_links\n            if get_domain(url=url)\n            in [\n                \"facebook.com\",\n                \"youtube.com\",\n                \"tiktok.com\",\n                \"instagram.com\",\n                \"twitter.com\",\n                \"snapchat.com\",\n            ]\n        ]\n\n    @property\n    def to_scrape(self) -&gt; List[str]:\n        \"\"\"List of URLs not from social media platforms.\n\n        Returns:\n            List[str]: List of URL strings.\n        \"\"\"\n        return [\n            url\n            for url in self.all_links\n            if get_domain(url=url)\n            not in [\n                \"facebook.com\",\n                \"youtube.com\",\n                \"tiktok.com\",\n                \"instagram.com\",\n                \"twitter.com\",\n                \"snapchat.com\",\n            ]\n        ]\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks.facebook","title":"<code>facebook: List[str]</code>  <code>property</code>","text":"<p>List of URLs from Facebook.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of URL strings.</p>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks.other_social","title":"<code>other_social: List[str]</code>  <code>property</code>","text":"<p>List of URLs from social media platforms.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of URL strings.</p>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks.to_scrape","title":"<code>to_scrape: List[str]</code>  <code>property</code>","text":"<p>List of URLs not from social media platforms.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of URL strings.</p>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks.youtube","title":"<code>youtube: List[str]</code>  <code>property</code>","text":"<p>List of URLs from YouTube.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of URL strings.</p>"},{"location":"reference/enrichment/#minall.enrichment.utils.FilteredLinks.__init__","title":"<code>__init__(table)</code>","text":"<p>Select and store all URLs from a target SQL table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>BaseTable</code> <p>Target SQL table.</p> required Source code in <code>minall/enrichment/utils.py</code> <pre><code>def __init__(self, table: LinksTable) -&gt; None:\n    \"\"\"Select and store all URLs from a target SQL table.\n\n    Args:\n        table (BaseTable): Target SQL table.\n    \"\"\"\n    cursor = table.conn.cursor()\n    self.all_links = [\n        row[0] for row in cursor.execute(f\"SELECT url FROM {table.name}\").fetchall()\n    ]\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.utils.apply_domain","title":"<code>apply_domain(url)</code>","text":"<p>Compose SQL query to update the domain column of a URL's row in the 'links' SQLite table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; apply_domain(url=\"https://www.youtube.com/channel/MkDocs\")\n(\"UPDATE links SET domain = 'youtube.com' WHERE url = 'https://www.youtube.com/channel/MkDocs'\", 'youtube.com')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL string.</p> required <p>Returns:</p> Type Description <code>Tuple[str | None, str | None]</code> <p>Tuple[str | None, str | None]: If domain was parsed, a tuple containing the SQL query and domain name.</p> Source code in <code>minall/enrichment/utils.py</code> <pre><code>def apply_domain(url: str) -&gt; Tuple[str | None, str | None]:\n    \"\"\"Compose SQL query to update the domain column of a URL's row in the 'links' SQLite table.\n\n    Examples:\n        &gt;&gt;&gt; apply_domain(url=\"https://www.youtube.com/channel/MkDocs\")\n        (\"UPDATE links SET domain = 'youtube.com' WHERE url = 'https://www.youtube.com/channel/MkDocs'\", 'youtube.com')\n\n    Args:\n        url (str): URL string.\n\n    Returns:\n        Tuple[str | None, str | None]: If domain was parsed, a tuple containing the SQL query and domain name.\n    \"\"\"\n\n    query = None\n    domain = get_domain(url)\n    if domain:\n        query = f\"UPDATE {LinksConstants.table_name} SET domain = '{domain}' WHERE {LinksConstants.primary_key} = '{url}'\"\n    return query, domain\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.utils.get_domain","title":"<code>get_domain(url)</code>","text":"<p>Parse the domain name of a given URL string.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_domain(url=\"https://www.youtube.com/channel/MkDocs\")\n'youtube.com'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL string.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: If successfully parsed, domain name.</p> Source code in <code>minall/enrichment/utils.py</code> <pre><code>def get_domain(url: str) -&gt; str | None:\n    \"\"\"Parse the domain name of a given URL string.\n\n    Examples:\n        &gt;&gt;&gt; get_domain(url=\"https://www.youtube.com/channel/MkDocs\")\n        'youtube.com'\n\n    Args:\n        url (str): URL string.\n\n    Returns:\n        str | None: If successfully parsed, domain name.\n    \"\"\"\n\n    domain_name = ural.get_domain_name(url)\n    if domain_name in YOUTUBE_DOMAINS:\n        domain_name = \"youtube.com\"\n    return domain_name\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo","title":"<code>minall.enrichment.buzzsumo</code>","text":"<p>Enrichment workflow's Buzzsumo data collection.</p> <p>Modules exported by this package:</p> <ul> <li><code>normalizer</code>: Dataclass to normlalize minet's Buzzsumo result object.</li> <li><code>contexts</code>: Context manager for client's CSV writers, multi-threader, and progress bar.</li> <li><code>get_data</code>: Function that runs all of the Buzzsumo enrichment process.</li> <li><code>client</code>: Wrapper for minet's Buzzsumo API client that normalizes minet's result.</li> </ul>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.normalizer","title":"<code>minall.enrichment.buzzsumo.normalizer</code>","text":"<p>Module contains constants for minet's Buzzsumo API client and a dataclass to normalize minet's Buzzsumo result.</p>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.normalizer.NormalizedBuzzsumoResult","title":"<code>NormalizedBuzzsumoResult</code>  <code>dataclass</code>","text":"<p>             Bases: <code>TabularRecord</code></p> <p>Dataclass to normalize minet's Buzzsumo API result.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>Target URL searched in Buzzsumo database.</p> <code>work_type</code> <code>str</code> <p>Target URL's ontological subtype, i.e. \"WebPage\", \"Article\", \"VideoObject\".</p> <code>twitter_share</code> <code>int</code> <p>Number of times the target URL appeared on Twitter.</p> <code>facebook_share</code> <code>int</code> <p>Number of times the target URL appeared on Facebook.</p> <code>title</code> <code>str</code> <p>Title of target URL web content.</p> <code>date_published</code> <code>datetime</code> <p>Date target URL web content was published.</p> <code>pinterest_share</code> <code>int</code> <p>Number of times the target URL appeared on Pinterest.</p> <code>creator_name</code> <code>str</code> <p>Entity intellectually responsible for (author of) the target URL's web content.</p> <code>creator_identifier</code> <code>str</code> <p>If target URL is a social media post, the platform's identifier for the author.</p> <code>duration</code> <code>int</code> <p>If the target URL is of a video, the video's duration.</p> <code>facebook_comment</code> <code>int</code> <p>Number of times Facebook users commented on a post containing the target URL.</p> <code>youtube_watch</code> <code>int</code> <p>If the target URL is of a YouTube video, number of times YouTube users watched the video.</p> <code>youtube_like</code> <code>int</code> <p>If the target URL is of a YouTube video, number of times YouTube users liked the video.</p> <code>tiktok_share</code> <code>int</code> <p>If the target URL is of TikTok content, number of shares on TikTok.</p> <code>tiktok_comment</code> <code>int</code> <p>If the target URL is of TikTok content, number of times TikTok users commented on the content.</p> <code>reddit_engagement</code> <code>int</code> <p>Number of times the target URL appeared on Reddit.</p> Source code in <code>minall/enrichment/buzzsumo/normalizer.py</code> <pre><code>@dataclass\nclass NormalizedBuzzsumoResult(TabularRecord):\n    \"\"\"Dataclass to normalize minet's Buzzsumo API result.\n\n    Attributes:\n        url (str): Target URL searched in Buzzsumo database.\n        work_type (str): Target URL's ontological subtype, i.e. \"WebPage\", \"Article\", \"VideoObject\".\n        twitter_share (int): Number of times the target URL appeared on Twitter.\n        facebook_share (int): Number of times the target URL appeared on Facebook.\n        title (str): Title of target URL web content.\n        date_published (datetime): Date target URL web content was published.\n        pinterest_share (int): Number of times the target URL appeared on Pinterest.\n        creator_name (str): Entity intellectually responsible for (author of) the target URL's web content.\n        creator_identifier (str): If target URL is a social media post, the platform's identifier for the author.\n        duration (int): If the target URL is of a video, the video's duration.\n        facebook_comment (int): Number of times Facebook users commented on a post containing the target URL.\n        youtube_watch (int): If the target URL is of a YouTube video, number of times YouTube users watched the video.\n        youtube_like (int): If the target URL is of a YouTube video, number of times YouTube users liked the video.\n        tiktok_share (int): If the target URL is of TikTok content, number of shares on TikTok.\n        tiktok_comment (int): If the target URL is of TikTok content, number of times TikTok users commented on the content.\n        reddit_engagement (int): Number of times the target URL appeared on Reddit.\n    \"\"\"\n\n    url: str\n    work_type: str\n    domain: Optional[str]\n    twitter_share: Optional[int]\n    facebook_share: Optional[int]\n    title: Optional[str]\n    date_published: Optional[datetime]\n    pinterest_share: Optional[int]\n    creator_name: Optional[str]\n    creator_identifier: Optional[str]\n    duration: Optional[int]\n    facebook_comment: Optional[int]\n    youtube_watch: Optional[int]\n    youtube_like: Optional[int]\n    youtube_comment: Optional[int]\n    tiktok_share: Optional[int]\n    tiktok_comment: Optional[int]\n    reddit_engagement: Optional[int]\n\n    @classmethod\n    def parse_buzzsumo_type(cls, data: BuzzsumoArticle | None) -&gt; str:\n        \"\"\"Helper function for transforming Buzzsumo's content classification into Schema.org subtype.\n\n        Args:\n            data (BuzzsumoArticle | None): If target URL was found in Buzzsumo database, minet's result; otherwise, None.\n\n        Returns:\n            str: Schema for web content's subtype.\n        \"\"\"\n        video_types = [\"is_video\"]\n        article_types = [\n            \"is_general_article\",\n            \"is_how_to_article\",\n            \"is_infographic\",\n            \"is_interview\",\n            \"is_list\",\n            \"is_newsletter\",\n            \"is_press_release\",\n            \"is_review\",\n            \"is_what_post\",\n            \"is_why_post\",\n        ]\n        work_type = \"WebPage\"\n        if data:\n            for t in video_types:\n                if getattr(data, t):\n                    return \"VideoObject\"\n            for t in article_types:\n                if getattr(data, t):\n                    return \"Article\"\n        return work_type\n\n    @classmethod\n    def from_payload(\n        cls,\n        url: str,\n        data: BuzzsumoArticle | None,\n    ) -&gt; \"NormalizedBuzzsumoResult\":\n        \"\"\"Parses minet's Buzzsumo result and creates normalized dataclass.\n\n        Args:\n            url (str): Target URL searched in Buzzsumo's database.\n            data (BuzzsumoArticle | None): If target URL was found in Buzzsumo database, minet's result; otherwise, None.\n\n        Returns:\n            NormalizedBuzzsumoResult: Dataclass that normalizes minet's Buzzsumo data.\n        \"\"\"\n        if data:\n            return NormalizedBuzzsumoResult(\n                url=url,\n                domain=get_domain(url),\n                work_type=cls.parse_buzzsumo_type(data),\n                twitter_share=getattr(data, \"twitter_shares\"),\n                facebook_share=getattr(data, \"facebook_shares\"),\n                title=getattr(data, \"title\"),\n                date_published=getattr(data, \"published_date\"),\n                pinterest_share=getattr(data, \"pinterest_shares\"),\n                creator_name=getattr(data, \"author_name\"),\n                creator_identifier=getattr(data, \"twitter_user_id\"),\n                duration=getattr(data, \"video_length\"),\n                facebook_comment=getattr(data, \"facebook_comments\"),\n                youtube_watch=getattr(data, \"youtube_views\"),\n                youtube_like=getattr(data, \"youtube_likes\"),\n                youtube_comment=getattr(data, \"youtube_comments\"),\n                tiktok_share=getattr(data, \"tiktok_share_count\"),\n                tiktok_comment=getattr(data, \"tiktok_comment_count\"),\n                reddit_engagement=getattr(data, \"total_reddit_engagements\"),\n            )\n        else:\n            return NormalizedBuzzsumoResult(\n                url=url,\n                work_type=cls.parse_buzzsumo_type(data),\n                domain=None,\n                twitter_share=None,\n                facebook_share=None,\n                title=None,\n                date_published=None,\n                pinterest_share=None,\n                creator_name=None,\n                creator_identifier=None,\n                duration=None,\n                facebook_comment=None,\n                youtube_watch=None,\n                youtube_like=None,\n                youtube_comment=None,\n                tiktok_share=None,\n                tiktok_comment=None,\n                reddit_engagement=None,\n            )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.normalizer.NormalizedBuzzsumoResult.from_payload","title":"<code>from_payload(url, data)</code>  <code>classmethod</code>","text":"<p>Parses minet's Buzzsumo result and creates normalized dataclass.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target URL searched in Buzzsumo's database.</p> required <code>data</code> <code>BuzzsumoArticle | None</code> <p>If target URL was found in Buzzsumo database, minet's result; otherwise, None.</p> required <p>Returns:</p> Name Type Description <code>NormalizedBuzzsumoResult</code> <code>NormalizedBuzzsumoResult</code> <p>Dataclass that normalizes minet's Buzzsumo data.</p> Source code in <code>minall/enrichment/buzzsumo/normalizer.py</code> <pre><code>@classmethod\ndef from_payload(\n    cls,\n    url: str,\n    data: BuzzsumoArticle | None,\n) -&gt; \"NormalizedBuzzsumoResult\":\n    \"\"\"Parses minet's Buzzsumo result and creates normalized dataclass.\n\n    Args:\n        url (str): Target URL searched in Buzzsumo's database.\n        data (BuzzsumoArticle | None): If target URL was found in Buzzsumo database, minet's result; otherwise, None.\n\n    Returns:\n        NormalizedBuzzsumoResult: Dataclass that normalizes minet's Buzzsumo data.\n    \"\"\"\n    if data:\n        return NormalizedBuzzsumoResult(\n            url=url,\n            domain=get_domain(url),\n            work_type=cls.parse_buzzsumo_type(data),\n            twitter_share=getattr(data, \"twitter_shares\"),\n            facebook_share=getattr(data, \"facebook_shares\"),\n            title=getattr(data, \"title\"),\n            date_published=getattr(data, \"published_date\"),\n            pinterest_share=getattr(data, \"pinterest_shares\"),\n            creator_name=getattr(data, \"author_name\"),\n            creator_identifier=getattr(data, \"twitter_user_id\"),\n            duration=getattr(data, \"video_length\"),\n            facebook_comment=getattr(data, \"facebook_comments\"),\n            youtube_watch=getattr(data, \"youtube_views\"),\n            youtube_like=getattr(data, \"youtube_likes\"),\n            youtube_comment=getattr(data, \"youtube_comments\"),\n            tiktok_share=getattr(data, \"tiktok_share_count\"),\n            tiktok_comment=getattr(data, \"tiktok_comment_count\"),\n            reddit_engagement=getattr(data, \"total_reddit_engagements\"),\n        )\n    else:\n        return NormalizedBuzzsumoResult(\n            url=url,\n            work_type=cls.parse_buzzsumo_type(data),\n            domain=None,\n            twitter_share=None,\n            facebook_share=None,\n            title=None,\n            date_published=None,\n            pinterest_share=None,\n            creator_name=None,\n            creator_identifier=None,\n            duration=None,\n            facebook_comment=None,\n            youtube_watch=None,\n            youtube_like=None,\n            youtube_comment=None,\n            tiktok_share=None,\n            tiktok_comment=None,\n            reddit_engagement=None,\n        )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.normalizer.NormalizedBuzzsumoResult.parse_buzzsumo_type","title":"<code>parse_buzzsumo_type(data)</code>  <code>classmethod</code>","text":"<p>Helper function for transforming Buzzsumo's content classification into Schema.org subtype.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>BuzzsumoArticle | None</code> <p>If target URL was found in Buzzsumo database, minet's result; otherwise, None.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Schema for web content's subtype.</p> Source code in <code>minall/enrichment/buzzsumo/normalizer.py</code> <pre><code>@classmethod\ndef parse_buzzsumo_type(cls, data: BuzzsumoArticle | None) -&gt; str:\n    \"\"\"Helper function for transforming Buzzsumo's content classification into Schema.org subtype.\n\n    Args:\n        data (BuzzsumoArticle | None): If target URL was found in Buzzsumo database, minet's result; otherwise, None.\n\n    Returns:\n        str: Schema for web content's subtype.\n    \"\"\"\n    video_types = [\"is_video\"]\n    article_types = [\n        \"is_general_article\",\n        \"is_how_to_article\",\n        \"is_infographic\",\n        \"is_interview\",\n        \"is_list\",\n        \"is_newsletter\",\n        \"is_press_release\",\n        \"is_review\",\n        \"is_what_post\",\n        \"is_why_post\",\n    ]\n    work_type = \"WebPage\"\n    if data:\n        for t in video_types:\n            if getattr(data, t):\n                return \"VideoObject\"\n        for t in article_types:\n            if getattr(data, t):\n                return \"Article\"\n    return work_type\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.client","title":"<code>minall.enrichment.buzzsumo.client</code>","text":"<p>Module containing a wrapper for minet's Buzzsumo API client.</p>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.client.BuzzsumoClient","title":"<code>BuzzsumoClient</code>","text":"<p>Wrapper for minet's Buzzsumo API client.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; wrapper = BuzzsumoClient(token=os.environ[\"BUZZSUMO_TOKEN\"])\n&gt;&gt;&gt; url=\"https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/\"\n&gt;&gt;&gt; wrapper(url)\nNormalizedBuzzsumoResult(url='https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/', work_type='Article', domain='fosdem.org', twitter_share=0, facebook_share=0, title='FOSDEM 2020 - Empowering social scientists with web mining tools', date_published=datetime.datetime(2024, 1, 4, 15, 48, 1), pinterest_share=0, creator_name=None, creator_identifier=None, duration=None, facebook_comment=0, youtube_watch=None, youtube_like=None, youtube_comment=None, tiktok_share=None, tiktok_comment=None, reddit_engagement=0)\n</code></pre> Source code in <code>minall/enrichment/buzzsumo/client.py</code> <pre><code>class BuzzsumoClient:\n    \"\"\"Wrapper for minet's Buzzsumo API client.\n\n    Examples:\n        &gt;&gt;&gt; import os\n        &gt;&gt;&gt; wrapper = BuzzsumoClient(token=os.environ[\"BUZZSUMO_TOKEN\"])\n        &gt;&gt;&gt; url=\"https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/\"\n        &gt;&gt;&gt; wrapper(url)\n        NormalizedBuzzsumoResult(url='https://archive.fosdem.org/2020/schedule/event/open_research_web_mining/', work_type='Article', domain='fosdem.org', twitter_share=0, facebook_share=0, title='FOSDEM 2020 - Empowering social scientists with web mining tools', date_published=datetime.datetime(2024, 1, 4, 15, 48, 1), pinterest_share=0, creator_name=None, creator_identifier=None, duration=None, facebook_comment=0, youtube_watch=None, youtube_like=None, youtube_comment=None, tiktok_share=None, tiktok_comment=None, reddit_engagement=0)\n    \"\"\"\n\n    def __init__(self, token: str) -&gt; None:\n        \"\"\"Creates an instance of mient's BuzzsumoAPIClient and sets values for the Buzzsumo API's requried begin-date and end-date parameters.\n\n        Examples:\n            &gt;&gt;&gt; wrapper = BuzzsumoClient(token=\"&lt;TOKEN&gt;\")\n            &gt;&gt;&gt; type(wrapper)\n            &lt;class 'minall.enrichment.buzzsumo.client.BuzzsumoClient'&gt;\n            &gt;&gt;&gt; type(wrapper.client)\n            &lt;class 'minet.buzzsumo.client.BuzzSumoAPIClient'&gt;\n\n        Args:\n            token (str): Buzzsumo API token.\n        \"\"\"\n        self.client = BuzzSumoAPIClient(token=token)\n        self.begin = BEGINDATE\n        self.end = ENDDATE\n\n    def __call__(self, url: str) -&gt; NormalizedBuzzsumoResult:\n        \"\"\"Executes mient's Buzzsumo API client on a URL and returns normalized data.\n\n        Args:\n            url (str): Target URL.\n\n        Returns:\n            NormalizedBuzzsumoResult: Dataclass that normalizes minet's Buzzsumo result.\n        \"\"\"\n        result = self.client.exact_url(\n            search_url=url, begin_timestamp=self.begin, end_timestamp=self.end\n        )\n        return NormalizedBuzzsumoResult.from_payload(url, result)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.client.BuzzsumoClient.__call__","title":"<code>__call__(url)</code>","text":"<p>Executes mient's Buzzsumo API client on a URL and returns normalized data.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target URL.</p> required <p>Returns:</p> Name Type Description <code>NormalizedBuzzsumoResult</code> <code>NormalizedBuzzsumoResult</code> <p>Dataclass that normalizes minet's Buzzsumo result.</p> Source code in <code>minall/enrichment/buzzsumo/client.py</code> <pre><code>def __call__(self, url: str) -&gt; NormalizedBuzzsumoResult:\n    \"\"\"Executes mient's Buzzsumo API client on a URL and returns normalized data.\n\n    Args:\n        url (str): Target URL.\n\n    Returns:\n        NormalizedBuzzsumoResult: Dataclass that normalizes minet's Buzzsumo result.\n    \"\"\"\n    result = self.client.exact_url(\n        search_url=url, begin_timestamp=self.begin, end_timestamp=self.end\n    )\n    return NormalizedBuzzsumoResult.from_payload(url, result)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.client.BuzzsumoClient.__init__","title":"<code>__init__(token)</code>","text":"<p>Creates an instance of mient's BuzzsumoAPIClient and sets values for the Buzzsumo API's requried begin-date and end-date parameters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wrapper = BuzzsumoClient(token=\"&lt;TOKEN&gt;\")\n&gt;&gt;&gt; type(wrapper)\n&lt;class 'minall.enrichment.buzzsumo.client.BuzzsumoClient'&gt;\n&gt;&gt;&gt; type(wrapper.client)\n&lt;class 'minet.buzzsumo.client.BuzzSumoAPIClient'&gt;\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>Buzzsumo API token.</p> required Source code in <code>minall/enrichment/buzzsumo/client.py</code> <pre><code>def __init__(self, token: str) -&gt; None:\n    \"\"\"Creates an instance of mient's BuzzsumoAPIClient and sets values for the Buzzsumo API's requried begin-date and end-date parameters.\n\n    Examples:\n        &gt;&gt;&gt; wrapper = BuzzsumoClient(token=\"&lt;TOKEN&gt;\")\n        &gt;&gt;&gt; type(wrapper)\n        &lt;class 'minall.enrichment.buzzsumo.client.BuzzsumoClient'&gt;\n        &gt;&gt;&gt; type(wrapper.client)\n        &lt;class 'minet.buzzsumo.client.BuzzSumoAPIClient'&gt;\n\n    Args:\n        token (str): Buzzsumo API token.\n    \"\"\"\n    self.client = BuzzSumoAPIClient(token=token)\n    self.begin = BEGINDATE\n    self.end = ENDDATE\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.get_data","title":"<code>minall.enrichment.buzzsumo.get_data</code>","text":"<p>Module containing a function that runs all of the Buzzsumo enrichment process.</p>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.get_data.get_buzzsumo_data","title":"<code>get_buzzsumo_data(data, token, outfile)</code>","text":"<p>Main function for writing Buzzsumo API results to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[str]</code> <p>List of URLs.</p> required <code>token</code> <code>str</code> <p>Token for Buzzsumo API.</p> required <code>outfile</code> <code>Path</code> <p>Path to CSV file in which to write results.</p> required Source code in <code>minall/enrichment/buzzsumo/get_data.py</code> <pre><code>def get_buzzsumo_data(data: List[str], token: str, outfile: Path):\n    \"\"\"Main function for writing Buzzsumo API results to a CSV file.\n\n    Args:\n        data (List[str]): List of URLs.\n        token (str): Token for Buzzsumo API.\n        outfile (Path): Path to CSV file in which to write results.\n    \"\"\"\n    with WriterContext(links_file=outfile) as writer:\n        # Save results to memory, trigger Global Interpreter Lock (GIL)\n        for result in yield_buzzsumo_data(token, data):\n            writer.writerow(result.as_csv_dict_row())\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.contexts","title":"<code>minall.enrichment.buzzsumo.contexts</code>","text":"<p>Module containing contexts for Buzzsumo data collection's CSV writer, progress bar, and multi-threader.</p>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.contexts.GeneratorContext","title":"<code>GeneratorContext</code>","text":"Source code in <code>minall/enrichment/buzzsumo/contexts.py</code> <pre><code>class GeneratorContext:\n    def __init__(self) -&gt; None:\n        \"\"\"Set up class for Buzzsumo client wrapper's contexts.\"\"\"\n        pass\n\n    def __enter__(self) -&gt; Tuple[Progress, ThreadPoolExecutor]:\n        \"\"\"Start the wrapper's context variables.\n\n        Returns:\n            Tuple[Progress, ThreadPoolExecutor]: Context variables.\n        \"\"\"\n        self.progress_bar = Progress(\n            TextColumn(\"[progress.description]{task.description}\"),\n            SpinnerColumn(),\n            MofNCompleteColumn(),\n            TimeElapsedColumn(),\n        )\n        self.progress_bar.start()\n\n        self.executor = ThreadPoolExecutor()\n\n        return self.progress_bar, self.executor\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Stop the Buzzsumo client wrapper's context variables.\"\"\"\n        self.progress_bar.stop()\n        self.executor.shutdown(wait=False, cancel_futures=True)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.contexts.GeneratorContext.__enter__","title":"<code>__enter__()</code>","text":"<p>Start the wrapper's context variables.</p> <p>Returns:</p> Type Description <code>Tuple[Progress, ThreadPoolExecutor]</code> <p>Tuple[Progress, ThreadPoolExecutor]: Context variables.</p> Source code in <code>minall/enrichment/buzzsumo/contexts.py</code> <pre><code>def __enter__(self) -&gt; Tuple[Progress, ThreadPoolExecutor]:\n    \"\"\"Start the wrapper's context variables.\n\n    Returns:\n        Tuple[Progress, ThreadPoolExecutor]: Context variables.\n    \"\"\"\n    self.progress_bar = Progress(\n        TextColumn(\"[progress.description]{task.description}\"),\n        SpinnerColumn(),\n        MofNCompleteColumn(),\n        TimeElapsedColumn(),\n    )\n    self.progress_bar.start()\n\n    self.executor = ThreadPoolExecutor()\n\n    return self.progress_bar, self.executor\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.contexts.GeneratorContext.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Stop the Buzzsumo client wrapper's context variables.</p> Source code in <code>minall/enrichment/buzzsumo/contexts.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Stop the Buzzsumo client wrapper's context variables.\"\"\"\n    self.progress_bar.stop()\n    self.executor.shutdown(wait=False, cancel_futures=True)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.contexts.GeneratorContext.__init__","title":"<code>__init__()</code>","text":"<p>Set up class for Buzzsumo client wrapper's contexts.</p> Source code in <code>minall/enrichment/buzzsumo/contexts.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Set up class for Buzzsumo client wrapper's contexts.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.contexts.WriterContext","title":"<code>WriterContext</code>","text":"Source code in <code>minall/enrichment/buzzsumo/contexts.py</code> <pre><code>class WriterContext:\n    def __init__(self, links_file: Path):\n        \"\"\"Set up class for iteratively writing normalized Buzzsumo results to CSV.\n\n        Args:\n            links_file (Path): Path to the links table CSV file.\n        \"\"\"\n        self.links_file = links_file\n\n    def __enter__(self) -&gt; csv.DictWriter:\n        \"\"\"Start the CSV writer's context.\n\n        Returns:\n            csv.DictWriter: Context variable for writing CSV rows.\n        \"\"\"\n        # Set up links file writer\n        self.links_file_obj = open(self.links_file, mode=\"w\")\n        self.links_file_writer = csv.DictWriter(\n            self.links_file_obj, fieldnames=LinksConstants.col_names\n        )\n        self.links_file_writer.writeheader()\n\n        return self.links_file_writer\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Stops the writer's context variable.\"\"\"\n        if self.links_file_obj:\n            self.links_file_obj.close()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.contexts.WriterContext.__enter__","title":"<code>__enter__()</code>","text":"<p>Start the CSV writer's context.</p> <p>Returns:</p> Type Description <code>DictWriter</code> <p>csv.DictWriter: Context variable for writing CSV rows.</p> Source code in <code>minall/enrichment/buzzsumo/contexts.py</code> <pre><code>def __enter__(self) -&gt; csv.DictWriter:\n    \"\"\"Start the CSV writer's context.\n\n    Returns:\n        csv.DictWriter: Context variable for writing CSV rows.\n    \"\"\"\n    # Set up links file writer\n    self.links_file_obj = open(self.links_file, mode=\"w\")\n    self.links_file_writer = csv.DictWriter(\n        self.links_file_obj, fieldnames=LinksConstants.col_names\n    )\n    self.links_file_writer.writeheader()\n\n    return self.links_file_writer\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.contexts.WriterContext.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Stops the writer's context variable.</p> Source code in <code>minall/enrichment/buzzsumo/contexts.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Stops the writer's context variable.\"\"\"\n    if self.links_file_obj:\n        self.links_file_obj.close()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.buzzsumo.contexts.WriterContext.__init__","title":"<code>__init__(links_file)</code>","text":"<p>Set up class for iteratively writing normalized Buzzsumo results to CSV.</p> <p>Parameters:</p> Name Type Description Default <code>links_file</code> <code>Path</code> <p>Path to the links table CSV file.</p> required Source code in <code>minall/enrichment/buzzsumo/contexts.py</code> <pre><code>def __init__(self, links_file: Path):\n    \"\"\"Set up class for iteratively writing normalized Buzzsumo results to CSV.\n\n    Args:\n        links_file (Path): Path to the links table CSV file.\n    \"\"\"\n    self.links_file = links_file\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle","title":"<code>minall.enrichment.crowdtangle</code>","text":"<p>Enrichment workflow's CrowdTangle data collection.</p> <p>Modules exported by this package:</p> <ul> <li><code>normalizer</code>: Dataclass to normlalize minet's CrowdTangle result object.</li> <li><code>contexts</code>: Context manager for client's CSV writers, multi-threader, and progress bar.</li> <li><code>get_data</code>: Function that runs all of the CrowdTangle enrichment process.</li> <li><code>client</code>: Wrapper for minet's CrowdTangle API client that normalizes minet's result.</li> <li><code>exceptions</code>:</li> </ul>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.normalizer","title":"<code>minall.enrichment.crowdtangle.normalizer</code>","text":"<p>Module contains functions and dataclasses to normalize minet's CrowdTangle API client result.</p>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.normalizer.NormalizedFacebookPost","title":"<code>NormalizedFacebookPost</code>  <code>dataclass</code>","text":"<p>             Bases: <code>TabularRecord</code></p> <p>Dataclass to normalize minet's CrowdTangle API result for Facebook posts.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>Target Facebook URL.</p> <code>work_type</code> <code>str</code> <p>Target Facebook content's ontological subtype, i.e. \"SocialMediaPosting\", \"ImageObject\", \"VideoObject\".</p> <code>duration</code> <code>str</code> <p>If a Facebook content is a video, the video's duration.</p> <code>identifier</code> <code>str</code> <p>Facebook's identifier for the post.</p> <code>date_published</code> <code>str</code> <p>Date of teh Facebook post's publication.</p> <code>date_modified</code> <code>str</code> <p>Date when the Facebook post was last modified.</p> <code>title</code> <code>str</code> <p>If applicable, title of the Facebook post content.</p> <code>abstract</code> <code>str</code> <p>If applicable, description of the Facebook post content.</p> <code>text</code> <code>str</code> <p>If applicable, text of Facebook post content.</p> <code>creator_identifier</code> <code>str</code> <p>Facebook's identifier for the post's creator.</p> <code>creator_name</code> <code>str</code> <p>Name of entity responsible for the Facebook post publication.</p> <code>creator_location_created</code> <code>str</code> <p>If available, principal country in which is located the entity responsible for the post's publication.</p> <code>creator_url</code> <code>str</code> <p>URL for the entity responsible for the Facebook post's publication.</p> <code>creator_facebook_subscribe</code> <code>int</code> <p>Number of Facebook accounts subscribed to the account of the entity responsible for the Facebook post's publication.</p> <code>facebook_comment</code> <code>int</code> <p>Number of comments on the Facebook post.</p> <code>facebook_like</code> <code>int</code> <p>Number of Facebook accounts that have liked the Facebook post.</p> <code>facebook_share</code> <code>int</code> <p>Number of times the Facebook post has been shared on Facebook.</p> <code>domain</code> <code>str</code> <p>Domain for the Facebook post's URL. Default = \"facebook.com\".</p> <code>creator_type</code> <code>str</code> <p>Ontological subtype for the Facebook post's creator. Default = \"defacto:SocialMediaAccount\".</p> Source code in <code>minall/enrichment/crowdtangle/normalizer.py</code> <pre><code>@dataclass\nclass NormalizedFacebookPost(TabularRecord):\n    \"\"\"Dataclass to normalize minet's CrowdTangle API result for Facebook posts.\n\n    Attributes:\n        url (str): Target Facebook URL.\n        work_type (str): Target Facebook content's ontological subtype, i.e. \"SocialMediaPosting\", \"ImageObject\", \"VideoObject\".\n        duration (str): If a Facebook content is a video, the video's duration.\n        identifier (str): Facebook's identifier for the post.\n        date_published (str): Date of teh Facebook post's publication.\n        date_modified (str): Date when the Facebook post was last modified.\n        title (str): If applicable, title of the Facebook post content.\n        abstract (str): If applicable, description of the Facebook post content.\n        text (str): If applicable, text of Facebook post content.\n        creator_identifier (str): Facebook's identifier for the post's creator.\n        creator_name (str): Name of entity responsible for the Facebook post publication.\n        creator_location_created (str): If available, principal country in which is located the entity responsible for the post's publication.\n        creator_url (str): URL for the entity responsible for the Facebook post's publication.\n        creator_facebook_subscribe (int): Number of Facebook accounts subscribed to the account of the entity responsible for the Facebook post's publication.\n        facebook_comment (int): Number of comments on the Facebook post.\n        facebook_like (int): Number of Facebook accounts that have liked the Facebook post.\n        facebook_share (int): Number of times the Facebook post has been shared on Facebook.\n        domain (str): Domain for the Facebook post's URL. Default = \"facebook.com\".\n        creator_type (str): Ontological subtype for the Facebook post's creator. Default = \"defacto:SocialMediaAccount\".\n    \"\"\"\n\n    url: str\n    work_type: str\n    duration: str\n    identifier: str\n    date_published: str\n    date_modified: str\n    title: Optional[str]\n    abstract: Optional[str]\n    text: Optional[str]\n    creator_identifier: str\n    creator_name: str\n    creator_location_created: Optional[str]\n    creator_url: str\n    creator_facebook_subscribe: int\n    facebook_comment: int\n    facebook_like: int\n    facebook_share: int\n    domain: str = \"facebook.com\"\n    creator_type: str = \"defacto:SocialMediaAccount\"\n\n    @classmethod\n    def from_payload(\n        cls,\n        url: str,\n        result: CrowdTanglePost,\n    ) -&gt; \"NormalizedFacebookPost\":\n        \"\"\"Parses minet's CrowdTangle result and creates normalized dataclass.\n\n        Args:\n            url (str): Target Facebook URL.\n            result (CrowdTanglePost): Result object returned from minet's CrowdTangle API client.\n\n        Returns:\n            NormalizedFacebookPost: Dataclass that normalizes minet's CrowdTangle data.\n        \"\"\"\n        work_type = \"SocialMediaPosting\"\n        if hasattr(result, \"type\"):\n            if result.type == \"photo\":\n                work_type = \"ImageObject\"\n            elif result.type == \"video\":\n                work_type = \"VideoObject\"\n\n        return NormalizedFacebookPost(\n            url=url,\n            work_type=work_type,\n            duration=result.video_length_ms,\n            identifier=result.id,\n            date_published=result.date,\n            date_modified=result.updated,\n            title=result.title,\n            abstract=result.description,\n            text=result.message,\n            creator_identifier=result.account.id,\n            creator_facebook_subscribe=result.account.subscriber_count,\n            creator_name=result.account.name,\n            creator_location_created=result.account.page_admin_top_country,\n            creator_url=result.account.url,\n            facebook_comment=result.actual_comment_count,\n            facebook_like=result.actual_like_count,\n            facebook_share=result.actual_share_count,\n        )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.normalizer.NormalizedFacebookPost.from_payload","title":"<code>from_payload(url, result)</code>  <code>classmethod</code>","text":"<p>Parses minet's CrowdTangle result and creates normalized dataclass.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target Facebook URL.</p> required <code>result</code> <code>CrowdTanglePost</code> <p>Result object returned from minet's CrowdTangle API client.</p> required <p>Returns:</p> Name Type Description <code>NormalizedFacebookPost</code> <code>NormalizedFacebookPost</code> <p>Dataclass that normalizes minet's CrowdTangle data.</p> Source code in <code>minall/enrichment/crowdtangle/normalizer.py</code> <pre><code>@classmethod\ndef from_payload(\n    cls,\n    url: str,\n    result: CrowdTanglePost,\n) -&gt; \"NormalizedFacebookPost\":\n    \"\"\"Parses minet's CrowdTangle result and creates normalized dataclass.\n\n    Args:\n        url (str): Target Facebook URL.\n        result (CrowdTanglePost): Result object returned from minet's CrowdTangle API client.\n\n    Returns:\n        NormalizedFacebookPost: Dataclass that normalizes minet's CrowdTangle data.\n    \"\"\"\n    work_type = \"SocialMediaPosting\"\n    if hasattr(result, \"type\"):\n        if result.type == \"photo\":\n            work_type = \"ImageObject\"\n        elif result.type == \"video\":\n            work_type = \"VideoObject\"\n\n    return NormalizedFacebookPost(\n        url=url,\n        work_type=work_type,\n        duration=result.video_length_ms,\n        identifier=result.id,\n        date_published=result.date,\n        date_modified=result.updated,\n        title=result.title,\n        abstract=result.description,\n        text=result.message,\n        creator_identifier=result.account.id,\n        creator_facebook_subscribe=result.account.subscriber_count,\n        creator_name=result.account.name,\n        creator_location_created=result.account.page_admin_top_country,\n        creator_url=result.account.url,\n        facebook_comment=result.actual_comment_count,\n        facebook_like=result.actual_like_count,\n        facebook_share=result.actual_share_count,\n    )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.normalizer.NormalizedSharedContent","title":"<code>NormalizedSharedContent</code>  <code>dataclass</code>","text":"<p>             Bases: <code>TabularRecord</code></p> <p>Dataclass for normalizing data about media content shared in a Facebook post.</p> <p>Attributes:</p> Name Type Description <code>post_url</code> <code>str</code> <p>Target Facebook URL, which shared the media content.</p> <code>content_url</code> <code>str</code> <p>CrowdTangle's URI for the shared media.</p> <code>media_type</code> <code>str</code> <p>Ontological subtype for the shared media, i.e. \"ImageObject\".</p> <code>height</code> <code>int | None</code> <p>If available, the height in pixels of the shared media.</p> <code>width</code> <code>int | None</code> <p>If available, the width in pixels of the shared media.</p> Source code in <code>minall/enrichment/crowdtangle/normalizer.py</code> <pre><code>@dataclass\nclass NormalizedSharedContent(TabularRecord):\n    \"\"\"Dataclass for normalizing data about media content shared in a Facebook post.\n\n    Attributes:\n        post_url (str): Target Facebook URL, which shared the media content.\n        content_url (str): CrowdTangle's URI for the shared media.\n        media_type (str): Ontological subtype for the shared media, i.e. \"ImageObject\".\n        height (int | None): If available, the height in pixels of the shared media.\n        width (int | None): If available, the width in pixels of the shared media.\n    \"\"\"\n\n    post_url: str\n    content_url: str | None\n    media_type: str\n    height: int | None\n    width: int | None\n\n    @classmethod\n    def parse_media_type(cls, type: str | None) -&gt; str:\n        \"\"\"Helper function to transform CrowdTangle's media classification into Schema.org's CreativeWork subtype.\n\n        Args:\n            type (str | None): If available, CrowdTangle's classification of the media object.\n\n        Returns:\n            str: Schema.org's CreativeWork subtype.\n        \"\"\"\n        if type == \"photo\":\n            return \"ImageObject\"\n        elif type == \"video\":\n            return \"VideoObject\"\n        else:\n            return \"MediaObject\"\n\n    @classmethod\n    def from_payload(\n        cls,\n        url: str,\n        media: dict,\n    ) -&gt; \"NormalizedSharedContent\":\n        \"\"\"Parses JSON data in CrowdTanglePost's \"media\" attribute.\n\n        Args:\n            url (str): URL of Facebook post that contains shared media.\n            media (dict): JSON in CrowdTanglePost's \"media\" attribute.\n\n        Returns:\n            NormalizedSharedContent: Dataclass that normalizes information about Facebook post's shared media content.\n        \"\"\"\n        return NormalizedSharedContent(\n            post_url=url,\n            content_url=media.get(\"url\"),\n            media_type=cls.parse_media_type(media.get(\"type\")),\n            height=media.get(\"height\"),\n            width=media.get(\"width\"),\n        )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.normalizer.NormalizedSharedContent.from_payload","title":"<code>from_payload(url, media)</code>  <code>classmethod</code>","text":"<p>Parses JSON data in CrowdTanglePost's \"media\" attribute.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL of Facebook post that contains shared media.</p> required <code>media</code> <code>dict</code> <p>JSON in CrowdTanglePost's \"media\" attribute.</p> required <p>Returns:</p> Name Type Description <code>NormalizedSharedContent</code> <code>NormalizedSharedContent</code> <p>Dataclass that normalizes information about Facebook post's shared media content.</p> Source code in <code>minall/enrichment/crowdtangle/normalizer.py</code> <pre><code>@classmethod\ndef from_payload(\n    cls,\n    url: str,\n    media: dict,\n) -&gt; \"NormalizedSharedContent\":\n    \"\"\"Parses JSON data in CrowdTanglePost's \"media\" attribute.\n\n    Args:\n        url (str): URL of Facebook post that contains shared media.\n        media (dict): JSON in CrowdTanglePost's \"media\" attribute.\n\n    Returns:\n        NormalizedSharedContent: Dataclass that normalizes information about Facebook post's shared media content.\n    \"\"\"\n    return NormalizedSharedContent(\n        post_url=url,\n        content_url=media.get(\"url\"),\n        media_type=cls.parse_media_type(media.get(\"type\")),\n        height=media.get(\"height\"),\n        width=media.get(\"width\"),\n    )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.normalizer.NormalizedSharedContent.parse_media_type","title":"<code>parse_media_type(type)</code>  <code>classmethod</code>","text":"<p>Helper function to transform CrowdTangle's media classification into Schema.org's CreativeWork subtype.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str | None</code> <p>If available, CrowdTangle's classification of the media object.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Schema.org's CreativeWork subtype.</p> Source code in <code>minall/enrichment/crowdtangle/normalizer.py</code> <pre><code>@classmethod\ndef parse_media_type(cls, type: str | None) -&gt; str:\n    \"\"\"Helper function to transform CrowdTangle's media classification into Schema.org's CreativeWork subtype.\n\n    Args:\n        type (str | None): If available, CrowdTangle's classification of the media object.\n\n    Returns:\n        str: Schema.org's CreativeWork subtype.\n    \"\"\"\n    if type == \"photo\":\n        return \"ImageObject\"\n    elif type == \"video\":\n        return \"VideoObject\"\n    else:\n        return \"MediaObject\"\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.normalizer.parse_facebook_post","title":"<code>parse_facebook_post(url, result)</code>","text":"<p>Transform minet's CrowdTanglePost object into normalized data as CSV dict row.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target Facebook URL.</p> required <code>result</code> <code>CrowdTanglePost | None</code> <p>If CrowdTangle API returned a match, minet's CrowdTangle API result object.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>Normalized data for Facebook post.</p> Source code in <code>minall/enrichment/crowdtangle/normalizer.py</code> <pre><code>def parse_facebook_post(url: str, result: CrowdTanglePost | None) -&gt; Dict:\n    \"\"\"Transform minet's CrowdTanglePost object into normalized data as CSV dict row.\n\n    Args:\n        url (str): Target Facebook URL.\n        result (CrowdTanglePost | None): If CrowdTangle API returned a match, minet's CrowdTangle API result object.\n\n    Returns:\n        Dict: Normalized data for Facebook post.\n    \"\"\"\n    if result:\n        formatted_result = NormalizedFacebookPost.from_payload(url, result)\n        return formatted_result.as_csv_dict_row()\n    else:\n        return {\"url\": url, \"domain\": \"facebook.com\", \"work_type\": \"SocialMediaPosting\"}\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.normalizer.parse_shared_content","title":"<code>parse_shared_content(url, result)</code>","text":"<p>Generator that streams the \"media\" attribute from minet's CrowdTanglePost object and returns normalized data as CSV dict row.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target Facebook URL.</p> required <code>result</code> <code>CrowdTanglePost</code> <p>minet's CrowdTangle API client result object.</p> required <p>Yields:</p> Type Description <code>Dict</code> <p>Generator[Dict, None, None]: Formatted CSV dict row of normalized shared content data.</p> Source code in <code>minall/enrichment/crowdtangle/normalizer.py</code> <pre><code>def parse_shared_content(\n    url: str, result: CrowdTanglePost\n) -&gt; Generator[Dict, None, None]:\n    \"\"\"Generator that streams the \"media\" attribute from minet's CrowdTanglePost object and returns normalized data as CSV dict row.\n\n    Args:\n        url (str): Target Facebook URL.\n        result (CrowdTanglePost): minet's CrowdTangle API client result object.\n\n    Yields:\n        Generator[Dict, None, None]: Formatted CSV dict row of normalized shared content data.\n    \"\"\"\n    if result and isinstance(getattr(result, \"media\"), list):\n        for media in result.media:\n            formatted_result = NormalizedSharedContent.from_payload(\n                url=url, media=media\n            )\n            yield formatted_result.as_csv_dict_row()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.client","title":"<code>minall.enrichment.crowdtangle.client</code>","text":"<p>Module contains a client and helper functions for collecting data from CrowdTangle.</p>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.client.CTClient","title":"<code>CTClient</code>","text":"<p>Wrapper for minet's CrowdTangle API client with helper function for parsing Facebook post ID.</p> Source code in <code>minall/enrichment/crowdtangle/client.py</code> <pre><code>class CTClient:\n    \"\"\"Wrapper for minet's CrowdTangle API client with helper function for parsing Facebook post ID.\"\"\"\n\n    def __init__(self, token: str, rate_limit: int) -&gt; None:\n        \"\"\"Create instance of minet's CrowdTangle API client.\n\n        Args:\n            token (str): CrowdTangle API token.\n            rate_limit (int): CrowdTangle API rate limit.\n        \"\"\"\n        self.client = CrowdTangleAPIClient(token=token, rate_limit=rate_limit)\n\n    def __call__(self, url: str) -&gt; Tuple[str, CrowdTanglePost | None]:\n        \"\"\"Execute collection of CrowdTangle data from parsed Facebook post ID.\n\n        Args:\n            url (str): Target Facebook URL.\n\n        Returns:\n            Tuple[str, CrowdTanglePost | None]: Target URL and, if successful, minet's CrowdTanglePost result object.\n        \"\"\"\n        post_id = adhoc_post_id_parser(url)\n        post = None\n        if post_id:\n            try:\n                post = self.client.post(post_id=post_id)\n            except Exception as e:\n                logging.exception(e)\n        return url, post\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.client.CTClient.__call__","title":"<code>__call__(url)</code>","text":"<p>Execute collection of CrowdTangle data from parsed Facebook post ID.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target Facebook URL.</p> required <p>Returns:</p> Type Description <code>Tuple[str, CrowdTanglePost | None]</code> <p>Tuple[str, CrowdTanglePost | None]: Target URL and, if successful, minet's CrowdTanglePost result object.</p> Source code in <code>minall/enrichment/crowdtangle/client.py</code> <pre><code>def __call__(self, url: str) -&gt; Tuple[str, CrowdTanglePost | None]:\n    \"\"\"Execute collection of CrowdTangle data from parsed Facebook post ID.\n\n    Args:\n        url (str): Target Facebook URL.\n\n    Returns:\n        Tuple[str, CrowdTanglePost | None]: Target URL and, if successful, minet's CrowdTanglePost result object.\n    \"\"\"\n    post_id = adhoc_post_id_parser(url)\n    post = None\n    if post_id:\n        try:\n            post = self.client.post(post_id=post_id)\n        except Exception as e:\n            logging.exception(e)\n    return url, post\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.client.CTClient.__init__","title":"<code>__init__(token, rate_limit)</code>","text":"<p>Create instance of minet's CrowdTangle API client.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str</code> <p>CrowdTangle API token.</p> required <code>rate_limit</code> <code>int</code> <p>CrowdTangle API rate limit.</p> required Source code in <code>minall/enrichment/crowdtangle/client.py</code> <pre><code>def __init__(self, token: str, rate_limit: int) -&gt; None:\n    \"\"\"Create instance of minet's CrowdTangle API client.\n\n    Args:\n        token (str): CrowdTangle API token.\n        rate_limit (int): CrowdTangle API rate limit.\n    \"\"\"\n    self.client = CrowdTangleAPIClient(token=token, rate_limit=rate_limit)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.client.adhoc_post_id_parser","title":"<code>adhoc_post_id_parser(url)</code>","text":"<p>Helper function to catch and fix problems parsing Facebook post ID.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target Facebook URL.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: If successful, post ID for target Facebook URL.</p> Source code in <code>minall/enrichment/crowdtangle/client.py</code> <pre><code>def adhoc_post_id_parser(url: str) -&gt; str | None:\n    \"\"\"Helper function to catch and fix problems parsing Facebook post ID.\n\n    Args:\n        url (str): Target Facebook URL.\n\n    Returns:\n        str | None: If successful, post ID for target Facebook URL.\n    \"\"\"\n    post_id = post_id_from_url(url)\n    if post_id:\n        return post_id\n    else:\n        parsed_url = parse_facebook_url(url)\n        if parsed_url:\n            if hasattr(parsed_url, \"id\"):\n                post_id = getattr(parsed_url, \"id\")\n            else:\n                return\n            if hasattr(parsed_url, \"parent_handle\"):\n                parent_id = getattr(parsed_url, \"parent_handle\")\n            elif hasattr(parsed_url, \"parent_id\"):\n                parent_id = getattr(parsed_url, \"parent_id\")\n            else:\n                return\n            if post_id and parent_id:\n                try:\n                    int(post_id)\n                except Exception:\n                    return\n                try:\n                    int(parent_id)\n                except Exception:\n                    return\n                return post_id + \"_\" + parent_id\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.client.parse_rate_limit","title":"<code>parse_rate_limit(rate_limit)</code>","text":"<p>Set default or convert rate limit string to integer.</p> <p>Parameters:</p> Name Type Description Default <code>rate_limit</code> <code>int | str | None</code> <p>Value of rate limit for CrowdTangle API.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Converted rate limit integer for CrowdTangle API.</p> Source code in <code>minall/enrichment/crowdtangle/client.py</code> <pre><code>def parse_rate_limit(rate_limit: int | str | None) -&gt; int:\n    \"\"\"Set default or convert rate limit string to integer.\n\n    Args:\n        rate_limit (int | str | None): Value of rate limit for CrowdTangle API.\n\n    Returns:\n        int: Converted rate limit integer for CrowdTangle API.\n    \"\"\"\n    if not rate_limit:\n        rate_limit = 10\n    elif isinstance(rate_limit, str):\n        rate_limit = int(rate_limit)\n    return rate_limit\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.get_data","title":"<code>minall.enrichment.crowdtangle.get_data</code>","text":"<p>Module contains functions for collecting, normalizing, and writing data from CrowdTangle.</p>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.get_data.get_facebook_post_data","title":"<code>get_facebook_post_data(data, token, rate_limit, links_outfile, shared_content_outfile)</code>","text":"<p>Function to collect, normalize, and write data from CrowdTangle.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[str]</code> <p>Set of target Facebook URLs.</p> required <code>token</code> <code>str</code> <p>CrowdTangle API token.</p> required <code>rate_limit</code> <code>int | str | None</code> <p>CrowdTangle API rate limit.</p> required <code>links_outfile</code> <code>Path</code> <p>Path to CSV file for Facebook post metadata.</p> required <code>shared_content_outfile</code> <code>Path</code> <p>Path to CSV for shared content metadata.</p> required Source code in <code>minall/enrichment/crowdtangle/get_data.py</code> <pre><code>def get_facebook_post_data(\n    data: List[str],\n    token: str,\n    rate_limit: int | str | None,\n    links_outfile: Path,\n    shared_content_outfile: Path,\n):\n    \"\"\"Function to collect, normalize, and write data from CrowdTangle.\n\n    Args:\n        data (List[str]): Set of target Facebook URLs.\n        token (str): CrowdTangle API token.\n        rate_limit (int | str | None): CrowdTangle API rate limit.\n        links_outfile (Path): Path to CSV file for Facebook post metadata.\n        shared_content_outfile (Path): Path to CSV for shared content metadata.\n    \"\"\"\n\n    rate_limit = parse_rate_limit(rate_limit)\n\n    with ContextManager(links_outfile, shared_content_outfile) as contexts:\n        links_writer, shared_content_writer, progress = contexts\n\n        t = progress.add_task(\n            description=\"[bold blue]Querying Facebook posts\", total=len(data)\n        )\n        for url, response in yield_facebook_data(\n            data=data, token=token, rate_limit=rate_limit\n        ):\n            progress.advance(t)\n            formatted_post = parse_facebook_post(url=url, result=response)\n            links_writer.writerow(formatted_post)\n            for formatted_media in parse_shared_content(url=url, result=response):\n                shared_content_writer.writerow(formatted_media)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.get_data.yield_facebook_data","title":"<code>yield_facebook_data(data, token, rate_limit)</code>","text":"<p>Streams target Facebook URLs to multi-threading context and yields minet's results.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[str]</code> <p>Set of target Facebook URLs.</p> required <code>token</code> <code>str</code> <p>CrowdTangle API token.</p> required <code>rate_limit</code> <code>int</code> <p>CrowdTangle API rate limit.</p> required <p>Yields:</p> Type Description <code>str</code> <p>Generator[Tuple[str, CrowdTanglePost | None], None, None]: Target Facebook URL and, if available, result of minet's CrowdTangle API client.</p> Source code in <code>minall/enrichment/crowdtangle/get_data.py</code> <pre><code>def yield_facebook_data(\n    data: List[str], token: str, rate_limit: int\n) -&gt; Generator[Tuple[str, Any], None, None]:\n    \"\"\"Streams target Facebook URLs to multi-threading context and yields minet's results.\n\n    Args:\n        data (List[str]): Set of target Facebook URLs.\n        token (str): CrowdTangle API token.\n        rate_limit (int): CrowdTangle API rate limit.\n\n    Yields:\n        Generator[Tuple[str, CrowdTanglePost | None], None, None]: Target Facebook URL and, if available, result of minet's CrowdTangle API client.\n    \"\"\"\n    client = CTClient(token=token, rate_limit=rate_limit)\n    with ThreadPoolExecutor() as executor:\n        for url, response in executor.map(client, data):\n            yield url, response\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.contexts","title":"<code>minall.enrichment.crowdtangle.contexts</code>","text":"<p>Context manager for CrowdTangle's CSV writers, multi-threader, and progress bar.</p>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.contexts.ContextManager","title":"<code>ContextManager</code>","text":"Source code in <code>minall/enrichment/crowdtangle/contexts.py</code> <pre><code>class ContextManager:\n    def __init__(self, links_file: Path, shared_content_file: Path):\n        \"\"\"Set up class for scraper's contexts.\n\n        Args:\n            links_file (Path): Path to CSV file for post metadata.\n            shared_content_file (Path): Path to CSV file for posts' shared content metadata.\n        \"\"\"\n        self.links_file = links_file\n        self.shared_content_file = shared_content_file\n\n    def __enter__(self) -&gt; Tuple[csv.DictWriter, csv.DictWriter, Progress]:\n        \"\"\"Start the module's context variables.\n\n        Returns:\n            Tuple[csv.DictWriter, csv.DictWriter, Progress]: CSV writer for post metadata, CSV writer for shared content metadata, rich progress bar.\n        \"\"\"\n        # Set up links file writer\n        self.links_file_obj = open(self.links_file, mode=\"w\")\n        self.links_file_writer = csv.DictWriter(\n            self.links_file_obj, fieldnames=LinksConstants.col_names\n        )\n        self.links_file_writer.writeheader()\n\n        # Set up shared_content file writer\n        self.shared_content_obj = open(self.shared_content_file, mode=\"w\")\n        self.shared_content_writer = csv.DictWriter(\n            self.shared_content_obj, fieldnames=ShareContentConstants.col_names\n        )\n        self.shared_content_writer.writeheader()\n\n        # Set up progress bar\n        self.progress_bar = Progress(\n            TextColumn(\"[progress.description]{task.description}\"),\n            SpinnerColumn(),\n            MofNCompleteColumn(),\n            TimeElapsedColumn(),\n        )\n        self.progress_bar.start()\n\n        return (\n            self.links_file_writer,\n            self.shared_content_writer,\n            self.progress_bar,\n        )\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Stop the scraper's context variables.\"\"\"\n        if self.shared_content_obj:\n            self.shared_content_obj.close()\n        if self.links_file_obj:\n            self.links_file_obj.close()\n        self.progress_bar.stop()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.contexts.ContextManager.__enter__","title":"<code>__enter__()</code>","text":"<p>Start the module's context variables.</p> <p>Returns:</p> Type Description <code>Tuple[DictWriter, DictWriter, Progress]</code> <p>Tuple[csv.DictWriter, csv.DictWriter, Progress]: CSV writer for post metadata, CSV writer for shared content metadata, rich progress bar.</p> Source code in <code>minall/enrichment/crowdtangle/contexts.py</code> <pre><code>def __enter__(self) -&gt; Tuple[csv.DictWriter, csv.DictWriter, Progress]:\n    \"\"\"Start the module's context variables.\n\n    Returns:\n        Tuple[csv.DictWriter, csv.DictWriter, Progress]: CSV writer for post metadata, CSV writer for shared content metadata, rich progress bar.\n    \"\"\"\n    # Set up links file writer\n    self.links_file_obj = open(self.links_file, mode=\"w\")\n    self.links_file_writer = csv.DictWriter(\n        self.links_file_obj, fieldnames=LinksConstants.col_names\n    )\n    self.links_file_writer.writeheader()\n\n    # Set up shared_content file writer\n    self.shared_content_obj = open(self.shared_content_file, mode=\"w\")\n    self.shared_content_writer = csv.DictWriter(\n        self.shared_content_obj, fieldnames=ShareContentConstants.col_names\n    )\n    self.shared_content_writer.writeheader()\n\n    # Set up progress bar\n    self.progress_bar = Progress(\n        TextColumn(\"[progress.description]{task.description}\"),\n        SpinnerColumn(),\n        MofNCompleteColumn(),\n        TimeElapsedColumn(),\n    )\n    self.progress_bar.start()\n\n    return (\n        self.links_file_writer,\n        self.shared_content_writer,\n        self.progress_bar,\n    )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.contexts.ContextManager.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Stop the scraper's context variables.</p> Source code in <code>minall/enrichment/crowdtangle/contexts.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Stop the scraper's context variables.\"\"\"\n    if self.shared_content_obj:\n        self.shared_content_obj.close()\n    if self.links_file_obj:\n        self.links_file_obj.close()\n    self.progress_bar.stop()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.contexts.ContextManager.__init__","title":"<code>__init__(links_file, shared_content_file)</code>","text":"<p>Set up class for scraper's contexts.</p> <p>Parameters:</p> Name Type Description Default <code>links_file</code> <code>Path</code> <p>Path to CSV file for post metadata.</p> required <code>shared_content_file</code> <code>Path</code> <p>Path to CSV file for posts' shared content metadata.</p> required Source code in <code>minall/enrichment/crowdtangle/contexts.py</code> <pre><code>def __init__(self, links_file: Path, shared_content_file: Path):\n    \"\"\"Set up class for scraper's contexts.\n\n    Args:\n        links_file (Path): Path to CSV file for post metadata.\n        shared_content_file (Path): Path to CSV file for posts' shared content metadata.\n    \"\"\"\n    self.links_file = links_file\n    self.shared_content_file = shared_content_file\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.crowdtangle.exceptions","title":"<code>minall.enrichment.crowdtangle.exceptions</code>","text":"<p>Exceptions raised during data collection from CrowdTangle API.</p> <p>This module contains exceptions raised during data collection from CrowdTangle API. The module contains the following exceptions:</p> <ul> <li><code>NoPostID</code> - Neither minet nor minall's adhoc parser successfully recovered the Facebook post's ID.</li> <li><code>PostNotfound</code> - CrowdTangle did not return a post matching the given post ID.</li> </ul>"},{"location":"reference/enrichment/#minall.enrichment.youtube","title":"<code>minall.enrichment.youtube</code>","text":"<p>Enrichment workflow's YouTube data collection.</p> <p>Modules exported by this package:</p> <ul> <li><code>normalizer</code>: Dataclass to normlalize minet's YouTube result objects.</li> <li><code>context</code>: Context manager for client's CSV writer and progress bar.</li> <li><code>get_data</code>: Function that runs all of the YouTube enrichment process.</li> </ul>"},{"location":"reference/enrichment/#minall.enrichment.youtube.normalizer","title":"<code>minall.enrichment.youtube.normalizer</code>","text":"<p>Module contains dataclasses to normalize minet's YouTube Video and Channel result objects.</p>"},{"location":"reference/enrichment/#minall.enrichment.youtube.normalizer.NormalizedYouTubeChannel","title":"<code>NormalizedYouTubeChannel</code>  <code>dataclass</code>","text":"<p>             Bases: <code>TabularRecord</code></p> <p>Dataclass to normalize minet's YoutubeChannel result object.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>Target YouTube channel URL.</p> <code>identifier</code> <code>str</code> <p>YouTube's unique identifier for the channel.</p> <code>date_published</code> <code>str</code> <p>Date when the channel was created.</p> <code>country_of_origin</code> <code>str</code> <p>Primary country in which the channel publishes content.</p> <code>title</code> <code>str</code> <p>Name of the channel.</p> <code>abstract</code> <code>str</code> <p>Description of the channel.</p> <code>keywords</code> <code>List[str]</code> <p>List of keywords attributed to the channel.</p> <code>youtube_subscribe</code> <code>int</code> <p>Number of YouTube users who subscribe to the channel.</p> <code>create_video</code> <code>int</code> <p>Number of videos the channel has published.</p> <code>domain</code> <code>str</code> <p>Domain of target URL. Default = \"youtube.com\".</p> <code>work_type</code> <code>str</code> <p>Ontological subtype of target web content. Default = \"WebPage\".</p> Source code in <code>minall/enrichment/youtube/normalizer.py</code> <pre><code>@dataclass\nclass NormalizedYouTubeChannel(TabularRecord):\n    \"\"\"Dataclass to normalize minet's YoutubeChannel result object.\n\n    Attributes:\n        url (str): Target YouTube channel URL.\n        identifier (str): YouTube's unique identifier for the channel.\n        date_published (str): Date when the channel was created.\n        country_of_origin (str): Primary country in which the channel publishes content.\n        title (str): Name of the channel.\n        abstract (str): Description of the channel.\n        keywords (List[str]): List of keywords attributed to the channel.\n        youtube_subscribe (int): Number of YouTube users who subscribe to the channel.\n        create_video (int): Number of videos the channel has published.\n        domain (str): Domain of target URL. Default = \"youtube.com\".\n        work_type (str): Ontological subtype of target web content. Default = \"WebPage\".\n    \"\"\"\n\n    url: str\n    identifier: str\n    date_published: str\n    country_of_origin: str\n    title: str\n    abstract: str\n    keywords: List[str]\n    youtube_subscribe: int\n    create_video: int\n    domain: str = \"youtube.com\"\n    work_type: str = \"WebPage\"\n\n    @classmethod\n    def from_payload(\n        cls,\n        url: str,\n        channel_result: MinetYouTubeChannelResult,\n    ) -&gt; \"NormalizedYouTubeChannel\":\n        \"\"\"Parses minet's channel result and creates a normalized dataclass.\n\n        Args:\n            url (str): Target YouTube channel URL.\n            channel_result (MinetYouTubeChannelResult): minet's channel results for the target channel URL.\n\n        Returns:\n            NormalizedYouTubeChannel: Dataclass that normalizes minet's channel results.\n        \"\"\"\n        return NormalizedYouTubeChannel(\n            url=url,\n            domain=\"youtube.com\",\n            work_type=\"WebPage\",\n            identifier=channel_result.channel_id,\n            date_published=channel_result.published_at,\n            country_of_origin=channel_result.country,\n            title=channel_result.title,\n            abstract=channel_result.description,\n            keywords=channel_result.keywords,\n            youtube_subscribe=channel_result.subscriber_count,\n            create_video=channel_result.video_count,\n        )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.normalizer.NormalizedYouTubeChannel.from_payload","title":"<code>from_payload(url, channel_result)</code>  <code>classmethod</code>","text":"<p>Parses minet's channel result and creates a normalized dataclass.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target YouTube channel URL.</p> required <code>channel_result</code> <code>YouTubeChannel</code> <p>minet's channel results for the target channel URL.</p> required <p>Returns:</p> Name Type Description <code>NormalizedYouTubeChannel</code> <code>NormalizedYouTubeChannel</code> <p>Dataclass that normalizes minet's channel results.</p> Source code in <code>minall/enrichment/youtube/normalizer.py</code> <pre><code>@classmethod\ndef from_payload(\n    cls,\n    url: str,\n    channel_result: MinetYouTubeChannelResult,\n) -&gt; \"NormalizedYouTubeChannel\":\n    \"\"\"Parses minet's channel result and creates a normalized dataclass.\n\n    Args:\n        url (str): Target YouTube channel URL.\n        channel_result (MinetYouTubeChannelResult): minet's channel results for the target channel URL.\n\n    Returns:\n        NormalizedYouTubeChannel: Dataclass that normalizes minet's channel results.\n    \"\"\"\n    return NormalizedYouTubeChannel(\n        url=url,\n        domain=\"youtube.com\",\n        work_type=\"WebPage\",\n        identifier=channel_result.channel_id,\n        date_published=channel_result.published_at,\n        country_of_origin=channel_result.country,\n        title=channel_result.title,\n        abstract=channel_result.description,\n        keywords=channel_result.keywords,\n        youtube_subscribe=channel_result.subscriber_count,\n        create_video=channel_result.video_count,\n    )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.normalizer.NormalizedYouTubeVideo","title":"<code>NormalizedYouTubeVideo</code>  <code>dataclass</code>","text":"<p>             Bases: <code>TabularRecord</code></p> <p>Dataclass to normalize minet's YoutubeVideo result object.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>Target YouTube video URL.</p> <code>identifier</code> <code>str</code> <p>YouTube's unique identifier for the video.</p> <code>date_published</code> <code>str</code> <p>Date the video was published on YouTube.</p> <code>duration</code> <code>str</code> <p>Duration of the video.</p> <code>title</code> <code>str</code> <p>Title of the video.</p> <code>abstract</code> <code>str</code> <p>Video's description.</p> <code>keywords</code> <code>List</code> <p>List of keywords applied to video.</p> <code>youtube_watch</code> <code>str</code> <p>Number of users who have watched the YouTube video.</p> <code>youtube_comment</code> <code>str</code> <p>Number of users who have commented on the YouTube video.</p> <code>youtube_like</code> <code>str</code> <p>Number of users who have liked the YouTube video.</p> <code>creator_type</code> <code>str</code> <p>Ontological subtype of the video's channel.</p> <code>creator_name</code> <code>str</code> <p>Name of the video's channel.</p> <code>creator_date_created</code> <code>str</code> <p>Date when the video's channel was created.</p> <code>creator_location_created</code> <code>str</code> <p>Primary country in which the video's channel publishes content.</p> <code>creator_identifier</code> <code>str</code> <p>YouTube's unique identifier for the video's channel.</p> <code>creator_youtube_subscribe</code> <code>str</code> <p>Number of YouTube accounts that subscribe to the video's channel.</p> <code>creator_create_video</code> <code>str</code> <p>Number of videos the video's channel has published.</p> <code>domain</code> <code>str</code> <p>Domain of target URL. Default = \"youtube.com\".</p> <code>work_type</code> <code>str</code> <p>Ontological subtype of target web content. Default = \"VideoObject\".</p> Source code in <code>minall/enrichment/youtube/normalizer.py</code> <pre><code>@dataclass\nclass NormalizedYouTubeVideo(TabularRecord):\n    \"\"\"Dataclass to normalize minet's YoutubeVideo result object.\n\n    Attributes:\n        url (str): Target YouTube video URL.\n        identifier (str): YouTube's unique identifier for the video.\n        date_published (str): Date the video was published on YouTube.\n        duration (str): Duration of the video.\n        title (str): Title of the video.\n        abstract (str): Video's description.\n        keywords (List): List of keywords applied to video.\n        youtube_watch (str): Number of users who have watched the YouTube video.\n        youtube_comment (str): Number of users who have commented on the YouTube video.\n        youtube_like (str): Number of users who have liked the YouTube video.\n        creator_type (str): Ontological subtype of the video's channel.\n        creator_name (str): Name of the video's channel.\n        creator_date_created (str): Date when the video's channel was created.\n        creator_location_created (str): Primary country in which the video's channel publishes content.\n        creator_identifier (str): YouTube's unique identifier for the video's channel.\n        creator_youtube_subscribe (str): Number of YouTube accounts that subscribe to the video's channel.\n        creator_create_video (str): Number of videos the video's channel has published.\n        domain (str): Domain of target URL. Default = \"youtube.com\".\n        work_type (str): Ontological subtype of target web content. Default = \"VideoObject\".\n    \"\"\"\n\n    url: str\n    identifier: str\n    date_published: str\n    duration: str\n    title: str\n    abstract: str\n    keywords: List[str]\n    youtube_watch: str\n    youtube_comment: str\n    youtube_like: str\n    # youtube_favorite was depreciated by YouTube in 2015.\n    creator_type: str\n    creator_name: str\n    creator_date_created: str\n    creator_location_created: str\n    creator_identifier: str\n    creator_youtube_subscribe: str\n    creator_create_video: str\n    domain: str = \"youtube.com\"\n    work_type: str = \"VideoObject\"\n\n    @classmethod\n    def from_payload(\n        cls,\n        url: str,\n        channel_result: MinetYouTubeChannelResult | None,\n        video_result: MinetYouTubeVideoResult,\n    ) -&gt; \"NormalizedYouTubeVideo\":\n        \"\"\"Parses minet's data for both a video and channel and creates a normalized dataclass.\n\n        Args:\n            url (str): Target YouTube video URL.\n            channel_result (MinetYouTubeChannelResult | None): minet's channel results containing metadata about the target video's channel.\n            video_result (MinetYouTubeVideoResult): minet's video results for the target video.\n\n        Returns:\n            NormalizedYouTubeVideo: Dataclass that normalizes and merges video and channel results.\n        \"\"\"\n        if channel_result:\n            channel = channel_result.as_csv_dict_row()\n        else:\n            channel = {}\n        return NormalizedYouTubeVideo(\n            url=url,\n            domain=\"youtube.com\",\n            work_type=\"VideoObject\",\n            identifier=video_result.video_id,\n            date_published=video_result.published_at,\n            duration=video_result.duration,\n            title=video_result.title,\n            abstract=video_result.description,\n            keywords=channel.get(\"keywords\"),  # type: ignore\n            youtube_watch=video_result.view_count,  # type: ignore\n            youtube_comment=video_result.comment_count,  # type: ignore\n            youtube_like=video_result.like_count,  # type: ignore\n            creator_type=\"WebPage\",\n            creator_name=video_result.channel_title,\n            creator_identifier=video_result.channel_id,\n            creator_date_created=channel.get(\"published_at\"),  # type: ignore\n            creator_location_created=channel.get(\"country\"),  # type: ignore\n            creator_youtube_subscribe=channel.get(\"subscriber_count\"),  # type: ignore\n            creator_create_video=channel.get(\"video_count\"),  # type: ignore\n        )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.normalizer.NormalizedYouTubeVideo.from_payload","title":"<code>from_payload(url, channel_result, video_result)</code>  <code>classmethod</code>","text":"<p>Parses minet's data for both a video and channel and creates a normalized dataclass.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target YouTube video URL.</p> required <code>channel_result</code> <code>YouTubeChannel | None</code> <p>minet's channel results containing metadata about the target video's channel.</p> required <code>video_result</code> <code>YouTubeVideo</code> <p>minet's video results for the target video.</p> required <p>Returns:</p> Name Type Description <code>NormalizedYouTubeVideo</code> <code>NormalizedYouTubeVideo</code> <p>Dataclass that normalizes and merges video and channel results.</p> Source code in <code>minall/enrichment/youtube/normalizer.py</code> <pre><code>@classmethod\ndef from_payload(\n    cls,\n    url: str,\n    channel_result: MinetYouTubeChannelResult | None,\n    video_result: MinetYouTubeVideoResult,\n) -&gt; \"NormalizedYouTubeVideo\":\n    \"\"\"Parses minet's data for both a video and channel and creates a normalized dataclass.\n\n    Args:\n        url (str): Target YouTube video URL.\n        channel_result (MinetYouTubeChannelResult | None): minet's channel results containing metadata about the target video's channel.\n        video_result (MinetYouTubeVideoResult): minet's video results for the target video.\n\n    Returns:\n        NormalizedYouTubeVideo: Dataclass that normalizes and merges video and channel results.\n    \"\"\"\n    if channel_result:\n        channel = channel_result.as_csv_dict_row()\n    else:\n        channel = {}\n    return NormalizedYouTubeVideo(\n        url=url,\n        domain=\"youtube.com\",\n        work_type=\"VideoObject\",\n        identifier=video_result.video_id,\n        date_published=video_result.published_at,\n        duration=video_result.duration,\n        title=video_result.title,\n        abstract=video_result.description,\n        keywords=channel.get(\"keywords\"),  # type: ignore\n        youtube_watch=video_result.view_count,  # type: ignore\n        youtube_comment=video_result.comment_count,  # type: ignore\n        youtube_like=video_result.like_count,  # type: ignore\n        creator_type=\"WebPage\",\n        creator_name=video_result.channel_title,\n        creator_identifier=video_result.channel_id,\n        creator_date_created=channel.get(\"published_at\"),  # type: ignore\n        creator_location_created=channel.get(\"country\"),  # type: ignore\n        creator_youtube_subscribe=channel.get(\"subscriber_count\"),  # type: ignore\n        creator_create_video=channel.get(\"video_count\"),  # type: ignore\n    )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.normalizer.ParsedLink","title":"<code>ParsedLink</code>","text":"<p>Class to store up-to-date metadata about target YouTube URL.</p> <p>This class's instance variables will be updated during the data collection process to reflect the target URL's video and/or channel metadata. If the target URL is of a video, its <code>ParsedLink</code> class instance should eventually be mutated to have a value in both the <code>video_result</code> and <code>channel_result</code> attributes because 2 API calls will be made. If the target URL is of a channel, its <code>ParsedLink</code> class instance should eventually be mutated to have a value in the <code>channel_result</code> attribute, after 1 call to the YouTube API's channels endpoint.</p> Source code in <code>minall/enrichment/youtube/normalizer.py</code> <pre><code>class ParsedLink:\n    \"\"\"Class to store up-to-date metadata about target YouTube URL.\n\n    This class's instance variables will be updated during the data collection process to reflect the target URL's video and/or channel metadata. If the target URL is of a video, its `ParsedLink` class instance should eventually be mutated to have a value in both the `video_result` and `channel_result` attributes because 2 API calls will be made. If the target URL is of a channel, its `ParsedLink` class instance should eventually be mutated to have a value in the `channel_result` attribute, after 1 call to the YouTube API's channels endpoint.\n    \"\"\"\n\n    def __init__(self, url: str) -&gt; None:\n        \"\"\"Determine type of YouTube web content.\n\n        Args:\n            url (str): Target YouTube URL.\n\n        Attributes:\n            link_id (str): Target YouTube URL.\n            type (YoutubeChannel | YoutubeVideo | Any): Result of ural's `parse_youtube_url()` function.\n            video_id (str | None): If a parsed YouTube type is a video, the result's `id` attribute.\n            channel_id (str | None): If a parsed YouTube type is a channel, the result's `id` attribute.\n            video_result (None): Empty class instance variable for later storing minet's video result object.\n            channel_result (None): Empty class instance variable for later storing minet's channel result object.\n        \"\"\"\n        self.link_id = url\n\n        self.type = parse_youtube_url(url)\n\n        if isinstance(self.type, YoutubeVideo):\n            self.video_id = getattr(self.type, \"id\")\n            self.channel_id = None\n\n        elif isinstance(self.type, YoutubeChannel):\n            self.channel_id = getattr(self.type, \"id\")\n            self.video_id = None\n\n        self.video_result = None\n        self.channel_result = None\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.normalizer.ParsedLink.__init__","title":"<code>__init__(url)</code>","text":"<p>Determine type of YouTube web content.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target YouTube URL.</p> required <p>Attributes:</p> Name Type Description <code>link_id</code> <code>str</code> <p>Target YouTube URL.</p> <code>type</code> <code>YoutubeChannel | YoutubeVideo | Any</code> <p>Result of ural's <code>parse_youtube_url()</code> function.</p> <code>video_id</code> <code>str | None</code> <p>If a parsed YouTube type is a video, the result's <code>id</code> attribute.</p> <code>channel_id</code> <code>str | None</code> <p>If a parsed YouTube type is a channel, the result's <code>id</code> attribute.</p> <code>video_result</code> <code>None</code> <p>Empty class instance variable for later storing minet's video result object.</p> <code>channel_result</code> <code>None</code> <p>Empty class instance variable for later storing minet's channel result object.</p> Source code in <code>minall/enrichment/youtube/normalizer.py</code> <pre><code>def __init__(self, url: str) -&gt; None:\n    \"\"\"Determine type of YouTube web content.\n\n    Args:\n        url (str): Target YouTube URL.\n\n    Attributes:\n        link_id (str): Target YouTube URL.\n        type (YoutubeChannel | YoutubeVideo | Any): Result of ural's `parse_youtube_url()` function.\n        video_id (str | None): If a parsed YouTube type is a video, the result's `id` attribute.\n        channel_id (str | None): If a parsed YouTube type is a channel, the result's `id` attribute.\n        video_result (None): Empty class instance variable for later storing minet's video result object.\n        channel_result (None): Empty class instance variable for later storing minet's channel result object.\n    \"\"\"\n    self.link_id = url\n\n    self.type = parse_youtube_url(url)\n\n    if isinstance(self.type, YoutubeVideo):\n        self.video_id = getattr(self.type, \"id\")\n        self.channel_id = None\n\n    elif isinstance(self.type, YoutubeChannel):\n        self.channel_id = getattr(self.type, \"id\")\n        self.video_id = None\n\n    self.video_result = None\n    self.channel_result = None\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.normalizer.normalize","title":"<code>normalize(parsed_link)</code>","text":"<p>Normalize minet result objects stored in instance variables of the <code>ParsedLink</code> class.</p> <p>Parameters:</p> Name Type Description Default <code>parsed_link</code> <code>ParsedLink</code> <p>Class instance with minet's YouTube API results.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary to be added to CSV row for 'links' SQL table.</p> Source code in <code>minall/enrichment/youtube/normalizer.py</code> <pre><code>def normalize(parsed_link: ParsedLink) -&gt; dict:\n    \"\"\"Normalize minet result objects stored in instance variables of the `ParsedLink` class.\n\n    Args:\n        parsed_link (ParsedLink): Class instance with minet's YouTube API results.\n\n    Returns:\n        dict: Dictionary to be added to CSV row for 'links' SQL table.\n    \"\"\"\n\n    url = parsed_link.link_id\n    if isinstance(parsed_link.video_result, MinetYouTubeVideoResult):\n        data = NormalizedYouTubeVideo.from_payload(\n            url=url,\n            channel_result=parsed_link.channel_result,\n            video_result=parsed_link.video_result,\n        )\n        return data.as_csv_dict_row()\n    elif isinstance(parsed_link.channel_result, MinetYouTubeChannelResult):\n        data = NormalizedYouTubeChannel.from_payload(\n            url=url, channel_result=parsed_link.channel_result\n        )\n        return data.as_csv_dict_row()\n    else:\n        return {\"url\": url}\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.get_data","title":"<code>minall.enrichment.youtube.get_data</code>","text":"<p>Module contains function to manage process of collecting and normalizing data about YouTube web content.</p>"},{"location":"reference/enrichment/#minall.enrichment.youtube.get_data.get_youtube_data","title":"<code>get_youtube_data(data, keys, outfile)</code>","text":"<p>Collects and writes metadata about target YouTube videos and channels to a CSV file that will be inserted into 'links' SQL table.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list[str]</code> <p>Set of target YouTube URLs.</p> required <code>keys</code> <code>list[str]</code> <p>Set of keys for YouTube API.</p> required <code>outfile</code> <code>Path</code> <p>Path to CSV file for 'links' SQL table.</p> required Source code in <code>minall/enrichment/youtube/get_data.py</code> <pre><code>def get_youtube_data(data: list[str], keys: list[str], outfile: Path) -&gt; None:\n    \"\"\"Collects and writes metadata about target YouTube videos and channels to a CSV file that will be inserted into 'links' SQL table.\n\n    Args:\n        data (list[str]): Set of target YouTube URLs.\n        keys (list[str]): Set of keys for YouTube API.\n        outfile (Path): Path to CSV file for 'links' SQL table.\n    \"\"\"\n    # Sort the URLs into channels and videos\n    parsed_links = [ParsedLink(url) for url in data]\n    n_videos = len([i for i in parsed_links if isinstance(i.type, YoutubeVideo)])\n\n    client = YouTubeAPIClient(key=keys)\n\n    # Mutate the parsed_links array by adding video data\n    with ProgressBar() as progress:\n        t = progress.add_task(\n            description=\"[bold red]Querying YouTube videos\", total=n_videos\n        )\n        for pl in parsed_links:\n            if isinstance(pl.type, YoutubeVideo):\n                for _, result in client.videos(videos=[pl.video_id]):\n                    setattr(pl, \"video_result\", result)\n                    setattr(pl, \"channel_id\", getattr(result, \"channel_id\"))\n                    progress.advance(t)\n\n    # Get a unique set of channels from video and channel data\n    channel_set = set()\n    for pl in parsed_links:\n        if pl.channel_id:\n            channel_set.add(\"https://www.youtube.com/channel/\" + pl.channel_id)\n\n    # Create an index of unique channels and their collected metadata\n    channel_index = {}\n    with ProgressBar() as progress:\n        t = progress.add_task(\n            description=\"[bold red]Querying YouTube channels\", total=len(channel_set)\n        )\n        for channel_url, result in client.channels(channels_target=channel_set):\n            channel_id = channel_url.split(\"/\")[-1]\n            channel_index.update({channel_id: result})\n            progress.advance(t)\n\n    # Again mutate the parsed_links array by adding channel data\n    for pl in parsed_links:\n        if pl.channel_id:\n            pl.channel_result = channel_index.get(pl.channel_id)\n\n    with Writer(links_file=outfile) as writer:\n        for pl in parsed_links:\n            normalized_result = normalize(pl)\n            writer.writerow(normalized_result)\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.context","title":"<code>minall.enrichment.youtube.context</code>","text":"<p>Module containing contexts for YouTube data collection's CSV writer and progress bar.</p>"},{"location":"reference/enrichment/#minall.enrichment.youtube.context.ProgressBar","title":"<code>ProgressBar</code>","text":"<p>Context for rich progress bar.</p> Source code in <code>minall/enrichment/youtube/context.py</code> <pre><code>class ProgressBar:\n    \"\"\"Context for rich progress bar.\"\"\"\n\n    def __init__(self) -&gt; None:\n        pass\n\n    def __enter__(self) -&gt; Progress:\n        \"\"\"Start the rich progress bar.\n\n        Returns:\n            Progress: Context variable for rich progress bar.\n        \"\"\"\n\n        self.progress_bar = Progress(\n            TextColumn(\"[progress.description]{task.description}\"),\n            SpinnerColumn(),\n            MofNCompleteColumn(),\n            TimeElapsedColumn(),\n        )\n        self.progress_bar.start()\n        return self.progress_bar\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Stops the progress bar's context variable.\"\"\"\n        self.progress_bar.stop()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.context.ProgressBar.__enter__","title":"<code>__enter__()</code>","text":"<p>Start the rich progress bar.</p> <p>Returns:</p> Name Type Description <code>Progress</code> <code>Progress</code> <p>Context variable for rich progress bar.</p> Source code in <code>minall/enrichment/youtube/context.py</code> <pre><code>def __enter__(self) -&gt; Progress:\n    \"\"\"Start the rich progress bar.\n\n    Returns:\n        Progress: Context variable for rich progress bar.\n    \"\"\"\n\n    self.progress_bar = Progress(\n        TextColumn(\"[progress.description]{task.description}\"),\n        SpinnerColumn(),\n        MofNCompleteColumn(),\n        TimeElapsedColumn(),\n    )\n    self.progress_bar.start()\n    return self.progress_bar\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.context.ProgressBar.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Stops the progress bar's context variable.</p> Source code in <code>minall/enrichment/youtube/context.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Stops the progress bar's context variable.\"\"\"\n    self.progress_bar.stop()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.context.Writer","title":"<code>Writer</code>","text":"<p>Context for writing YouTube links metadata to CSV of 'links' SQL table.</p> Source code in <code>minall/enrichment/youtube/context.py</code> <pre><code>class Writer:\n    \"\"\"Context for writing YouTube links metadata to CSV of 'links' SQL table.\"\"\"\n\n    def __init__(self, links_file: Path):\n        \"\"\"Set up class for iteratively writing normalized YouTube results to CSV.\n\n        Args:\n            links_file (Path): Path to the links table CSV file.\n        \"\"\"\n        self.links_file = links_file\n\n    def __enter__(self) -&gt; csv.DictWriter:\n        \"\"\"Start the CSV writer's context.\n\n        Returns:\n            csv.DictWriter: Context variable for writing CSV rows.\n        \"\"\"\n\n        self.links_file_obj = open(self.links_file, mode=\"w\")\n        self.links_file_writer = csv.DictWriter(\n            self.links_file_obj, fieldnames=LinksConstants.col_names\n        )\n        self.links_file_writer.writeheader()\n\n        return self.links_file_writer\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Stops the writer's context variable.\"\"\"\n        if self.links_file_obj:\n            self.links_file_obj.close()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.context.Writer.__enter__","title":"<code>__enter__()</code>","text":"<p>Start the CSV writer's context.</p> <p>Returns:</p> Type Description <code>DictWriter</code> <p>csv.DictWriter: Context variable for writing CSV rows.</p> Source code in <code>minall/enrichment/youtube/context.py</code> <pre><code>def __enter__(self) -&gt; csv.DictWriter:\n    \"\"\"Start the CSV writer's context.\n\n    Returns:\n        csv.DictWriter: Context variable for writing CSV rows.\n    \"\"\"\n\n    self.links_file_obj = open(self.links_file, mode=\"w\")\n    self.links_file_writer = csv.DictWriter(\n        self.links_file_obj, fieldnames=LinksConstants.col_names\n    )\n    self.links_file_writer.writeheader()\n\n    return self.links_file_writer\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.context.Writer.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Stops the writer's context variable.</p> Source code in <code>minall/enrichment/youtube/context.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Stops the writer's context variable.\"\"\"\n    if self.links_file_obj:\n        self.links_file_obj.close()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.youtube.context.Writer.__init__","title":"<code>__init__(links_file)</code>","text":"<p>Set up class for iteratively writing normalized YouTube results to CSV.</p> <p>Parameters:</p> Name Type Description Default <code>links_file</code> <code>Path</code> <p>Path to the links table CSV file.</p> required Source code in <code>minall/enrichment/youtube/context.py</code> <pre><code>def __init__(self, links_file: Path):\n    \"\"\"Set up class for iteratively writing normalized YouTube results to CSV.\n\n    Args:\n        links_file (Path): Path to the links table CSV file.\n    \"\"\"\n    self.links_file = links_file\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.other_social_media","title":"<code>minall.enrichment.other_social_media</code>","text":"<p>Module to update ontological subtype for social media posts whose data is not accessible.</p>"},{"location":"reference/enrichment/#minall.enrichment.other_social_media.add_data","title":"<code>minall.enrichment.other_social_media.add_data</code>","text":"<p>Module contains function to write web content ontological subtype information to CSV.</p> <p>The module contains a function that write the ontological subtype \"SocialMediaPosting\" and the related target URL to a CSV, which will be inserted into the 'links' SQL table.</p>"},{"location":"reference/enrichment/#minall.enrichment.other_social_media.add_data.add_data","title":"<code>add_data(data, outfile)</code>","text":"<p>For the set of target URLs, write the URL and the category \"SocialMediaPosting\" to a CSV row for insert into the 'links' SQL table.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[str]</code> <p>Target URLs.</p> required <code>outfile</code> <code>Path</code> <p>Path to CSV file for links.</p> required Source code in <code>minall/enrichment/other_social_media/add_data.py</code> <pre><code>def add_data(data: List[str], outfile: Path):\n    \"\"\"For the set of target URLs, write the URL and the category \"SocialMediaPosting\" to a CSV row for insert into the 'links' SQL table.\n\n    Args:\n        data (List[str]): Target URLs.\n        outfile (Path): Path to CSV file for links.\n    \"\"\"\n    with open(outfile, \"w\") as f:\n        writer = csv.DictWriter(f, fieldnames=LinksConstants.col_names)\n        writer.writeheader()\n        [\n            writer.writerow({\"url\": url, \"work_type\": \"SocialMediaPosting\"})\n            for url in data\n        ]\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text","title":"<code>minall.enrichment.article_text</code>","text":"<p>Enrichment workflow's HTML scraping features.</p> <p>Modules exported by this package:</p> <ul> <li><code>normalizer</code>: Dataclass to normlalize minet's Trafilatura result object.</li> <li><code>contexts</code>: Context manager for scraper's CSV writers, multi-threader, and progress bar.</li> <li><code>get_data</code>: Function that runs all of the scraping process.</li> <li><code>scraper</code>: Class and helper function for scraping HTML.</li> </ul>"},{"location":"reference/enrichment/#minall.enrichment.article_text.normalizer","title":"<code>minall.enrichment.article_text.normalizer</code>","text":"<p>Dataclass to normlalize minet's Trafilatura result object.</p>"},{"location":"reference/enrichment/#minall.enrichment.article_text.normalizer.NormalizedScrapedWebPage","title":"<code>NormalizedScrapedWebPage</code>  <code>dataclass</code>","text":"<p>             Bases: <code>TabularRecord</code></p> <p>Dataclass to normlalize minet's Trafilatura result object.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>URL targeted for scraping.</p> <code>title</code> <code>str | None</code> <p>Title scraped from HTML.</p> <code>text</code> <code>str | None</code> <p>Main text scraped from HTML.</p> <code>date_published</code> <code>str | None</code> <p>Date scraped from HTML.</p> <code>work_type</code> <code>str</code> <p>Target URL's ontological subtype. Default = \"WebPage\".</p> Source code in <code>minall/enrichment/article_text/normalizer.py</code> <pre><code>@dataclass\nclass NormalizedScrapedWebPage(TabularRecord):\n    \"\"\"Dataclass to normlalize minet's Trafilatura result object.\n\n    Attributes:\n        url (str): URL targeted for scraping.\n        title (str | None): Title scraped from HTML.\n        text (str | None): Main text scraped from HTML.\n        date_published (str | None): Date scraped from HTML.\n        work_type (str): Target URL's ontological subtype. Default = \"WebPage\".\n    \"\"\"\n\n    url: str\n    title: str | None\n    text: str | None\n    date_published: str | None\n    work_type: str = \"WebPage\"\n\n    @classmethod\n    def from_payload(\n        cls,\n        url: str,\n        result: TrafilaturaResult,\n    ) -&gt; \"NormalizedScrapedWebPage\":\n        return NormalizedScrapedWebPage(\n            url=url, title=result.title, text=result.content, date_published=result.date\n        )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.scraper","title":"<code>minall.enrichment.article_text.scraper</code>","text":"<p>Class and helper function for scraping HTML.</p> <p>This module's <code>Scraper</code> class enhances minet's <code>request()</code> and <code>extract()</code> methods by providing additional support for unexpected HTML encodings.</p> <ol> <li>Uses minet's <code>request()</code> method on a target URL to get a <code>Response</code> object.</li> <li>Verifies that the <code>Response</code> object is encoded in some form of utf-8.</li> <li>Extracts the HTML body from the <code>Response</code>. [<code>text = response.text()</code>]</li> <li>Uses bs4's fool-proof <code>UnicodeDammit</code> to parse the exact encoding. [<code>UnicodeDammit(text, \"html.parser\").declared_html_encoding</code>]</li> <li>Gives the encoding to bs4's <code>BeautifulSoup</code> to parse the HTML.</li> <li>Gives the <code>BeautifulSoup</code> result to minet's <code>extract()</code> method in order to return minet's <code>TrafilaturaResult</code> object.</li> </ol>"},{"location":"reference/enrichment/#minall.enrichment.article_text.scraper.Scraper","title":"<code>Scraper</code>","text":"<p>Class to manage HTML scraping.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; scraper = Scraper()\n&gt;&gt;&gt; url, result = scraper(url='https://zenodo.org/records/7974793')\n&gt;&gt;&gt; url == result.canonical_url\nTrue\n&gt;&gt;&gt; result.title\n'Minet, a webmining CLI tool &amp; library for python.'\n</code></pre> Source code in <code>minall/enrichment/article_text/scraper.py</code> <pre><code>class Scraper:\n    \"\"\"Class to manage HTML scraping.\n\n    Examples:\n        &gt;&gt;&gt; scraper = Scraper()\n        &gt;&gt;&gt; url, result = scraper(url='https://zenodo.org/records/7974793')\n        &gt;&gt;&gt; url == result.canonical_url\n        True\n        &gt;&gt;&gt; result.title\n        'Minet, a webmining CLI tool &amp; library for python.'\n    \"\"\"\n\n    def __init__(\n        self, progress: Progress | None = None, total: int | None = None\n    ) -&gt; None:\n        \"\"\"If provided the context of a rich progress bar, save it to the class instance and add the task 'Scraping webpage'.\n\n        Args:\n            progress (Progress | None, optional): Context of a rich progress bar instance. Defaults to None.\n            total (int | None, optional): Total number of items treated during progress context. Defaults to None.\n        \"\"\"\n        self.progress = progress\n        if progress:\n            self.progress = progress\n            t = progress.add_task(\n                description=\"[bold yellow]Scraping webpage\", total=total\n            )\n            self.task_id = t\n\n    def __call__(self, url: str) -&gt; Tuple[str, TrafilaturaResult | None]:\n        \"\"\"Requests and scrapes HTML, returning minet's Trafilatura Result object.\n\n        Args:\n            url (str): Target URL.\n\n        Returns:\n            Tuple[str, TrafilaturaResult | None]: The target URL and, if scraping was successful, minet's Trafilatura Result object.\n        \"\"\"\n        if self.progress:\n            self.progress.advance(self.task_id)\n        result = None\n        response = None\n\n        # Request URL's HTML\n        try:\n            response = request(url)\n        except Exception as e:\n            logging.error(e)\n\n        # Parse requested HTML\n        if response and good_response(response):\n            text = response.text()\n            try:\n                # Avoid input conversion error, deriving from inside Trafilatura's lxml dependency\n                encoding = UnicodeDammit(text, \"html.parser\").declared_html_encoding\n                soup = BeautifulSoup(text, features=\"lxml\", from_encoding=encoding)\n                text = soup.decode(formatter=\"html\")\n                result = extract(text)\n            except Exception as e:\n                logger.exception(e)\n        return url, result\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.scraper.Scraper.__call__","title":"<code>__call__(url)</code>","text":"<p>Requests and scrapes HTML, returning minet's Trafilatura Result object.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target URL.</p> required <p>Returns:</p> Type Description <code>Tuple[str, TrafilaturaResult | None]</code> <p>Tuple[str, TrafilaturaResult | None]: The target URL and, if scraping was successful, minet's Trafilatura Result object.</p> Source code in <code>minall/enrichment/article_text/scraper.py</code> <pre><code>def __call__(self, url: str) -&gt; Tuple[str, TrafilaturaResult | None]:\n    \"\"\"Requests and scrapes HTML, returning minet's Trafilatura Result object.\n\n    Args:\n        url (str): Target URL.\n\n    Returns:\n        Tuple[str, TrafilaturaResult | None]: The target URL and, if scraping was successful, minet's Trafilatura Result object.\n    \"\"\"\n    if self.progress:\n        self.progress.advance(self.task_id)\n    result = None\n    response = None\n\n    # Request URL's HTML\n    try:\n        response = request(url)\n    except Exception as e:\n        logging.error(e)\n\n    # Parse requested HTML\n    if response and good_response(response):\n        text = response.text()\n        try:\n            # Avoid input conversion error, deriving from inside Trafilatura's lxml dependency\n            encoding = UnicodeDammit(text, \"html.parser\").declared_html_encoding\n            soup = BeautifulSoup(text, features=\"lxml\", from_encoding=encoding)\n            text = soup.decode(formatter=\"html\")\n            result = extract(text)\n        except Exception as e:\n            logger.exception(e)\n    return url, result\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.scraper.Scraper.__init__","title":"<code>__init__(progress=None, total=None)</code>","text":"<p>If provided the context of a rich progress bar, save it to the class instance and add the task 'Scraping webpage'.</p> <p>Parameters:</p> Name Type Description Default <code>progress</code> <code>Progress | None</code> <p>Context of a rich progress bar instance. Defaults to None.</p> <code>None</code> <code>total</code> <code>int | None</code> <p>Total number of items treated during progress context. Defaults to None.</p> <code>None</code> Source code in <code>minall/enrichment/article_text/scraper.py</code> <pre><code>def __init__(\n    self, progress: Progress | None = None, total: int | None = None\n) -&gt; None:\n    \"\"\"If provided the context of a rich progress bar, save it to the class instance and add the task 'Scraping webpage'.\n\n    Args:\n        progress (Progress | None, optional): Context of a rich progress bar instance. Defaults to None.\n        total (int | None, optional): Total number of items treated during progress context. Defaults to None.\n    \"\"\"\n    self.progress = progress\n    if progress:\n        self.progress = progress\n        t = progress.add_task(\n            description=\"[bold yellow]Scraping webpage\", total=total\n        )\n        self.task_id = t\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.scraper.good_response","title":"<code>good_response(response)</code>","text":"<p>Verifies that the response that minet's request method returned is valid for scraping.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>Response</code> <p>Response object returned from minet's request method.</p> required <p>Returns:</p> Type Description <code>Response | None</code> <p>Response | None: If valid, the Response; otherwise None.</p> Source code in <code>minall/enrichment/article_text/scraper.py</code> <pre><code>def good_response(response: Response) -&gt; Response | None:\n    \"\"\"Verifies that the response that minet's request method returned is valid for scraping.\n\n    Args:\n        response (Response): Response object returned from minet's request method.\n\n    Returns:\n        Response | None: If valid, the Response; otherwise None.\n    \"\"\"\n    if (\n        response.is_text\n        and response.encoding\n        and \"utf\" in response.encoding\n        and \"8\" in response.encoding\n    ):\n        return response\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.get_data","title":"<code>minall.enrichment.article_text.get_data</code>","text":"<p>Module contains a function that runs the scraping feature.</p>"},{"location":"reference/enrichment/#minall.enrichment.article_text.get_data.get_data","title":"<code>get_data(data, outfile)</code>","text":"<p>Iterating through the target URLs, scrape data and write to out-file.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list[str]</code> <p>Set of target URLs for scraping.</p> required <code>outfile</code> <code>Path</code> <p>Path to CSV file for writing normalized results.</p> required Source code in <code>minall/enrichment/article_text/get_data.py</code> <pre><code>def get_data(data: list[str], outfile: Path):\n    \"\"\"Iterating through the target URLs, scrape data and write to out-file.\n\n    Args:\n        data (list[str]): Set of target URLs for scraping.\n        outfile (Path): Path to CSV file for writing normalized results.\n    \"\"\"\n    with ContextManager(links_file=outfile) as contexts:\n        writer, executor, progress = contexts\n        scraper = Scraper(progress=progress, total=len(data))\n        for url, result in executor.map(scraper, data):\n            if result:\n                formatted_result = NormalizedScrapedWebPage.from_payload(\n                    url=url, result=result\n                )\n                writer.writerow(formatted_result.as_csv_dict_row())\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.contexts","title":"<code>minall.enrichment.article_text.contexts</code>","text":"<p>Context manager for scraper's CSV writers, multi-threader, and progress bar.</p>"},{"location":"reference/enrichment/#minall.enrichment.article_text.contexts.ContextManager","title":"<code>ContextManager</code>","text":"Source code in <code>minall/enrichment/article_text/contexts.py</code> <pre><code>class ContextManager:\n    def __init__(self, links_file: Path):\n        \"\"\"Set up class for scraper's contexts.\n\n        Args:\n            links_file (Path): Path to out-file for CSV writer.\n        \"\"\"\n        self.links_file = links_file\n\n    def __enter__(self) -&gt; Tuple[csv.DictWriter, ThreadPoolExecutor, Progress]:\n        \"\"\"Start the scraper's context variables.\n\n        Returns:\n            Tuple[csv.DictWriter, ThreadPoolExecutor, Progress]: Context variables.\n        \"\"\"\n        # Set up links file writer\n        self.links_file_obj = open(self.links_file, mode=\"w\", encoding=\"utf-8\")\n        self.links_file_writer = csv.DictWriter(\n            self.links_file_obj, fieldnames=LinksConstants.col_names\n        )\n        self.links_file_writer.writeheader()\n\n        # Set up multi-threading pool\n        self.executor = ThreadPoolExecutor(max_workers=3)\n\n        # Set up progress bar\n        self.progress_bar = Progress(\n            TextColumn(\"[progress.description]{task.description}\"),\n            SpinnerColumn(),\n            MofNCompleteColumn(),\n            TimeElapsedColumn(),\n        )\n        self.progress_bar.start()\n\n        return (\n            self.links_file_writer,\n            self.executor,\n            self.progress_bar,\n        )\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Stop the scraper's context variables.\"\"\"\n        if self.links_file_obj:\n            self.links_file_obj.close()\n        self.executor.shutdown(wait=False, cancel_futures=True)\n        self.progress_bar.stop()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.contexts.ContextManager.__enter__","title":"<code>__enter__()</code>","text":"<p>Start the scraper's context variables.</p> <p>Returns:</p> Type Description <code>Tuple[DictWriter, ThreadPoolExecutor, Progress]</code> <p>Tuple[csv.DictWriter, ThreadPoolExecutor, Progress]: Context variables.</p> Source code in <code>minall/enrichment/article_text/contexts.py</code> <pre><code>def __enter__(self) -&gt; Tuple[csv.DictWriter, ThreadPoolExecutor, Progress]:\n    \"\"\"Start the scraper's context variables.\n\n    Returns:\n        Tuple[csv.DictWriter, ThreadPoolExecutor, Progress]: Context variables.\n    \"\"\"\n    # Set up links file writer\n    self.links_file_obj = open(self.links_file, mode=\"w\", encoding=\"utf-8\")\n    self.links_file_writer = csv.DictWriter(\n        self.links_file_obj, fieldnames=LinksConstants.col_names\n    )\n    self.links_file_writer.writeheader()\n\n    # Set up multi-threading pool\n    self.executor = ThreadPoolExecutor(max_workers=3)\n\n    # Set up progress bar\n    self.progress_bar = Progress(\n        TextColumn(\"[progress.description]{task.description}\"),\n        SpinnerColumn(),\n        MofNCompleteColumn(),\n        TimeElapsedColumn(),\n    )\n    self.progress_bar.start()\n\n    return (\n        self.links_file_writer,\n        self.executor,\n        self.progress_bar,\n    )\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.contexts.ContextManager.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Stop the scraper's context variables.</p> Source code in <code>minall/enrichment/article_text/contexts.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Stop the scraper's context variables.\"\"\"\n    if self.links_file_obj:\n        self.links_file_obj.close()\n    self.executor.shutdown(wait=False, cancel_futures=True)\n    self.progress_bar.stop()\n</code></pre>"},{"location":"reference/enrichment/#minall.enrichment.article_text.contexts.ContextManager.__init__","title":"<code>__init__(links_file)</code>","text":"<p>Set up class for scraper's contexts.</p> <p>Parameters:</p> Name Type Description Default <code>links_file</code> <code>Path</code> <p>Path to out-file for CSV writer.</p> required Source code in <code>minall/enrichment/article_text/contexts.py</code> <pre><code>def __init__(self, links_file: Path):\n    \"\"\"Set up class for scraper's contexts.\n\n    Args:\n        links_file (Path): Path to out-file for CSV writer.\n    \"\"\"\n    self.links_file = links_file\n</code></pre>"},{"location":"reference/home/","title":"Code base","text":"<p>The structure of the documentation resembles the code's architecture. Each page, as shown in the navigation bar on the left, represents a module or a folder descending from the source code's directory, <code>minall/</code>. The descriptions and examples of individual classes and functions are generated automatically from dostrings written in the Python modules.</p> <p>Click through the pages/modules and scroll down to different Python objects, as seen on the pages' right-hand navigation bar, to explore how the code works.</p> <ul> <li><code>docs/</code></li> <li><code>minall/</code><ul> <li><code>cli/</code></li> <li><code>enrichment/</code></li> <li><code>tables/</code></li> <li><code>utils/</code></li> <li><code>__init__.py</code></li> <li><code>__version__.py</code></li> <li><code>main.py</code></li> </ul> </li> <li><code>tests/</code></li> </ul>"},{"location":"reference/main/","title":"Minall","text":"<p>To facilitate the project's use as a Python library and as a CLI tool, <code>minall</code>'s workflow is managed via an exportable class, <code>Minall</code>.</p> <p>By creating a class instance of <code>Minall</code>, the following preliminary steps are taken:</p> <ul> <li>API credentials for the <code>minet</code> clients are parsed. (param: <code>config</code>)</li> <li>File paths to the workflow's eventual output, CSV files for the target URLs (<code>links.csv</code>) and their shared content (<code>shared_content.csv</code>), are prepared. This includes the creation of any necessary parent directories. (param: <code>out_dir</code>)</li> <li>The SQLite database connection is created. The connection can either be in-memory or, if a file path is provided, to an embedded SQLite database. If the user wants <code>Minall</code> to create and store the workflow's results in an SQLite database file, simply providing a file path will also create the file. (param: <code>database</code>)</li> <li>Through the SQLite connection, SQL tables are created for the user-provided data files. A file of target URLs is necessary, whose data will be parsed and inserted into the 'links' SQL table. (param: <code>links_file</code>, <code>url_col</code>, <code>shared_content_file</code>)</li> <li>The class instance remembers whether to (a) deploy all of the <code>minall</code> enrichment workflow or (b) only collect the generalized Buzzsumo metadata. (param: <code>buzzsumo_only</code>)</li> </ul>"},{"location":"reference/main/#minall.main","title":"<code>minall.main</code>","text":"<p>Minall enrichment workflow.</p> <p>With the class <code>Minall</code>, this module manages the entire workflow.</p> <p>The class contains the following methods:</p> <ul> <li><code>__init__(database, config, output_dir, links_file, url_col, shared_content_file, buzzsumo_only)</code> - Intialize SQLite database and out-file paths.</li> <li><code>collect_and_coalesce()</code> - Collect new data and coalesce with existing data in relevant SQL tables.</li> <li><code>export()</code> - Write enriched SQL tables to CSV out-files.</li> </ul>"},{"location":"reference/main/#minall.main.Minall","title":"<code>Minall</code>","text":"<p>Class to store variables and execute steps of enrichment.</p> Source code in <code>minall/main.py</code> <pre><code>class Minall:\n    \"\"\"Class to store variables and execute steps of enrichment.\"\"\"\n\n    def __init__(\n        self,\n        database: str | None,\n        config: str | dict | None,\n        output_dir: Path | str,\n        links_file: Path | str,\n        url_col: str,\n        shared_content_file: Path | str | None = None,\n        buzzsumo_only: bool = False,\n    ) -&gt; None:\n        \"\"\"Intialize SQLite database and out-file paths.\n\n        Examples:\n            &gt;&gt;&gt; # Set file path variables.\n            &gt;&gt;&gt; OUT_DIR = Path(__file__).parent.parent.joinpath(\"docs\").joinpath(\"doctest\")\n            &gt;&gt;&gt; LINKS_FILE = OUT_DIR.joinpath('minall_init_example.csv')\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Create Minall instance.\n            &gt;&gt;&gt; minall = Minall(database=None, config={}, output_dir=str(OUT_DIR), links_file=str(LINKS_FILE), url_col='target_url')\n            &gt;&gt;&gt; minall.links_table.table\n            LinksConstants(table_name='links', primary_key='url')\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Check that Minall's SQLite database connection has committed 1 change (creating the 'links' table).\n            &gt;&gt;&gt; minall.connection.total_changes\n            1\n\n        Args:\n            database (str | None): Path name to SQLite database. If None, creates database in memory.\n            config (str | dict | None): Credentials for API keys.\n            output_dir (Path | str): Path to directory for enriched CSV files.\n            links_file (Path | str): Path to in-file for URLs.\n            url_col (str): Name of URL column in URLs file.\n            shared_content_file (str | None): Path name to CSV file of shared content related to URLs.\n            buzzsumo_only (bool, optional): Whether to only run Buzzsumo enrichment. Defaults to False.\n        \"\"\"\n\n        # Connect to the SQLite database\n        self.connection = connect_to_database(database=database)\n\n        # Parse API keys from config file / dict\n        self.keys = APIKeys(config=config)\n\n        # Store Buzzsumo-only flag\n        self.buzzsumo_only = buzzsumo_only\n\n        # Set paths to output directory and out-files\n        if not isinstance(output_dir, Path):\n            output_dir = Path(output_dir)\n        self.output_dir = output_dir\n        self.output_dir.mkdir(exist_ok=True)\n        [p.mkdir(exist_ok=True) for p in self.output_dir.parents]\n        self.links_file = self.output_dir.joinpath(\"links.csv\")\n        self.shared_contents_file = self.output_dir.joinpath(\"shared_content.csv\")\n\n        # Input original data into the database\n        if not isinstance(links_file, Path):\n            links_file = Path(links_file)\n        self.links_table = LinksTable(\n            conn=self.connection,\n            infile=links_file,\n            url_col=url_col,\n            outfile=self.links_file,\n        )\n\n        if isinstance(shared_content_file, str):\n            shared_content_file = Path(shared_content_file)\n        self.shared_content_table = SharedContentTable(\n            conn=self.connection,\n            infile=shared_content_file,\n            outfile=self.shared_contents_file,\n        )\n\n    def collect_and_coalesce(self):\n        \"\"\"Collect new data and coalesce with existing data in relevant SQL tables.\n\n        This method creates an instance of the class `Enrichment` (from `minall.enrichment.enrichment`), providing the target URL table ('links' table, `self.links_table`), the minet API credentials (`self.keys`), and the related shared content table (`self.shared_content_table`) which may go unused depending on parameters used when `Enrichment` is called.\n\n        Having prepared the `Enrichment` instance, the method then calls the class, providing its `self.buzzsumo_only` instance attribute as the argument for `Enrichment`'s `buzzsumo_only` parameter. The latter boolean parameter determines whether all of the `Enrichment` class's methods will be deployed or only its Buzzsumo method.\n        \"\"\"\n        enricher = Enrichment(\n            links_table=self.links_table,\n            shared_content_table=self.shared_content_table,\n            keys=self.keys,\n        )\n        enricher(buzzsumo_only=self.buzzsumo_only)\n\n    def export(self) -&gt; Tuple[Path, Path]:\n        \"\"\"Write enriched SQL tables to CSV out-files.\n\n        This method simply exports to CSV files both of the `Minall` class instance's SQL tables, `self.links_table` and `self.shared_content_table`. The class that manages the SQL tables (`minall.tables.base.BaseTable`), stores each table's out-file path as an instance variable. The parent directory for both out-files was declared during `Minall`'s `__init__()` method via the parameter `output_dir`, from which the out-file paths were subsequently derived.\n\n        Returns:\n            Tuple[Path, Path]: Paths to links and shared content CSV files.\n        \"\"\"\n        self.links_table.export()\n        self.shared_content_table.export()\n        return self.links_file, self.shared_contents_file\n</code></pre>"},{"location":"reference/main/#minall.main.Minall.__init__","title":"<code>__init__(database, config, output_dir, links_file, url_col, shared_content_file=None, buzzsumo_only=False)</code>","text":"<p>Intialize SQLite database and out-file paths.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Set file path variables.\n&gt;&gt;&gt; OUT_DIR = Path(__file__).parent.parent.joinpath(\"docs\").joinpath(\"doctest\")\n&gt;&gt;&gt; LINKS_FILE = OUT_DIR.joinpath('minall_init_example.csv')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create Minall instance.\n&gt;&gt;&gt; minall = Minall(database=None, config={}, output_dir=str(OUT_DIR), links_file=str(LINKS_FILE), url_col='target_url')\n&gt;&gt;&gt; minall.links_table.table\nLinksConstants(table_name='links', primary_key='url')\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check that Minall's SQLite database connection has committed 1 change (creating the 'links' table).\n&gt;&gt;&gt; minall.connection.total_changes\n1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>database</code> <code>str | None</code> <p>Path name to SQLite database. If None, creates database in memory.</p> required <code>config</code> <code>str | dict | None</code> <p>Credentials for API keys.</p> required <code>output_dir</code> <code>Path | str</code> <p>Path to directory for enriched CSV files.</p> required <code>links_file</code> <code>Path | str</code> <p>Path to in-file for URLs.</p> required <code>url_col</code> <code>str</code> <p>Name of URL column in URLs file.</p> required <code>shared_content_file</code> <code>str | None</code> <p>Path name to CSV file of shared content related to URLs.</p> <code>None</code> <code>buzzsumo_only</code> <code>bool</code> <p>Whether to only run Buzzsumo enrichment. Defaults to False.</p> <code>False</code> Source code in <code>minall/main.py</code> <pre><code>def __init__(\n    self,\n    database: str | None,\n    config: str | dict | None,\n    output_dir: Path | str,\n    links_file: Path | str,\n    url_col: str,\n    shared_content_file: Path | str | None = None,\n    buzzsumo_only: bool = False,\n) -&gt; None:\n    \"\"\"Intialize SQLite database and out-file paths.\n\n    Examples:\n        &gt;&gt;&gt; # Set file path variables.\n        &gt;&gt;&gt; OUT_DIR = Path(__file__).parent.parent.joinpath(\"docs\").joinpath(\"doctest\")\n        &gt;&gt;&gt; LINKS_FILE = OUT_DIR.joinpath('minall_init_example.csv')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create Minall instance.\n        &gt;&gt;&gt; minall = Minall(database=None, config={}, output_dir=str(OUT_DIR), links_file=str(LINKS_FILE), url_col='target_url')\n        &gt;&gt;&gt; minall.links_table.table\n        LinksConstants(table_name='links', primary_key='url')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Check that Minall's SQLite database connection has committed 1 change (creating the 'links' table).\n        &gt;&gt;&gt; minall.connection.total_changes\n        1\n\n    Args:\n        database (str | None): Path name to SQLite database. If None, creates database in memory.\n        config (str | dict | None): Credentials for API keys.\n        output_dir (Path | str): Path to directory for enriched CSV files.\n        links_file (Path | str): Path to in-file for URLs.\n        url_col (str): Name of URL column in URLs file.\n        shared_content_file (str | None): Path name to CSV file of shared content related to URLs.\n        buzzsumo_only (bool, optional): Whether to only run Buzzsumo enrichment. Defaults to False.\n    \"\"\"\n\n    # Connect to the SQLite database\n    self.connection = connect_to_database(database=database)\n\n    # Parse API keys from config file / dict\n    self.keys = APIKeys(config=config)\n\n    # Store Buzzsumo-only flag\n    self.buzzsumo_only = buzzsumo_only\n\n    # Set paths to output directory and out-files\n    if not isinstance(output_dir, Path):\n        output_dir = Path(output_dir)\n    self.output_dir = output_dir\n    self.output_dir.mkdir(exist_ok=True)\n    [p.mkdir(exist_ok=True) for p in self.output_dir.parents]\n    self.links_file = self.output_dir.joinpath(\"links.csv\")\n    self.shared_contents_file = self.output_dir.joinpath(\"shared_content.csv\")\n\n    # Input original data into the database\n    if not isinstance(links_file, Path):\n        links_file = Path(links_file)\n    self.links_table = LinksTable(\n        conn=self.connection,\n        infile=links_file,\n        url_col=url_col,\n        outfile=self.links_file,\n    )\n\n    if isinstance(shared_content_file, str):\n        shared_content_file = Path(shared_content_file)\n    self.shared_content_table = SharedContentTable(\n        conn=self.connection,\n        infile=shared_content_file,\n        outfile=self.shared_contents_file,\n    )\n</code></pre>"},{"location":"reference/main/#minall.main.Minall.collect_and_coalesce","title":"<code>collect_and_coalesce()</code>","text":"<p>Collect new data and coalesce with existing data in relevant SQL tables.</p> <p>This method creates an instance of the class <code>Enrichment</code> (from <code>minall.enrichment.enrichment</code>), providing the target URL table ('links' table, <code>self.links_table</code>), the minet API credentials (<code>self.keys</code>), and the related shared content table (<code>self.shared_content_table</code>) which may go unused depending on parameters used when <code>Enrichment</code> is called.</p> <p>Having prepared the <code>Enrichment</code> instance, the method then calls the class, providing its <code>self.buzzsumo_only</code> instance attribute as the argument for <code>Enrichment</code>'s <code>buzzsumo_only</code> parameter. The latter boolean parameter determines whether all of the <code>Enrichment</code> class's methods will be deployed or only its Buzzsumo method.</p> Source code in <code>minall/main.py</code> <pre><code>def collect_and_coalesce(self):\n    \"\"\"Collect new data and coalesce with existing data in relevant SQL tables.\n\n    This method creates an instance of the class `Enrichment` (from `minall.enrichment.enrichment`), providing the target URL table ('links' table, `self.links_table`), the minet API credentials (`self.keys`), and the related shared content table (`self.shared_content_table`) which may go unused depending on parameters used when `Enrichment` is called.\n\n    Having prepared the `Enrichment` instance, the method then calls the class, providing its `self.buzzsumo_only` instance attribute as the argument for `Enrichment`'s `buzzsumo_only` parameter. The latter boolean parameter determines whether all of the `Enrichment` class's methods will be deployed or only its Buzzsumo method.\n    \"\"\"\n    enricher = Enrichment(\n        links_table=self.links_table,\n        shared_content_table=self.shared_content_table,\n        keys=self.keys,\n    )\n    enricher(buzzsumo_only=self.buzzsumo_only)\n</code></pre>"},{"location":"reference/main/#minall.main.Minall.export","title":"<code>export()</code>","text":"<p>Write enriched SQL tables to CSV out-files.</p> <p>This method simply exports to CSV files both of the <code>Minall</code> class instance's SQL tables, <code>self.links_table</code> and <code>self.shared_content_table</code>. The class that manages the SQL tables (<code>minall.tables.base.BaseTable</code>), stores each table's out-file path as an instance variable. The parent directory for both out-files was declared during <code>Minall</code>'s <code>__init__()</code> method via the parameter <code>output_dir</code>, from which the out-file paths were subsequently derived.</p> <p>Returns:</p> Type Description <code>Tuple[Path, Path]</code> <p>Tuple[Path, Path]: Paths to links and shared content CSV files.</p> Source code in <code>minall/main.py</code> <pre><code>def export(self) -&gt; Tuple[Path, Path]:\n    \"\"\"Write enriched SQL tables to CSV out-files.\n\n    This method simply exports to CSV files both of the `Minall` class instance's SQL tables, `self.links_table` and `self.shared_content_table`. The class that manages the SQL tables (`minall.tables.base.BaseTable`), stores each table's out-file path as an instance variable. The parent directory for both out-files was declared during `Minall`'s `__init__()` method via the parameter `output_dir`, from which the out-file paths were subsequently derived.\n\n    Returns:\n        Tuple[Path, Path]: Paths to links and shared content CSV files.\n    \"\"\"\n    self.links_table.export()\n    self.shared_content_table.export()\n    return self.links_file, self.shared_contents_file\n</code></pre>"},{"location":"reference/tables/","title":"Table tools","text":"<p>With SQLite, the module <code>minall/tables</code> manages the data during the enrichment process, from the data input at the start to the updated version exported at the end. The process relies on the following two tables:</p> <ol> <li> <p>The <code>links</code> table, which is the backbone of the enrichment, stores the target URLs and their enriched metadata.</p> </li> <li> <p>The <code>shared_content</code> table, which is optional, stores URLs pointing to content shared via the target URLs' content.</p> </li> </ol> <p>As illustrated in the figure below, the two tables are related. The target URL (<code>url</code>) in the <code>links</code> table refers to the <code>post_url</code> in the <code>shared_content</code> table. A target URL (<code>url</code>) in the <code>links</code> table can share 0 or more items. Depending on the URLs dataset, it could be the case that no entities in the <code>links</code> table have shared any content. All entities in the <code>shared_content</code> must relate to at least one entity in the <code>links</code> table. Content in the <code>shared_content</code> table can have been shared by 1 or more URLs in the <code>links</code> table.</p> <pre><code>erDiagram\n    LINKS }|--o{ SHARED_CONTENT : shares\n    LINKS {\n        text url PK\n        text domain\n        text work_type\n        text duration\n        text identifier\n        text date_published\n        text date_modified\n        text country_of_origin\n        text abstract\n        text keywords\n        text title\n        text text\n        text hashtags\n        text creator_type\n        text creator_date_created\n        text creator_identifier\n        integer creator_facebook_follow\n        integer creator_facebook_subscribe\n        integer creator_twitter_follow\n        integer creator_youtube_subscribe\n        integer creator_create_video\n        text creator_name\n        text creator_url\n        integer facebook_comment\n        integer facebook_like\n        integer facebook_share\n        integer pinterest_share\n        integer twitter_share\n        integer tiktok_share\n        integer tiktok_comment\n        integer reddit_engagement\n        integer youtube_watch\n        integer youtube_comment\n        integer youtube_like\n        integer youtube_favorite\n        integer youtube_subscribe\n        integer create_video\n    }\n    SHARED_CONTENT {\n        text post_url PK\n        text content_url PK\n        text media_type\n        integer height\n        integer width\n    }</code></pre>"},{"location":"reference/tables/#minall.tables.links","title":"<code>minall.tables.links</code>","text":""},{"location":"reference/tables/#minall.tables.links.LinksConstants","title":"<code>LinksConstants</code>  <code>dataclass</code>","text":"<p>Dataclass to manage 'links' table.</p> <p>This dataclass manages the 'links' table's required column names and their data types.</p> <p>Attributes:</p> Name Type Description <code>table_name</code> <code>str</code> <p>Name of the table. Default = \"links\".</p> <code>primary_key</code> <code>str</code> <p>Text string of primary key. Default = \"url\".</p> <code>pk_list</code> <code>list</code> <p>List of primary key columns. Default = [\"url\"]</p> <code>dtypes</code> <code>dict</code> <p>Key-value pairs of column names and SQLite data type descriptions.</p> <code>col_names</code> <code>list</code> <p>List of column names.</p> Source code in <code>minall/tables/links.py</code> <pre><code>@dataclass\nclass LinksConstants:\n    \"\"\"Dataclass to manage 'links' table.\n\n    This dataclass manages the 'links' table's required column names and their data types.\n\n    Attributes:\n        table_name (str): Name of the table. Default = \"links\".\n        primary_key (str): Text string of primary key. Default = \"url\".\n        pk_list (list): List of primary key columns. Default = [\"url\"]\n        dtypes (dict): Key-value pairs of column names and SQLite data type descriptions.\n        col_names (list): List of column names.\n    \"\"\"\n\n    table_name: str = \"links\"\n    primary_key: str = \"url\"\n    pk_list = [\"url\"]\n    dtypes = {\n        \"url\": \"TEXT\",\n        \"domain\": \"TEXT\",\n        \"work_type\": \"TEXT\",\n        \"duration\": \"TEXT\",\n        \"identifier\": \"TEXT\",\n        \"date_published\": \"TEXT\",\n        \"date_modified\": \"TEXT\",\n        \"country_of_origin\": \"TEXT\",\n        \"abstract\": \"TEXT\",\n        \"keywords\": \"TEXT\",\n        \"title\": \"TEXT\",\n        \"text\": \"TEXT\",\n        \"hashtags\": \"TEXT\",\n        \"creator_type\": \"TEXT\",\n        \"creator_date_created\": \"TEXT\",\n        \"creator_location_created\": \"TEXT\",\n        \"creator_identifier\": \"TEXT\",\n        \"creator_facebook_follow\": \"INTEGER\",\n        \"creator_facebook_subscribe\": \"INTEGER\",\n        \"creator_twitter_follow\": \"INTEGER\",\n        \"creator_youtube_subscribe\": \"INTEGER\",\n        \"creator_create_video\": \"INTEGER\",\n        \"creator_name\": \"TEXT\",\n        \"creator_url\": \"TEXT\",\n        \"facebook_comment\": \"INTEGER\",\n        \"facebook_like\": \"INTEGER\",\n        \"facebook_share\": \"INTEGER\",\n        \"pinterest_share\": \"INTEGER\",\n        \"twitter_share\": \"INTEGER\",\n        \"tiktok_share\": \"INTEGER\",\n        \"tiktok_comment\": \"INTEGER\",\n        \"reddit_engagement\": \"INTEGER\",\n        \"youtube_watch\": \"INTEGER\",\n        \"youtube_comment\": \"INTEGER\",\n        \"youtube_like\": \"INTEGER\",\n        \"youtube_favorite\": \"INTEGER\",\n        \"youtube_subscribe\": \"INTEGER\",\n        \"create_video\": \"INTEGER\",\n    }\n    col_names = dtypes.keys()\n</code></pre>"},{"location":"reference/tables/#minall.tables.links.LinksTable","title":"<code>LinksTable</code>","text":"<p>             Bases: <code>BaseTable</code></p> <p>Class for creating, updating, and reading SQL table for target URLs.</p> Source code in <code>minall/tables/links.py</code> <pre><code>class LinksTable(BaseTable):\n    \"\"\"Class for creating, updating, and reading SQL table for target URLs.\"\"\"\n\n    dtypes = LinksConstants.dtypes\n    name = LinksConstants.table_name\n    pk_list = LinksConstants.pk_list\n\n    def __init__(\n        self, conn: Connection, infile: Path, outfile: Path, url_col: str | None = None\n    ):\n        \"\"\"In database connection, create SQL table and populate with data from target URLs dataset file.\n\n        Args:\n            conn (Connection): SQLite connection.\n            infile (Path): Path to URLs dataset file.\n            url_col (str | None, optional): Column name of target URLs. Defaults to None.\n\n        Raises:\n            NoCSVHeaders: Dataset file does not have headers.\n            KeyError: User did not define URL column and dataset file does not have default column 'url'.\n            NoURLColumn: User-defined URL column not found in dataset file.\n        \"\"\"\n        # Update the table's columns to include all in-file columns\n        self.dtypes = self._parse_infile_columns(\n            infile=infile, url_col=url_col, constant_cols=self.dtypes\n        )\n        # Inherit the parent base class\n        super().__init__(\n            name=self.name,\n            pk=self.pk_list,\n            dtypes=self.dtypes,\n            conn=conn,\n            outfile=outfile,\n        )\n\n        # Insert in-file data\n        with open(infile) as f:\n            reader = csv.DictReader(f)\n\n            # Confirm the in-file is compatible with the table\n            headers = reader.fieldnames\n            if not headers:\n                raise NoCSVHeaders()\n            elif len(set(headers).difference(self.dtype_dict.keys())) &gt; 0:\n                raise KeyError()\n\n            # Insert the in-file data\n            for row in reader:\n                if url_col:\n                    row.update({\"url\": row[url_col]})\n                placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n                cols, values = \", \".join(row.keys()), tuple(list(row.values()))\n                query = \"\"\"\n                INSERT OR IGNORE INTO {table}({cols})\n                VALUES ({placeholder})\n                \"\"\".format(\n                    table=self.name, cols=cols, placeholder=placeholder\n                )\n                self.execute(query=query, values=values)\n\n    def _parse_infile_columns(\n        self, infile: Path, constant_cols: Dict, url_col: str | None\n    ) -&gt; Dict:\n        \"\"\"During init method, modify table columns to include in-file's columns.\n\n        Args:\n            infile (Path): Path to URLs dataset.\n            constant_cols (Dict): Key-value pairs of table's standard columns and data types.\n            url_col (str | None, optional): Column name of target URLs.\n\n        Raises:\n            NoCSVHeaders: The infile does not have headers.\n            KeyError: The infile does not have a recognizable URL column.\n            NoURLColumn: The infile does not have the user-declared URL column.\n\n        Returns:\n            Dict: Key-value pairs of table's column names and data types.\n        \"\"\"\n        with casanova.reader(infile) as reader:\n            headers = reader.headers\n        if not headers:\n            raise NoCSVHeaders()\n        elif not url_col and not \"url\" in headers:\n            raise KeyError()\n        elif url_col and not url_col in headers:\n            raise NoURLColumn(url_col=url_col)\n        dtypes = {col: \"TEXT\" for col in headers}\n        return dtypes | constant_cols\n</code></pre>"},{"location":"reference/tables/#minall.tables.links.LinksTable.__init__","title":"<code>__init__(conn, infile, outfile, url_col=None)</code>","text":"<p>In database connection, create SQL table and populate with data from target URLs dataset file.</p> <p>Parameters:</p> Name Type Description Default <code>conn</code> <code>Connection</code> <p>SQLite connection.</p> required <code>infile</code> <code>Path</code> <p>Path to URLs dataset file.</p> required <code>url_col</code> <code>str | None</code> <p>Column name of target URLs. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>NoCSVHeaders</code> <p>Dataset file does not have headers.</p> <code>KeyError</code> <p>User did not define URL column and dataset file does not have default column 'url'.</p> <code>NoURLColumn</code> <p>User-defined URL column not found in dataset file.</p> Source code in <code>minall/tables/links.py</code> <pre><code>def __init__(\n    self, conn: Connection, infile: Path, outfile: Path, url_col: str | None = None\n):\n    \"\"\"In database connection, create SQL table and populate with data from target URLs dataset file.\n\n    Args:\n        conn (Connection): SQLite connection.\n        infile (Path): Path to URLs dataset file.\n        url_col (str | None, optional): Column name of target URLs. Defaults to None.\n\n    Raises:\n        NoCSVHeaders: Dataset file does not have headers.\n        KeyError: User did not define URL column and dataset file does not have default column 'url'.\n        NoURLColumn: User-defined URL column not found in dataset file.\n    \"\"\"\n    # Update the table's columns to include all in-file columns\n    self.dtypes = self._parse_infile_columns(\n        infile=infile, url_col=url_col, constant_cols=self.dtypes\n    )\n    # Inherit the parent base class\n    super().__init__(\n        name=self.name,\n        pk=self.pk_list,\n        dtypes=self.dtypes,\n        conn=conn,\n        outfile=outfile,\n    )\n\n    # Insert in-file data\n    with open(infile) as f:\n        reader = csv.DictReader(f)\n\n        # Confirm the in-file is compatible with the table\n        headers = reader.fieldnames\n        if not headers:\n            raise NoCSVHeaders()\n        elif len(set(headers).difference(self.dtype_dict.keys())) &gt; 0:\n            raise KeyError()\n\n        # Insert the in-file data\n        for row in reader:\n            if url_col:\n                row.update({\"url\": row[url_col]})\n            placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n            cols, values = \", \".join(row.keys()), tuple(list(row.values()))\n            query = \"\"\"\n            INSERT OR IGNORE INTO {table}({cols})\n            VALUES ({placeholder})\n            \"\"\".format(\n                table=self.name, cols=cols, placeholder=placeholder\n            )\n            self.execute(query=query, values=values)\n</code></pre>"},{"location":"reference/tables/#minall.tables.shared_content","title":"<code>minall.tables.shared_content</code>","text":""},{"location":"reference/tables/#minall.tables.shared_content.ShareContentConstants","title":"<code>ShareContentConstants</code>  <code>dataclass</code>","text":"<p>Dataclass to manage 'shared_content' table.</p> <p>This dataclass manages the 'shared_content' table's required column names and their data types. Being a dataclass, however, the instance of the class can also be subsequently modified to include other column names (and their data types) according to the input data. The 'shared_content' table is meant to relate to the 'links' table, wherein the former's 'post_url' column refers to the latter's 'url' column.</p> <p>Contrary to the 'links' table, whose primary key column can be derived from any declared target URL column in the input data, the 'shared_content' table requires the input data has the two columns that jointly compose its primary key, 'post_url' and 'content_url.'</p> <p>Attributes:</p> Name Type Description <code>table_name</code> <code>str</code> <p>Name of the table. Default = \"shared_content\".</p> <code>primary_key</code> <code>str</code> <p>Text string of composite primary key. Default = \"post_url,content_url\".</p> <code>pk_list</code> <code>list</code> <p>List of comosite primary key columns. Default = [\"post_url\", \"content_url]</p> <code>dtypes</code> <code>dict</code> <p>Key-value pairs of column names and SQLite data type descriptions.</p> <code>col_names</code> <code>list</code> <p>List of column names.</p> Source code in <code>minall/tables/shared_content.py</code> <pre><code>@dataclass\nclass ShareContentConstants:\n    \"\"\"Dataclass to manage 'shared_content' table.\n\n    This dataclass manages the 'shared_content' table's required column names and their data types. Being a dataclass, however, the instance of the class can also be subsequently modified to include other column names (and their data types) according to the input data. The 'shared_content' table is meant to relate to the 'links' table, wherein the former's 'post_url' column refers to the latter's 'url' column.\n\n    Contrary to the 'links' table, whose primary key column can be derived from any declared target URL column in the input data, the 'shared_content' table requires the input data has the two columns that jointly compose its primary key, 'post_url' and 'content_url.'\n\n    Attributes:\n        table_name (str): Name of the table. Default = \"shared_content\".\n        primary_key (str): Text string of composite primary key. Default = \"post_url,content_url\".\n        pk_list (list): List of comosite primary key columns. Default = [\"post_url\", \"content_url]\n        dtypes (dict): Key-value pairs of column names and SQLite data type descriptions.\n        col_names (list): List of column names.\n    \"\"\"\n\n    table_name = \"shared_content\"\n    primary_key = \"post_url,content_url\"\n    pk_list = [\"post_url\", \"content_url\"]\n    dtypes = {\n        \"post_url\": f\"TEXT REFERENCES {LinksConstants.table_name}(url) ON UPDATE CASCADE\",\n        \"media_type\": \"TEXT\",\n        \"content_url\": \"TEXT\",\n        \"height\": \"INTEGER\",\n        \"width\": \"INTEGER\",\n    }\n    col_names = dtypes.keys()\n</code></pre>"},{"location":"reference/tables/#minall.tables.shared_content.SharedContentTable","title":"<code>SharedContentTable</code>","text":"<p>             Bases: <code>BaseTable</code></p> <p>Class for creating, updating, and reading SQL table for shared media content, each of which is related to 1 or more entities in the 'links' table.</p> Source code in <code>minall/tables/shared_content.py</code> <pre><code>class SharedContentTable(BaseTable):\n    \"\"\"Class for creating, updating, and reading SQL table for shared media content, each of which is related to 1 or more entities in the 'links' table.\"\"\"\n\n    dtypes = ShareContentConstants.dtypes\n    name = ShareContentConstants.table_name\n    pk_list = ShareContentConstants.pk_list\n\n    def __init__(self, conn: Connection, infile: Path | None, outfile: Path):\n        \"\"\"In database connection, create SQL table. If the user provides an existing shared_content.csv file, populate the table with that input.\n\n        Args:\n            conn (Connection): SQLite connection.\n            infile (Path): Path to shared content dataset file.\n\n        Raises:\n            NoCSVHeaders: Dataset file does not have headers.\n            NoPrimaryKeyColumns: One or more of the required columns ('post_url', 'content_url') is not in the dataset file.\n        \"\"\"\n        # Update the table's columns to include all in-file columns\n        if infile:\n            self.dtypes = self._parse_infile_columns(\n                infile=infile, constant_cols=self.dtypes\n            )\n        # Inherit the parent base class\n        super().__init__(\n            name=self.name,\n            pk=self.pk_list,\n            dtypes=self.dtypes,\n            conn=conn,\n            outfile=outfile,\n        )\n\n        # Insert in-file data\n        if infile:\n            with open(infile) as f:\n                reader = csv.DictReader(f)\n\n                # Confirm the in-file is compatible with the table\n                headers = reader.fieldnames\n                if not headers:\n                    raise NoCSVHeaders()\n                elif len(set(headers).difference(self.dtype_dict.keys())) &gt; 0:\n                    raise KeyError()\n\n                # Insert the in-file data\n                for row in reader:\n                    placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n                    cols, values = \", \".join(row.keys()), tuple(list(row.values()))\n                    query = \"\"\"\n                    INSERT OR IGNORE INTO {table}({cols})\n                    VALUES ({placeholder})\n                    \"\"\".format(\n                        table=self.name, cols=cols, placeholder=placeholder\n                    )\n                    self.execute(query=query, values=values)\n\n    def _parse_infile_columns(self, infile: Path, constant_cols: Dict) -&gt; Dict:\n        \"\"\"During init method, modify table columns to include in-file's columns.\n\n        Args:\n            infile (Path): Path to URLs dataset.\n            constant_cols (Dict): Key-value pairs of table's standard columns and data types.\n            url_col (str | None, optional): Column name of target URLs.\n\n        Raises:\n            NoCSVHeaders: The infile does not have headers.\n            KeyError: The infile does not have a recognizable URL column.\n            NoURLColumn: The infile does not have the user-declared URL column.\n\n        Returns:\n            Dict: Key-value pairs of table's column names and data types.\n        \"\"\"\n        with casanova.reader(infile) as reader:\n            headers = reader.headers\n        if not headers:\n            raise NoCSVHeaders()\n        diff = set(self.pk_list).difference(headers)\n        if len(diff) &gt; 0:\n            raise NoPrimaryKeyColumns(col=list(diff)[0])\n        dtypes = {col: \"TEXT\" for col in headers}\n        return dtypes | constant_cols\n</code></pre>"},{"location":"reference/tables/#minall.tables.shared_content.SharedContentTable.__init__","title":"<code>__init__(conn, infile, outfile)</code>","text":"<p>In database connection, create SQL table. If the user provides an existing shared_content.csv file, populate the table with that input.</p> <p>Parameters:</p> Name Type Description Default <code>conn</code> <code>Connection</code> <p>SQLite connection.</p> required <code>infile</code> <code>Path</code> <p>Path to shared content dataset file.</p> required <p>Raises:</p> Type Description <code>NoCSVHeaders</code> <p>Dataset file does not have headers.</p> <code>NoPrimaryKeyColumns</code> <p>One or more of the required columns ('post_url', 'content_url') is not in the dataset file.</p> Source code in <code>minall/tables/shared_content.py</code> <pre><code>def __init__(self, conn: Connection, infile: Path | None, outfile: Path):\n    \"\"\"In database connection, create SQL table. If the user provides an existing shared_content.csv file, populate the table with that input.\n\n    Args:\n        conn (Connection): SQLite connection.\n        infile (Path): Path to shared content dataset file.\n\n    Raises:\n        NoCSVHeaders: Dataset file does not have headers.\n        NoPrimaryKeyColumns: One or more of the required columns ('post_url', 'content_url') is not in the dataset file.\n    \"\"\"\n    # Update the table's columns to include all in-file columns\n    if infile:\n        self.dtypes = self._parse_infile_columns(\n            infile=infile, constant_cols=self.dtypes\n        )\n    # Inherit the parent base class\n    super().__init__(\n        name=self.name,\n        pk=self.pk_list,\n        dtypes=self.dtypes,\n        conn=conn,\n        outfile=outfile,\n    )\n\n    # Insert in-file data\n    if infile:\n        with open(infile) as f:\n            reader = csv.DictReader(f)\n\n            # Confirm the in-file is compatible with the table\n            headers = reader.fieldnames\n            if not headers:\n                raise NoCSVHeaders()\n            elif len(set(headers).difference(self.dtype_dict.keys())) &gt; 0:\n                raise KeyError()\n\n            # Insert the in-file data\n            for row in reader:\n                placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n                cols, values = \", \".join(row.keys()), tuple(list(row.values()))\n                query = \"\"\"\n                INSERT OR IGNORE INTO {table}({cols})\n                VALUES ({placeholder})\n                \"\"\".format(\n                    table=self.name, cols=cols, placeholder=placeholder\n                )\n                self.execute(query=query, values=values)\n</code></pre>"},{"location":"reference/tables/#minall.tables.base","title":"<code>minall.tables.base</code>","text":"<p>Create and execute queries on SQLite tables.</p> <p>This module contains the class <code>BaseTable</code> that manages the SQLite database's tables. It contains the following methods:</p>"},{"location":"reference/tables/#minall.tables.base.BaseTable","title":"<code>BaseTable</code>","text":"<p>Base class for SQLite tables.</p> Source code in <code>minall/tables/base.py</code> <pre><code>class BaseTable:\n    \"\"\"Base class for SQLite tables.\"\"\"\n\n    def __init__(\n        self, name: str, pk: List[str], conn: Connection, dtypes: Dict, outfile: Path\n    ) -&gt; None:\n        \"\"\"Create the SQL table with the given columns and data types.\n\n        Args:\n            name (str): Table name.\n            pk (List[str]): List of primary keys.\n            conn (Connection): SQLite connection.\n            dtypes (Dict): Key-value pairs of column names and data types.\n            outfile (Path): Path to CSV file where the table will be exported.\n        \"\"\"\n        self.conn = conn\n        self.name = name\n        self.pk_list = pk\n        self.pk_str = \",\".join(pk)\n        self.dtype_dict = dtypes\n        self.outfile = outfile\n\n        # Create the table\n        self.execute(query=f\"DROP TABLE IF EXISTS {self.name}\")\n        self.execute(query=self.create_query)\n\n    def export(self, outfile: Path | None = None):\n        \"\"\"Write the SQL table to a CSV file.\n\n        Args:\n            outfile (Path | None, optional): Path to out-file. Defaults to None.\n        \"\"\"\n        if not outfile:\n            outfile = self.outfile\n        cursor = self.conn.cursor()\n        headers = [\n            t[1]\n            for t in cursor.execute(\n                \"SELECT * FROM pragma_table_info('{}');\".format(self.name)\n            ).fetchall()\n        ]\n        rows = cursor.execute(f\"SELECT * FROM {self.name}\").fetchall()\n        with open(outfile, \"w\") as f:\n            writer = csv.writer(f)\n            writer.writerow(headers)\n            for row in rows:\n                writer.writerow(row)\n\n    def update_from_csv(self, datafile: Path):\n        \"\"\"Reading from a CSV file, update the table rows.\n\n        Args:\n            datafile (Path): Path to file with new data.\n        \"\"\"\n        with open(datafile) as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n                cols_in_csv = \", \".join(row.keys())\n                values = tuple(list(row.values()))\n                coalesce_stmt = self.coalesce_statement(row.keys())\n                query = \"\"\"\n                INSERT INTO {table}({cols_in_csv})\n                VALUES ({placeholder})\n                ON CONFLICT ({pk})\n                DO UPDATE SET {coalesce_stmt}\n                \"\"\".format(\n                    table=self.name,\n                    cols_in_csv=cols_in_csv,\n                    placeholder=placeholder,\n                    pk=self.pk_str,\n                    coalesce_stmt=coalesce_stmt,\n                )\n                self.execute(query=query, values=values)\n\n    def coalesce_statement(self, cols: Iterable[str]) -&gt; str:\n        \"\"\"Compose SQL coalesce statement from columns to be updated.\n\n        Examples:\n            &gt;&gt;&gt; # Set up connection and columns / data types for table.\n            &gt;&gt;&gt; from minall.utils.database import connect_to_database\n            &gt;&gt;&gt; columns_n_datatypes = {\"url\": \"TEXT\", \"domain\": \"TEXT\", \"work_type\": \"TEXT\"}\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Create table.\n            &gt;&gt;&gt; table = BaseTable(name=\"test\", pk=[\"url\"], conn=connect_to_database(), dtypes=columns_n_datatypes, outfile=Path(\"test.csv\"))\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Compose SQL statement to replace table's row with new data.\n            &gt;&gt;&gt; table.coalesce_statement(cols=columns_n_datatypes.keys())\n            'domain=COALESCE(excluded.domain, domain), work_type=COALESCE(excluded.work_type, work_type)'\n\n        Args:\n            cols (Iterable[str]): Row columns.\n\n        Returns:\n            str: SQL statement.\n        \"\"\"\n        return \", \".join(\n            [f\"{k}=COALESCE(excluded.{k}, {k})\" for k in cols if k not in self.pk_list]\n        )\n\n    @property\n    def create_query(self) -&gt; str:\n        \"\"\"SQL statement to create table.\n\n        Examples:\n            &gt;&gt;&gt; # Set up connection and columns / data types for table.\n            &gt;&gt;&gt; from minall.utils.database import connect_to_database\n            &gt;&gt;&gt; columns_n_datatypes = {\"url\": \"TEXT\", \"domain\": \"TEXT\", \"work_type\": \"TEXT\"}\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Create table.\n            &gt;&gt;&gt; table = BaseTable(name=\"test\", pk=[\"url\"], conn=connect_to_database(), dtypes=columns_n_datatypes, outfile=Path(\"test.csv\"))\n            &gt;&gt;&gt;\n            &gt;&gt;&gt; # Compose SQL statement to create table.\n            &gt;&gt;&gt; table.create_query\n            &gt;&gt;&gt; 'CREATE TABLE IF NOT EXISTS test(url TEXT, domain TEXT, work_type TEXT, PRIMARY KEY (url))'\n\n\n        Returns:\n            str: _description_\n        \"\"\"\n        cols = \", \".join([f\"{k} {v}\" for k, v in self.dtype_dict.items()])\n        return (\n            \"\"\"CREATE TABLE IF NOT EXISTS {table}({cols}, PRIMARY KEY ({pk}))\"\"\".format(\n                table=self.name, cols=cols, pk=self.pk_str\n            )\n        )\n\n    def execute(self, query: str, values: Tuple | None = None):\n        \"\"\"Function to commit a query to the database connection.\n\n        Args:\n            query (str): SQL statement.\n            values (Tuple | None, optional): Values to be inserted in the query's placeholders. Defaults to None.\n\n        Raises:\n            e: SQLite Exception.\n        \"\"\"\n        cursor = self.conn.cursor()\n        try:\n            if values:\n                cursor.execute(query, values)\n            else:\n                cursor.execute(query)\n        except Exception as e:\n            print(\"\\n\\n\", query, \"\\n\\n\")\n            raise e\n\n    def select_from(self, cols: str, filter: str | None = None) -&gt; List:\n        \"\"\"Function to select rows from the SQL table.\n\n        Args:\n            cols (str): Target of SELECT statement.\n            filter (str | None, optional): Where condition to apply after FROM statement. Defaults to None.\n\n        Raises:\n            e: SQLite Exception.\n\n        Returns:\n            List: List of rows.\n        \"\"\"\n        if not filter:\n            filter = \"\"\n        else:\n            filter = \" \" + filter\n        query = f\"select {cols} from {self.name}{filter}\"\n        cursor = self.conn.cursor()\n        try:\n            response = cursor.execute(query)\n            self.conn.commit()\n        except Exception as e:\n            print(\"\\n\\n\", query, \"\\n\\n\")\n            raise e\n        else:\n            return response.fetchall()\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.create_query","title":"<code>create_query: str</code>  <code>property</code>","text":"<p>SQL statement to create table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Set up connection and columns / data types for table.\n&gt;&gt;&gt; from minall.utils.database import connect_to_database\n&gt;&gt;&gt; columns_n_datatypes = {\"url\": \"TEXT\", \"domain\": \"TEXT\", \"work_type\": \"TEXT\"}\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create table.\n&gt;&gt;&gt; table = BaseTable(name=\"test\", pk=[\"url\"], conn=connect_to_database(), dtypes=columns_n_datatypes, outfile=Path(\"test.csv\"))\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Compose SQL statement to create table.\n&gt;&gt;&gt; table.create_query\n&gt;&gt;&gt; 'CREATE TABLE IF NOT EXISTS test(url TEXT, domain TEXT, work_type TEXT, PRIMARY KEY (url))'\n</code></pre> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>description</p>"},{"location":"reference/tables/#minall.tables.base.BaseTable.__init__","title":"<code>__init__(name, pk, conn, dtypes, outfile)</code>","text":"<p>Create the SQL table with the given columns and data types.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name.</p> required <code>pk</code> <code>List[str]</code> <p>List of primary keys.</p> required <code>conn</code> <code>Connection</code> <p>SQLite connection.</p> required <code>dtypes</code> <code>Dict</code> <p>Key-value pairs of column names and data types.</p> required <code>outfile</code> <code>Path</code> <p>Path to CSV file where the table will be exported.</p> required Source code in <code>minall/tables/base.py</code> <pre><code>def __init__(\n    self, name: str, pk: List[str], conn: Connection, dtypes: Dict, outfile: Path\n) -&gt; None:\n    \"\"\"Create the SQL table with the given columns and data types.\n\n    Args:\n        name (str): Table name.\n        pk (List[str]): List of primary keys.\n        conn (Connection): SQLite connection.\n        dtypes (Dict): Key-value pairs of column names and data types.\n        outfile (Path): Path to CSV file where the table will be exported.\n    \"\"\"\n    self.conn = conn\n    self.name = name\n    self.pk_list = pk\n    self.pk_str = \",\".join(pk)\n    self.dtype_dict = dtypes\n    self.outfile = outfile\n\n    # Create the table\n    self.execute(query=f\"DROP TABLE IF EXISTS {self.name}\")\n    self.execute(query=self.create_query)\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.coalesce_statement","title":"<code>coalesce_statement(cols)</code>","text":"<p>Compose SQL coalesce statement from columns to be updated.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Set up connection and columns / data types for table.\n&gt;&gt;&gt; from minall.utils.database import connect_to_database\n&gt;&gt;&gt; columns_n_datatypes = {\"url\": \"TEXT\", \"domain\": \"TEXT\", \"work_type\": \"TEXT\"}\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create table.\n&gt;&gt;&gt; table = BaseTable(name=\"test\", pk=[\"url\"], conn=connect_to_database(), dtypes=columns_n_datatypes, outfile=Path(\"test.csv\"))\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Compose SQL statement to replace table's row with new data.\n&gt;&gt;&gt; table.coalesce_statement(cols=columns_n_datatypes.keys())\n'domain=COALESCE(excluded.domain, domain), work_type=COALESCE(excluded.work_type, work_type)'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cols</code> <code>Iterable[str]</code> <p>Row columns.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>SQL statement.</p> Source code in <code>minall/tables/base.py</code> <pre><code>def coalesce_statement(self, cols: Iterable[str]) -&gt; str:\n    \"\"\"Compose SQL coalesce statement from columns to be updated.\n\n    Examples:\n        &gt;&gt;&gt; # Set up connection and columns / data types for table.\n        &gt;&gt;&gt; from minall.utils.database import connect_to_database\n        &gt;&gt;&gt; columns_n_datatypes = {\"url\": \"TEXT\", \"domain\": \"TEXT\", \"work_type\": \"TEXT\"}\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create table.\n        &gt;&gt;&gt; table = BaseTable(name=\"test\", pk=[\"url\"], conn=connect_to_database(), dtypes=columns_n_datatypes, outfile=Path(\"test.csv\"))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Compose SQL statement to replace table's row with new data.\n        &gt;&gt;&gt; table.coalesce_statement(cols=columns_n_datatypes.keys())\n        'domain=COALESCE(excluded.domain, domain), work_type=COALESCE(excluded.work_type, work_type)'\n\n    Args:\n        cols (Iterable[str]): Row columns.\n\n    Returns:\n        str: SQL statement.\n    \"\"\"\n    return \", \".join(\n        [f\"{k}=COALESCE(excluded.{k}, {k})\" for k in cols if k not in self.pk_list]\n    )\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.execute","title":"<code>execute(query, values=None)</code>","text":"<p>Function to commit a query to the database connection.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SQL statement.</p> required <code>values</code> <code>Tuple | None</code> <p>Values to be inserted in the query's placeholders. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>e</code> <p>SQLite Exception.</p> Source code in <code>minall/tables/base.py</code> <pre><code>def execute(self, query: str, values: Tuple | None = None):\n    \"\"\"Function to commit a query to the database connection.\n\n    Args:\n        query (str): SQL statement.\n        values (Tuple | None, optional): Values to be inserted in the query's placeholders. Defaults to None.\n\n    Raises:\n        e: SQLite Exception.\n    \"\"\"\n    cursor = self.conn.cursor()\n    try:\n        if values:\n            cursor.execute(query, values)\n        else:\n            cursor.execute(query)\n    except Exception as e:\n        print(\"\\n\\n\", query, \"\\n\\n\")\n        raise e\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.export","title":"<code>export(outfile=None)</code>","text":"<p>Write the SQL table to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>outfile</code> <code>Path | None</code> <p>Path to out-file. Defaults to None.</p> <code>None</code> Source code in <code>minall/tables/base.py</code> <pre><code>def export(self, outfile: Path | None = None):\n    \"\"\"Write the SQL table to a CSV file.\n\n    Args:\n        outfile (Path | None, optional): Path to out-file. Defaults to None.\n    \"\"\"\n    if not outfile:\n        outfile = self.outfile\n    cursor = self.conn.cursor()\n    headers = [\n        t[1]\n        for t in cursor.execute(\n            \"SELECT * FROM pragma_table_info('{}');\".format(self.name)\n        ).fetchall()\n    ]\n    rows = cursor.execute(f\"SELECT * FROM {self.name}\").fetchall()\n    with open(outfile, \"w\") as f:\n        writer = csv.writer(f)\n        writer.writerow(headers)\n        for row in rows:\n            writer.writerow(row)\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.select_from","title":"<code>select_from(cols, filter=None)</code>","text":"<p>Function to select rows from the SQL table.</p> <p>Parameters:</p> Name Type Description Default <code>cols</code> <code>str</code> <p>Target of SELECT statement.</p> required <code>filter</code> <code>str | None</code> <p>Where condition to apply after FROM statement. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>e</code> <p>SQLite Exception.</p> <p>Returns:</p> Name Type Description <code>List</code> <code>List</code> <p>List of rows.</p> Source code in <code>minall/tables/base.py</code> <pre><code>def select_from(self, cols: str, filter: str | None = None) -&gt; List:\n    \"\"\"Function to select rows from the SQL table.\n\n    Args:\n        cols (str): Target of SELECT statement.\n        filter (str | None, optional): Where condition to apply after FROM statement. Defaults to None.\n\n    Raises:\n        e: SQLite Exception.\n\n    Returns:\n        List: List of rows.\n    \"\"\"\n    if not filter:\n        filter = \"\"\n    else:\n        filter = \" \" + filter\n    query = f\"select {cols} from {self.name}{filter}\"\n    cursor = self.conn.cursor()\n    try:\n        response = cursor.execute(query)\n        self.conn.commit()\n    except Exception as e:\n        print(\"\\n\\n\", query, \"\\n\\n\")\n        raise e\n    else:\n        return response.fetchall()\n</code></pre>"},{"location":"reference/tables/#minall.tables.base.BaseTable.update_from_csv","title":"<code>update_from_csv(datafile)</code>","text":"<p>Reading from a CSV file, update the table rows.</p> <p>Parameters:</p> Name Type Description Default <code>datafile</code> <code>Path</code> <p>Path to file with new data.</p> required Source code in <code>minall/tables/base.py</code> <pre><code>def update_from_csv(self, datafile: Path):\n    \"\"\"Reading from a CSV file, update the table rows.\n\n    Args:\n        datafile (Path): Path to file with new data.\n    \"\"\"\n    with open(datafile) as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            placeholder = \", \".join([\"?\" for _ in range(len(row.items()))])\n            cols_in_csv = \", \".join(row.keys())\n            values = tuple(list(row.values()))\n            coalesce_stmt = self.coalesce_statement(row.keys())\n            query = \"\"\"\n            INSERT INTO {table}({cols_in_csv})\n            VALUES ({placeholder})\n            ON CONFLICT ({pk})\n            DO UPDATE SET {coalesce_stmt}\n            \"\"\".format(\n                table=self.name,\n                cols_in_csv=cols_in_csv,\n                placeholder=placeholder,\n                pk=self.pk_str,\n                coalesce_stmt=coalesce_stmt,\n            )\n            self.execute(query=query, values=values)\n</code></pre>"},{"location":"reference/tables/#minall.tables.exceptions","title":"<code>minall.tables.exceptions</code>","text":"<p>Exceptions for validating CSV files used to create SQLite tables.</p> <p>This module contains exceptions to manage the process of validating a CSV file given as input for the enrichment process. The module contains the following exceptions:</p> <ul> <li><code>NoCSVHeaders</code> - The CSV does not have headers.</li> <li><code>NoURLColumn</code> - When building the 'links' table, the declared URL column is not in the CSV file.</li> <li><code>NoPrimaryKeyColumns</code> - When building the 'shared_content' table, either the 'post_url' column or the 'content_url' column are missing from the CSV file.</li> </ul> <p>When creating the 'links' table, the input CSV file must have a column for URLs; the URLs must be cleaned and/or ready to serve as the source for the data collection. The name of the URL column can vary and must be declared.</p> <p>When creating the 'shared_content' table, the column names are not modifiable. The CSV must have the columns 'post_url' and 'content_url;' the former relates to a URL in the 'links' table, and the latter incidates a URL for content embedded in the Web Content of the former.</p>"},{"location":"reference/tables/#minall.tables.exceptions.NoCSVHeaders","title":"<code>NoCSVHeaders</code>","text":"<p>             Bases: <code>Exception</code></p> <p>The CSV in-file lacks headers.</p> Source code in <code>minall/tables/exceptions.py</code> <pre><code>class NoCSVHeaders(Exception):\n    \"\"\"The CSV in-file lacks headers.\"\"\"\n\n    def __init__(self) -&gt; None:\n        message = \"No headers detected in CSV file.\"\n        super().__init__(message)\n</code></pre>"},{"location":"reference/tables/#minall.tables.exceptions.NoPrimaryKeyColumns","title":"<code>NoPrimaryKeyColumns</code>","text":"<p>             Bases: <code>Exception</code></p> <p>The CSV in-file is missing a required column.</p> Source code in <code>minall/tables/exceptions.py</code> <pre><code>class NoPrimaryKeyColumns(Exception):\n    \"\"\"The CSV in-file is missing a required column.\"\"\"\n\n    def __init__(self, col: str) -&gt; None:\n        message = f\"Required primary key column '{col}' is not a header in the given CSV file.\"\n        super().__init__(message)\n</code></pre>"},{"location":"reference/tables/#minall.tables.exceptions.NoURLColumn","title":"<code>NoURLColumn</code>","text":"<p>             Bases: <code>Exception</code></p> <p>The CSV in-file is missing a user-declared column.</p> Source code in <code>minall/tables/exceptions.py</code> <pre><code>class NoURLColumn(Exception):\n    \"\"\"The CSV in-file is missing a user-declared column.\"\"\"\n\n    def __init__(self, url_col: str) -&gt; None:\n        message = f\"The declared URL column '{url_col}' is not a header in the given CSV file.\"\n        super().__init__(message)\n</code></pre>"},{"location":"reference/utils/","title":"Utilities","text":"<p>Little blurb</p>"},{"location":"reference/utils/#minall.utils.database","title":"<code>minall.utils.database</code>","text":"<p>Utilities to manage SQLite database connection.</p> <p>The module contains the following function and class:</p> <ul> <li><code>connect_to_database(database)</code> - If provided with path, connects to embedded SQLite database; otherwise, connects to in-memory SQLite database.</li> <li><code>SQLiteWrapper(connection)</code> - Stores connection and cursor, executes queries.</li> </ul>"},{"location":"reference/utils/#minall.utils.database.SQLiteWrapper","title":"<code>SQLiteWrapper</code>","text":"<p>Class to store SQLite database connection and execute SQL queries.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n&gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n&gt;&gt;&gt; wrapper.select(\"select * from test\")\n[]\n</code></pre> Source code in <code>minall/utils/database.py</code> <pre><code>class SQLiteWrapper:\n    \"\"\"Class to store SQLite database connection and execute SQL queries.\n\n    Examples:\n        &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n        &gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n        &gt;&gt;&gt; wrapper.select(\"select * from test\")\n        []\n\n    \"\"\"\n\n    def __init__(self, connection: Connection) -&gt; None:\n        \"\"\"Store database connection and create cursor.\n\n        Examples:\n            &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n            &gt;&gt;&gt; type(wrapper.cursor)\n            &lt;class 'sqlite3.Cursor'&gt;\n\n        Args:\n            connection (Connection): Connection to SQLite database.\n        \"\"\"\n        self.connection = connection\n        self.cursor = self.connection.cursor()\n\n    def __call__(self, query: str, values: List[Tuple] | None = None) -&gt; None:\n        \"\"\"Execute and commit SQL query.\n\n        Examples:\n            &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n            &gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n            &gt;&gt;&gt; wrapper.select(\"select * from test\")\n            []\n\n        Args:\n            query (str): Query string, can contain SQL place holders for values (?).\n            values (list[tuple] | None, optional): Values to be included in query. Defaults to None.\n\n        Raises:\n            Exception: `sqlite3` Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.\n        \"\"\"\n        try:\n            if values:\n                self.cursor.execute(query, values)\n            else:\n                self.cursor.execute(query)\n            self.connection.commit()\n        except Exception as e:\n            print(\"\\n\", query, \"\\n\")\n            print(values)\n            raise e\n\n    def select(self, query: str) -&gt; List:\n        \"\"\"Return selection from SQLite database.\n\n        Examples:\n            &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n            &gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n            &gt;&gt;&gt; wrapper.select(\"select * from test\")\n            []\n\n        Args:\n            query (str): SQL select query.\n\n        Raises:\n            Exception: `sqlite3` Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.\n\n        Returns:\n            List: Array of results from SQL query.\n        \"\"\"\n        try:\n            response = self.cursor.execute(query)\n            self.connection.commit()\n        except Exception as e:\n            print(\"\\n\", query, \"\\n\")\n            raise e\n        else:\n            return response.fetchall()\n</code></pre>"},{"location":"reference/utils/#minall.utils.database.SQLiteWrapper.__call__","title":"<code>__call__(query, values=None)</code>","text":"<p>Execute and commit SQL query.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n&gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n&gt;&gt;&gt; wrapper.select(\"select * from test\")\n[]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Query string, can contain SQL place holders for values (?).</p> required <code>values</code> <code>list[tuple] | None</code> <p>Values to be included in query. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p><code>sqlite3</code> Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.</p> Source code in <code>minall/utils/database.py</code> <pre><code>def __call__(self, query: str, values: List[Tuple] | None = None) -&gt; None:\n    \"\"\"Execute and commit SQL query.\n\n    Examples:\n        &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n        &gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n        &gt;&gt;&gt; wrapper.select(\"select * from test\")\n        []\n\n    Args:\n        query (str): Query string, can contain SQL place holders for values (?).\n        values (list[tuple] | None, optional): Values to be included in query. Defaults to None.\n\n    Raises:\n        Exception: `sqlite3` Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.\n    \"\"\"\n    try:\n        if values:\n            self.cursor.execute(query, values)\n        else:\n            self.cursor.execute(query)\n        self.connection.commit()\n    except Exception as e:\n        print(\"\\n\", query, \"\\n\")\n        print(values)\n        raise e\n</code></pre>"},{"location":"reference/utils/#minall.utils.database.SQLiteWrapper.__init__","title":"<code>__init__(connection)</code>","text":"<p>Store database connection and create cursor.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n&gt;&gt;&gt; type(wrapper.cursor)\n&lt;class 'sqlite3.Cursor'&gt;\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Connection</code> <p>Connection to SQLite database.</p> required Source code in <code>minall/utils/database.py</code> <pre><code>def __init__(self, connection: Connection) -&gt; None:\n    \"\"\"Store database connection and create cursor.\n\n    Examples:\n        &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n        &gt;&gt;&gt; type(wrapper.cursor)\n        &lt;class 'sqlite3.Cursor'&gt;\n\n    Args:\n        connection (Connection): Connection to SQLite database.\n    \"\"\"\n    self.connection = connection\n    self.cursor = self.connection.cursor()\n</code></pre>"},{"location":"reference/utils/#minall.utils.database.SQLiteWrapper.select","title":"<code>select(query)</code>","text":"<p>Return selection from SQLite database.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n&gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n&gt;&gt;&gt; wrapper.select(\"select * from test\")\n[]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SQL select query.</p> required <p>Raises:</p> Type Description <code>Exception</code> <p><code>sqlite3</code> Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.</p> <p>Returns:</p> Name Type Description <code>List</code> <code>List</code> <p>Array of results from SQL query.</p> Source code in <code>minall/utils/database.py</code> <pre><code>def select(self, query: str) -&gt; List:\n    \"\"\"Return selection from SQLite database.\n\n    Examples:\n        &gt;&gt;&gt; wrapper = SQLiteWrapper(connection=connect_to_database())\n        &gt;&gt;&gt; _ = wrapper(query=\"create table test(name text)\")\n        &gt;&gt;&gt; wrapper.select(\"select * from test\")\n        []\n\n    Args:\n        query (str): SQL select query.\n\n    Raises:\n        Exception: `sqlite3` Exception caused either by falling to execute query with cursor or by failing to commit changes to connected database.\n\n    Returns:\n        List: Array of results from SQL query.\n    \"\"\"\n    try:\n        response = self.cursor.execute(query)\n        self.connection.commit()\n    except Exception as e:\n        print(\"\\n\", query, \"\\n\")\n        raise e\n    else:\n        return response.fetchall()\n</code></pre>"},{"location":"reference/utils/#minall.utils.database.connect_to_database","title":"<code>connect_to_database(database=None)</code>","text":"<p>Connect to SQLite database.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; conn = connect_to_database()\n&gt;&gt;&gt; type(conn)\n&lt;class 'sqlite3.Connection'&gt;\n&gt;&gt;&gt; _ = conn.cursor().execute(\"create table test(name text)\")\n&gt;&gt;&gt; conn.cursor().execute(\"select * from test\").fetchall()\n[]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>database</code> <code>str | None</code> <p>If given, path to embedded SQLite database. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Connection</code> <code>Connection</code> <p>description</p> Source code in <code>minall/utils/database.py</code> <pre><code>def connect_to_database(database: str | None = None) -&gt; Connection:\n    \"\"\"Connect to SQLite database.\n\n    Examples:\n        &gt;&gt;&gt; conn = connect_to_database()\n        &gt;&gt;&gt; type(conn)\n        &lt;class 'sqlite3.Connection'&gt;\n        &gt;&gt;&gt; _ = conn.cursor().execute(\"create table test(name text)\")\n        &gt;&gt;&gt; conn.cursor().execute(\"select * from test\").fetchall()\n        []\n\n    Args:\n        database (str | None, optional): If given, path to embedded SQLite database. Defaults to None.\n\n    Returns:\n        Connection: _description_\n    \"\"\"\n\n    if database:\n        [p.mkdir(exist_ok=True) for p in Path(database).parents]\n        connection = sqlite3.connect(database)\n    else:\n        connection = sqlite3.connect(\":memory:\")\n    return connection\n</code></pre>"},{"location":"reference/utils/#minall.utils.parse_config","title":"<code>minall.utils.parse_config</code>","text":"<p>Data class to store and manage minet client credentials.</p> <p>The class <code>APIKeys</code> contains the following methods and properties:</p> <ul> <li><code>__init__(config)</code> - Parses the minet client configuration details.</li> <li><code>env_string()</code> - Formats the minet client credentials as an environment variable string.</li> <li><code>load_config_file(config_file)</code> - Parse client configuration details from JSON or YAML file.</li> </ul>"},{"location":"reference/utils/#minall.utils.parse_config.APIKeys","title":"<code>APIKeys</code>  <code>dataclass</code>","text":"<p>Data class to store and manage minet client credentials.</p> <p>Attributes:</p> Name Type Description <code>buzzsumo_token</code> <code>Optional[str]</code> <p>Buzzsumo API token. Optional.</p> <code>crowdtangle_token</code> <code>Optional[str]</code> <p>CrowdTangle API token. Optional.</p> <code>crowdtangle_rate_limit</code> <code>Optional[str]</code> <p>CrowdTangle API rate limit, cast as a string. Optional.</p> <code>youtube_key</code> <code>Optional[List[str]]) </code> <p>List of YouTube API keys. Optional.</p> Source code in <code>minall/utils/parse_config.py</code> <pre><code>@dataclass\nclass APIKeys:\n    \"\"\"Data class to store and manage minet client credentials.\n\n    Attributes:\n        buzzsumo_token (Optional[str]): Buzzsumo API token. Optional.\n        crowdtangle_token (Optional[str]):  CrowdTangle API token. Optional.\n        crowdtangle_rate_limit (Optional[str]): CrowdTangle API rate limit, cast as a string. Optional.\n        youtube_key (Optional[List[str]]) : List of YouTube API keys. Optional.\n    \"\"\"\n\n    buzzsumo_token: Optional[str]\n    crowdtangle_token: Optional[str]\n    crowdtangle_rate_limit: Optional[str]\n    youtube_key: Optional[List[str]]\n\n    def __init__(self, config: str | dict | None = None):\n        \"\"\"Parse and save minet API client configuration details.\n\n        Examples:\n            &gt;&gt;&gt; keys = APIKeys(config={\"youtube\": {\"key\": \"key1,key2\"}})\n            &gt;&gt;&gt; keys\n            APIKeys(buzzsumo_token=None, crowdtangle_token=None, crowdtangle_rate_limit=None, youtube_key=[\"key1\", \"key2\"])\n            &gt;&gt;&gt; keys.youtube_key\n            [\"key1, \"key2]\n\n        Args:\n            config (str | dict | None, optional): If string, string is treated like file path to JSON or YAML file that contains details; if dict, details are directly parsed; if None, details are searched from environment variables. Defaults to None.\n        \"\"\"\n        if config:\n            if isinstance(config, str):\n                parsed_config = self.load_config_file(config)\n            else:\n                parsed_config = config\n            self.buzzsumo_token = parsed_config[\"buzzsumo\"][\"token\"]\n            self.crowdtangle_token = parsed_config[\"crowdtangle\"][\"token\"]\n            self.crowdtangle_rate_limit = parsed_config[\"crowdtangle\"][\"rate_limit\"]\n            yt_keys = parsed_config[\"youtube\"][\"key\"]\n            if isinstance(yt_keys, list):\n                self.youtube_key = yt_keys\n            else:\n                self.youtube_key = parsed_config[\"youtube\"][\"key\"].split(\",\")\n        else:\n            self.buzzsumo_token = os.environ.get(\"BUZZSUMO_TOKEN\")\n            self.crowdtangle_token = os.environ.get(\"CROWDTANGLE_TOKEN\")\n            self.crowdtangle_rate_limit = os.environ.get(\"CROWDTANGLE_RATE_LIMIT\")\n            youtube_key = os.environ.get(\"YOUTUBE_KEY\")\n            if youtube_key:\n                self.youtube_key = youtube_key.split(\",\")\n            else:\n                self.youtube_key = []\n\n    @property\n    def env_string(self) -&gt; str:\n        r\"\"\"Formatted string for setting environment variables.\n\n        Examples:\n            &gt;&gt;&gt; keys = APIKeys(config={'buzzsumo': {'token': 'bz_token'}, 'crowdtangle': {'token': 'ct_token', 'rate_limit': 10}, 'youtube': {'key': 'key1,key2'}})\n            &gt;&gt;&gt; keys.env_string\n            \"BUZZSUMO_TOKEN=bz_token\\nCROWDTANGLE_TOKEN=ct_token\\nCROWDTANGLE_RATE_LIMIT=10\\nYOUTUBE_KEY=['key1', 'key2']\\n\"\n\n        Returns:\n            str: String declaring environment variables.\n        \"\"\"\n\n        return \"BUZZSUMO_TOKEN={bz}\\nCROWDTANGLE_TOKEN={ct}\\nCROWDTANGLE_RATE_LIMIT={crl}\\nYOUTUBE_KEY={yt}\\n\".format(\n            bz=self.buzzsumo_token,\n            ct=self.crowdtangle_token,\n            crl=self.crowdtangle_rate_limit,\n            yt=self.youtube_key,\n        )\n\n    def load_config_file(self, config_file: str) -&gt; dict:\n        \"\"\"Parse dictionary from JSON or YAML configuration file.\n\n        Args:\n            config_file (str): Path to JSON or YAML file.\n\n        Raises:\n            OSError: Error raised if given file path does not have the extension \".json\", \".yml\", or \".yaml\".\n\n        Returns:\n            dict: Parsed dictionary from JSON or YAML configuration file.\n        \"\"\"\n\n        with open(config_file) as f:\n            extension = Path(config_file).suffix\n            if extension == \".json\":\n                return json.load(f)\n            elif extension == \".yml\" or extension == \".yaml\":\n                return yaml.safe_load(f)\n            else:\n                raise OSError\n</code></pre>"},{"location":"reference/utils/#minall.utils.parse_config.APIKeys.env_string","title":"<code>env_string: str</code>  <code>property</code>","text":"<p>Formatted string for setting environment variables.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; keys = APIKeys(config={'buzzsumo': {'token': 'bz_token'}, 'crowdtangle': {'token': 'ct_token', 'rate_limit': 10}, 'youtube': {'key': 'key1,key2'}})\n&gt;&gt;&gt; keys.env_string\n\"BUZZSUMO_TOKEN=bz_token\\nCROWDTANGLE_TOKEN=ct_token\\nCROWDTANGLE_RATE_LIMIT=10\\nYOUTUBE_KEY=['key1', 'key2']\\n\"\n</code></pre> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>String declaring environment variables.</p>"},{"location":"reference/utils/#minall.utils.parse_config.APIKeys.__init__","title":"<code>__init__(config=None)</code>","text":"<p>Parse and save minet API client configuration details.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; keys = APIKeys(config={\"youtube\": {\"key\": \"key1,key2\"}})\n&gt;&gt;&gt; keys\nAPIKeys(buzzsumo_token=None, crowdtangle_token=None, crowdtangle_rate_limit=None, youtube_key=[\"key1\", \"key2\"])\n&gt;&gt;&gt; keys.youtube_key\n[\"key1, \"key2]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>str | dict | None</code> <p>If string, string is treated like file path to JSON or YAML file that contains details; if dict, details are directly parsed; if None, details are searched from environment variables. Defaults to None.</p> <code>None</code> Source code in <code>minall/utils/parse_config.py</code> <pre><code>def __init__(self, config: str | dict | None = None):\n    \"\"\"Parse and save minet API client configuration details.\n\n    Examples:\n        &gt;&gt;&gt; keys = APIKeys(config={\"youtube\": {\"key\": \"key1,key2\"}})\n        &gt;&gt;&gt; keys\n        APIKeys(buzzsumo_token=None, crowdtangle_token=None, crowdtangle_rate_limit=None, youtube_key=[\"key1\", \"key2\"])\n        &gt;&gt;&gt; keys.youtube_key\n        [\"key1, \"key2]\n\n    Args:\n        config (str | dict | None, optional): If string, string is treated like file path to JSON or YAML file that contains details; if dict, details are directly parsed; if None, details are searched from environment variables. Defaults to None.\n    \"\"\"\n    if config:\n        if isinstance(config, str):\n            parsed_config = self.load_config_file(config)\n        else:\n            parsed_config = config\n        self.buzzsumo_token = parsed_config[\"buzzsumo\"][\"token\"]\n        self.crowdtangle_token = parsed_config[\"crowdtangle\"][\"token\"]\n        self.crowdtangle_rate_limit = parsed_config[\"crowdtangle\"][\"rate_limit\"]\n        yt_keys = parsed_config[\"youtube\"][\"key\"]\n        if isinstance(yt_keys, list):\n            self.youtube_key = yt_keys\n        else:\n            self.youtube_key = parsed_config[\"youtube\"][\"key\"].split(\",\")\n    else:\n        self.buzzsumo_token = os.environ.get(\"BUZZSUMO_TOKEN\")\n        self.crowdtangle_token = os.environ.get(\"CROWDTANGLE_TOKEN\")\n        self.crowdtangle_rate_limit = os.environ.get(\"CROWDTANGLE_RATE_LIMIT\")\n        youtube_key = os.environ.get(\"YOUTUBE_KEY\")\n        if youtube_key:\n            self.youtube_key = youtube_key.split(\",\")\n        else:\n            self.youtube_key = []\n</code></pre>"},{"location":"reference/utils/#minall.utils.parse_config.APIKeys.load_config_file","title":"<code>load_config_file(config_file)</code>","text":"<p>Parse dictionary from JSON or YAML configuration file.</p> <p>Parameters:</p> Name Type Description Default <code>config_file</code> <code>str</code> <p>Path to JSON or YAML file.</p> required <p>Raises:</p> Type Description <code>OSError</code> <p>Error raised if given file path does not have the extension \".json\", \".yml\", or \".yaml\".</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Parsed dictionary from JSON or YAML configuration file.</p> Source code in <code>minall/utils/parse_config.py</code> <pre><code>def load_config_file(self, config_file: str) -&gt; dict:\n    \"\"\"Parse dictionary from JSON or YAML configuration file.\n\n    Args:\n        config_file (str): Path to JSON or YAML file.\n\n    Raises:\n        OSError: Error raised if given file path does not have the extension \".json\", \".yml\", or \".yaml\".\n\n    Returns:\n        dict: Parsed dictionary from JSON or YAML configuration file.\n    \"\"\"\n\n    with open(config_file) as f:\n        extension = Path(config_file).suffix\n        if extension == \".json\":\n            return json.load(f)\n        elif extension == \".yml\" or extension == \".yaml\":\n            return yaml.safe_load(f)\n        else:\n            raise OSError\n</code></pre>"},{"location":"reference/utils/#minall.utils.progress_bar","title":"<code>minall.utils.progress_bar</code>","text":"<p>Context for rich progress bar.</p>"},{"location":"reference/utils/#minall.utils.progress_bar.progress_bar","title":"<code>progress_bar()</code>","text":"<p>Rich progress bar with Spinner column.</p> <p>Yields:</p> Type Description <code>Progress</code> <p>Generator[Progress, None, None]: Rich progress bar context</p> Source code in <code>minall/utils/progress_bar.py</code> <pre><code>@contextmanager\ndef progress_bar() -&gt; Generator[Progress, None, None]:\n    \"\"\"Rich progress bar with Spinner column.\n\n    Yields:\n        Generator[Progress, None, None]: Rich progress bar context\n    \"\"\"\n    with Progress(\n        TextColumn(\"[progress.description]{task.description}\"),\n        SpinnerColumn(),\n        MofNCompleteColumn(),\n        TimeElapsedColumn(),\n    ) as progress:\n        yield progress\n</code></pre>"}]}